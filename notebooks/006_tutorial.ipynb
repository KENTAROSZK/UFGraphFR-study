{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410653fb",
   "metadata": {},
   "source": [
    "005に対して以下の変更を入れた。\n",
    "\n",
    "承知いたしました。「サーバーのグローバルアイテム埋め込みを直接更新」するのではなく、サーバー側でオプティマイザを使って「学習」させる形に修正を加えます。\n",
    "\n",
    "この変更により、サーバーの`global_item_embedding`は、勾配降下法によって更新される通常のPyTorchモジュールのパラメータとして扱われるようになります。\n",
    "\n",
    "**主な変更点:**\n",
    "\n",
    "1.  **`Server` クラスにオプティマイザを追加**: `__init__` メソッドで `self.global_item_optimizer` を初期化します。\n",
    "\n",
    "2.  **`aggregate_item_embeddings` 関数を修正**:\n",
    "\n",
    "      * この関数は、グラフ畳み込みとFedAvgによる加重平均の結果として得られた `new_global_item_embedding_weight` を直接 `copy_` するのではなく、サーバーのオプティマイザが最適化するための「ターゲット」または「参照」として利用します。\n",
    "      * **重要な概念**: Federated Learningにおけるサーバー側の更新は、ローカルモデルの平均化が「サーバーモデルの勾配」と見なされることが多いです。ここでは、`R_tensor` から得られた `new_global_item_embedding_weight` を、サーバーの`global_item_embedding`が目指すべき理想的な状態として扱い、その状態に近づくようにオプティマイザを動かす、という解釈を取ります。\n",
    "      * ただし、PyTorchの通常の学習ループでは、損失を計算し、`backward()` を呼び出して勾配を計算し、`optimizer.step()` でパラメータを更新します。サーバー側での「学習」を厳密に再現するには、`new_global_item_embedding_weight` を用いて何らかの「損失」を定義し、それを最小化する形で`global_item_embedding`を更新する必要があります。\n",
    "\n",
    "    最もシンプルで一般的なアプローチは、FedAvgにおける「サーバーモデルは、クライアントモデルの重み付き平均に更新される」という概念をPyTorchの最適化パスに変換することです。これは通常、以下のように行われます。\n",
    "\n",
    "      * サーバーのオプティマイザの勾配をゼロにする。\n",
    "      * サーバーの`global_item_embedding`の現在の重みと、クライアントから集約された新しいターゲット重みとの間の「差」を損失として扱う（例えば、MSEロス）。\n",
    "      * この損失に基づいて勾配を計算し、オプティマイザでステップを実行する。\n",
    "\n",
    "    しかし、論文の文脈では、この「学習」は必ずしも厳密な意味でのロス最小化を伴うとは限りません。FedAvgの多くは、単に重み付き平均を計算して直接適用します。そこで、今回は`optimizer.step()`を利用しつつ、**グラフ集約された結果をサーバーモデルが「学習」する**という解釈を強調するために、`new_global_item_embedding_weight`をターゲットとして、サーバーの埋め込みを更新する形にします。\n",
    "\n",
    "    **より実践的なアプローチ**: グローバルアイテム埋め込みを直接最適化するには、集約された `new_global_item_embedding_weight` を「擬似的な勾配」として利用するか、あるいはそれを「ターゲット」として、現在の `self.global_item_embedding.weight` との差分を損失として最適化する方法が考えられます。後者の方法を採用します。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2443e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kentaro.suzuki/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embedding dimension: 384\n",
      "Number of users: 100\n",
      "Number of items: 50\n",
      "Total interactions: 5000\n",
      "Number of clients (1 client per user): 100\n",
      "\n",
      "--- Communication Round 1/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7839\n",
      "  Client 1 (User 1) local loss: 0.8479\n",
      "  Client 2 (User 2) local loss: 0.8426\n",
      "  Client 3 (User 3) local loss: 0.7891\n",
      "  Client 4 (User 4) local loss: 0.8219\n",
      "  Client 5 (User 5) local loss: 0.8059\n",
      "  Client 6 (User 6) local loss: 0.8673\n",
      "  Client 7 (User 7) local loss: 0.8535\n",
      "  Client 8 (User 8) local loss: 0.8148\n",
      "  Client 9 (User 9) local loss: 0.7695\n",
      "  Client 10 (User 10) local loss: 0.9366\n",
      "  Client 11 (User 11) local loss: 0.8265\n",
      "  Client 12 (User 12) local loss: 0.8255\n",
      "  Client 13 (User 13) local loss: 0.8200\n",
      "  Client 14 (User 14) local loss: 0.8185\n",
      "  Client 15 (User 15) local loss: 0.7798\n",
      "  Client 16 (User 16) local loss: 0.8306\n",
      "  Client 17 (User 17) local loss: 0.8093\n",
      "  Client 18 (User 18) local loss: 0.8758\n",
      "  Client 19 (User 19) local loss: 0.7985\n",
      "  Client 20 (User 20) local loss: 0.8492\n",
      "  Client 21 (User 21) local loss: 0.8564\n",
      "  Client 22 (User 22) local loss: 0.8726\n",
      "  Client 23 (User 23) local loss: 0.8516\n",
      "  Client 24 (User 24) local loss: 0.8059\n",
      "  Client 25 (User 25) local loss: 0.7776\n",
      "  Client 26 (User 26) local loss: 0.7164\n",
      "  Client 27 (User 27) local loss: 0.8858\n",
      "  Client 28 (User 28) local loss: 0.8516\n",
      "  Client 29 (User 29) local loss: 0.8110\n",
      "  Client 30 (User 30) local loss: 0.7714\n",
      "  Client 31 (User 31) local loss: 0.8201\n",
      "  Client 32 (User 32) local loss: 0.8012\n",
      "  Client 33 (User 33) local loss: 0.9078\n",
      "  Client 34 (User 34) local loss: 0.8734\n",
      "  Client 35 (User 35) local loss: 0.8265\n",
      "  Client 36 (User 36) local loss: 0.8332\n",
      "  Client 37 (User 37) local loss: 0.7666\n",
      "  Client 38 (User 38) local loss: 0.8451\n",
      "  Client 39 (User 39) local loss: 0.8332\n",
      "  Client 40 (User 40) local loss: 0.7761\n",
      "  Client 41 (User 41) local loss: 0.8193\n",
      "  Client 42 (User 42) local loss: 0.7967\n",
      "  Client 43 (User 43) local loss: 0.7994\n",
      "  Client 44 (User 44) local loss: 0.8263\n",
      "  Client 45 (User 45) local loss: 0.8031\n",
      "  Client 46 (User 46) local loss: 0.8069\n",
      "  Client 47 (User 47) local loss: 0.8049\n",
      "  Client 48 (User 48) local loss: 0.7863\n",
      "  Client 49 (User 49) local loss: 0.8126\n",
      "  Client 50 (User 50) local loss: 0.8552\n",
      "  Client 51 (User 51) local loss: 0.7575\n",
      "  Client 52 (User 52) local loss: 0.7759\n",
      "  Client 53 (User 53) local loss: 0.8346\n",
      "  Client 54 (User 54) local loss: 0.8293\n",
      "  Client 55 (User 55) local loss: 0.8854\n",
      "  Client 56 (User 56) local loss: 0.8029\n",
      "  Client 57 (User 57) local loss: 0.8237\n",
      "  Client 58 (User 58) local loss: 0.8397\n",
      "  Client 59 (User 59) local loss: 0.8487\n",
      "  Client 60 (User 60) local loss: 0.8540\n",
      "  Client 61 (User 61) local loss: 0.8574\n",
      "  Client 62 (User 62) local loss: 0.7693\n",
      "  Client 63 (User 63) local loss: 0.7502\n",
      "  Client 64 (User 64) local loss: 0.8670\n",
      "  Client 65 (User 65) local loss: 0.7920\n",
      "  Client 66 (User 66) local loss: 0.7600\n",
      "  Client 67 (User 67) local loss: 0.8543\n",
      "  Client 68 (User 68) local loss: 0.8010\n",
      "  Client 69 (User 69) local loss: 0.8155\n",
      "  Client 70 (User 70) local loss: 0.8870\n",
      "  Client 71 (User 71) local loss: 0.7590\n",
      "  Client 72 (User 72) local loss: 0.7857\n",
      "  Client 73 (User 73) local loss: 0.8363\n",
      "  Client 74 (User 74) local loss: 0.8324\n",
      "  Client 75 (User 75) local loss: 0.8126\n",
      "  Client 76 (User 76) local loss: 0.8401\n",
      "  Client 77 (User 77) local loss: 0.8510\n",
      "  Client 78 (User 78) local loss: 0.8151\n",
      "  Client 79 (User 79) local loss: 0.8528\n",
      "  Client 80 (User 80) local loss: 0.8721\n",
      "  Client 81 (User 81) local loss: 0.7680\n",
      "  Client 82 (User 82) local loss: 0.8782\n",
      "  Client 83 (User 83) local loss: 0.8644\n",
      "  Client 84 (User 84) local loss: 0.7984\n",
      "  Client 85 (User 85) local loss: 0.8338\n",
      "  Client 86 (User 86) local loss: 0.7988\n",
      "  Client 87 (User 87) local loss: 0.8311\n",
      "  Client 88 (User 88) local loss: 0.7956\n",
      "  Client 89 (User 89) local loss: 0.7596\n",
      "  Client 90 (User 90) local loss: 0.8285\n",
      "  Client 91 (User 91) local loss: 0.7952\n",
      "  Client 92 (User 92) local loss: 0.8793\n",
      "  Client 93 (User 93) local loss: 0.8993\n",
      "  Client 94 (User 94) local loss: 0.8107\n",
      "  Client 95 (User 95) local loss: 0.8629\n",
      "  Client 96 (User 96) local loss: 0.8444\n",
      "  Client 97 (User 97) local loss: 0.8019\n",
      "  Client 98 (User 98) local loss: 0.8148\n",
      "  Client 99 (User 99) local loss: 0.8388\n",
      "Round 1 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 2/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7878\n",
      "  Client 1 (User 1) local loss: 0.8464\n",
      "  Client 2 (User 2) local loss: 0.8350\n",
      "  Client 3 (User 3) local loss: 0.8150\n",
      "  Client 4 (User 4) local loss: 0.8009\n",
      "  Client 5 (User 5) local loss: 0.7887\n",
      "  Client 6 (User 6) local loss: 0.8518\n",
      "  Client 7 (User 7) local loss: 0.8505\n",
      "  Client 8 (User 8) local loss: 0.8186\n",
      "  Client 9 (User 9) local loss: 0.7574\n",
      "  Client 10 (User 10) local loss: 0.9455\n",
      "  Client 11 (User 11) local loss: 0.8449\n",
      "  Client 12 (User 12) local loss: 0.8171\n",
      "  Client 13 (User 13) local loss: 0.8235\n",
      "  Client 14 (User 14) local loss: 0.8167\n",
      "  Client 15 (User 15) local loss: 0.7788\n",
      "  Client 16 (User 16) local loss: 0.8443\n",
      "  Client 17 (User 17) local loss: 0.8201\n",
      "  Client 18 (User 18) local loss: 0.8474\n",
      "  Client 19 (User 19) local loss: 0.8253\n",
      "  Client 20 (User 20) local loss: 0.8477\n",
      "  Client 21 (User 21) local loss: 0.8489\n",
      "  Client 22 (User 22) local loss: 0.8702\n",
      "  Client 23 (User 23) local loss: 0.8494\n",
      "  Client 24 (User 24) local loss: 0.8080\n",
      "  Client 25 (User 25) local loss: 0.7823\n",
      "  Client 26 (User 26) local loss: 0.7157\n",
      "  Client 27 (User 27) local loss: 0.8912\n",
      "  Client 28 (User 28) local loss: 0.8484\n",
      "  Client 29 (User 29) local loss: 0.7978\n",
      "  Client 30 (User 30) local loss: 0.7651\n",
      "  Client 31 (User 31) local loss: 0.8135\n",
      "  Client 32 (User 32) local loss: 0.8050\n",
      "  Client 33 (User 33) local loss: 0.8915\n",
      "  Client 34 (User 34) local loss: 0.8578\n",
      "  Client 35 (User 35) local loss: 0.8555\n",
      "  Client 36 (User 36) local loss: 0.8383\n",
      "  Client 37 (User 37) local loss: 0.7761\n",
      "  Client 38 (User 38) local loss: 0.8249\n",
      "  Client 39 (User 39) local loss: 0.8364\n",
      "  Client 40 (User 40) local loss: 0.7798\n",
      "  Client 41 (User 41) local loss: 0.8116\n",
      "  Client 42 (User 42) local loss: 0.7848\n",
      "  Client 43 (User 43) local loss: 0.8022\n",
      "  Client 44 (User 44) local loss: 0.8236\n",
      "  Client 45 (User 45) local loss: 0.8076\n",
      "  Client 46 (User 46) local loss: 0.8084\n",
      "  Client 47 (User 47) local loss: 0.8032\n",
      "  Client 48 (User 48) local loss: 0.7985\n",
      "  Client 49 (User 49) local loss: 0.8195\n",
      "  Client 50 (User 50) local loss: 0.8592\n",
      "  Client 51 (User 51) local loss: 0.7343\n",
      "  Client 52 (User 52) local loss: 0.7951\n",
      "  Client 53 (User 53) local loss: 0.8270\n",
      "  Client 54 (User 54) local loss: 0.8271\n",
      "  Client 55 (User 55) local loss: 0.8829\n",
      "  Client 56 (User 56) local loss: 0.8018\n",
      "  Client 57 (User 57) local loss: 0.8495\n",
      "  Client 58 (User 58) local loss: 0.8252\n",
      "  Client 59 (User 59) local loss: 0.8528\n",
      "  Client 60 (User 60) local loss: 0.8397\n",
      "  Client 61 (User 61) local loss: 0.8428\n",
      "  Client 62 (User 62) local loss: 0.7869\n",
      "  Client 63 (User 63) local loss: 0.7749\n",
      "  Client 64 (User 64) local loss: 0.9070\n",
      "  Client 65 (User 65) local loss: 0.7904\n",
      "  Client 66 (User 66) local loss: 0.7630\n",
      "  Client 67 (User 67) local loss: 0.8326\n",
      "  Client 68 (User 68) local loss: 0.7881\n",
      "  Client 69 (User 69) local loss: 0.8320\n",
      "  Client 70 (User 70) local loss: 0.8784\n",
      "  Client 71 (User 71) local loss: 0.7785\n",
      "  Client 72 (User 72) local loss: 0.8101\n",
      "  Client 73 (User 73) local loss: 0.8400\n",
      "  Client 74 (User 74) local loss: 0.8295\n",
      "  Client 75 (User 75) local loss: 0.8057\n",
      "  Client 76 (User 76) local loss: 0.8322\n",
      "  Client 77 (User 77) local loss: 0.8495\n",
      "  Client 78 (User 78) local loss: 0.8144\n",
      "  Client 79 (User 79) local loss: 0.8572\n",
      "  Client 80 (User 80) local loss: 0.8589\n",
      "  Client 81 (User 81) local loss: 0.7780\n",
      "  Client 82 (User 82) local loss: 0.8556\n",
      "  Client 83 (User 83) local loss: 0.8546\n",
      "  Client 84 (User 84) local loss: 0.7974\n",
      "  Client 85 (User 85) local loss: 0.8312\n",
      "  Client 86 (User 86) local loss: 0.7918\n",
      "  Client 87 (User 87) local loss: 0.8223\n",
      "  Client 88 (User 88) local loss: 0.8059\n",
      "  Client 89 (User 89) local loss: 0.7656\n",
      "  Client 90 (User 90) local loss: 0.8267\n",
      "  Client 91 (User 91) local loss: 0.8039\n",
      "  Client 92 (User 92) local loss: 0.8708\n",
      "  Client 93 (User 93) local loss: 0.9175\n",
      "  Client 94 (User 94) local loss: 0.7916\n",
      "  Client 95 (User 95) local loss: 0.8598\n",
      "  Client 96 (User 96) local loss: 0.8427\n",
      "  Client 97 (User 97) local loss: 0.7944\n",
      "  Client 98 (User 98) local loss: 0.8128\n",
      "  Client 99 (User 99) local loss: 0.8474\n",
      "Round 2 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 3/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7929\n",
      "  Client 1 (User 1) local loss: 0.8327\n",
      "  Client 2 (User 2) local loss: 0.8339\n",
      "  Client 3 (User 3) local loss: 0.7971\n",
      "  Client 4 (User 4) local loss: 0.8052\n",
      "  Client 5 (User 5) local loss: 0.8146\n",
      "  Client 6 (User 6) local loss: 0.8500\n",
      "  Client 7 (User 7) local loss: 0.8473\n",
      "  Client 8 (User 8) local loss: 0.8109\n",
      "  Client 9 (User 9) local loss: 0.7793\n",
      "  Client 10 (User 10) local loss: 0.9211\n",
      "  Client 11 (User 11) local loss: 0.8308\n",
      "  Client 12 (User 12) local loss: 0.8149\n",
      "  Client 13 (User 13) local loss: 0.8104\n",
      "  Client 14 (User 14) local loss: 0.8159\n",
      "  Client 15 (User 15) local loss: 0.7636\n",
      "  Client 16 (User 16) local loss: 0.8472\n",
      "  Client 17 (User 17) local loss: 0.8177\n",
      "  Client 18 (User 18) local loss: 0.8536\n",
      "  Client 19 (User 19) local loss: 0.8242\n",
      "  Client 20 (User 20) local loss: 0.8458\n",
      "  Client 21 (User 21) local loss: 0.8407\n",
      "  Client 22 (User 22) local loss: 0.8483\n",
      "  Client 23 (User 23) local loss: 0.8359\n",
      "  Client 24 (User 24) local loss: 0.7942\n",
      "  Client 25 (User 25) local loss: 0.7871\n",
      "  Client 26 (User 26) local loss: 0.7266\n",
      "  Client 27 (User 27) local loss: 0.8828\n",
      "  Client 28 (User 28) local loss: 0.8511\n",
      "  Client 29 (User 29) local loss: 0.8063\n",
      "  Client 30 (User 30) local loss: 0.7742\n",
      "  Client 31 (User 31) local loss: 0.8185\n",
      "  Client 32 (User 32) local loss: 0.8035\n",
      "  Client 33 (User 33) local loss: 0.8959\n",
      "  Client 34 (User 34) local loss: 0.8702\n",
      "  Client 35 (User 35) local loss: 0.8409\n",
      "  Client 36 (User 36) local loss: 0.8165\n",
      "  Client 37 (User 37) local loss: 0.7673\n",
      "  Client 38 (User 38) local loss: 0.8337\n",
      "  Client 39 (User 39) local loss: 0.8147\n",
      "  Client 40 (User 40) local loss: 0.7776\n",
      "  Client 41 (User 41) local loss: 0.7934\n",
      "  Client 42 (User 42) local loss: 0.7838\n",
      "  Client 43 (User 43) local loss: 0.8097\n",
      "  Client 44 (User 44) local loss: 0.8283\n",
      "  Client 45 (User 45) local loss: 0.8123\n",
      "  Client 46 (User 46) local loss: 0.7997\n",
      "  Client 47 (User 47) local loss: 0.8087\n",
      "  Client 48 (User 48) local loss: 0.7868\n",
      "  Client 49 (User 49) local loss: 0.8169\n",
      "  Client 50 (User 50) local loss: 0.8569\n",
      "  Client 51 (User 51) local loss: 0.7495\n",
      "  Client 52 (User 52) local loss: 0.8074\n",
      "  Client 53 (User 53) local loss: 0.8197\n",
      "  Client 54 (User 54) local loss: 0.8310\n",
      "  Client 55 (User 55) local loss: 0.8618\n",
      "  Client 56 (User 56) local loss: 0.8005\n",
      "  Client 57 (User 57) local loss: 0.8257\n",
      "  Client 58 (User 58) local loss: 0.8282\n",
      "  Client 59 (User 59) local loss: 0.8438\n",
      "  Client 60 (User 60) local loss: 0.8484\n",
      "  Client 61 (User 61) local loss: 0.8534\n",
      "  Client 62 (User 62) local loss: 0.7914\n",
      "  Client 63 (User 63) local loss: 0.7842\n",
      "  Client 64 (User 64) local loss: 0.8703\n",
      "  Client 65 (User 65) local loss: 0.7887\n",
      "  Client 66 (User 66) local loss: 0.7615\n",
      "  Client 67 (User 67) local loss: 0.8510\n",
      "  Client 68 (User 68) local loss: 0.7987\n",
      "  Client 69 (User 69) local loss: 0.8185\n",
      "  Client 70 (User 70) local loss: 0.8810\n",
      "  Client 71 (User 71) local loss: 0.7822\n",
      "  Client 72 (User 72) local loss: 0.7958\n",
      "  Client 73 (User 73) local loss: 0.8406\n",
      "  Client 74 (User 74) local loss: 0.8210\n",
      "  Client 75 (User 75) local loss: 0.8046\n",
      "  Client 76 (User 76) local loss: 0.8380\n",
      "  Client 77 (User 77) local loss: 0.8480\n",
      "  Client 78 (User 78) local loss: 0.8020\n",
      "  Client 79 (User 79) local loss: 0.8666\n",
      "  Client 80 (User 80) local loss: 0.8687\n",
      "  Client 81 (User 81) local loss: 0.7824\n",
      "  Client 82 (User 82) local loss: 0.8455\n",
      "  Client 83 (User 83) local loss: 0.8513\n",
      "  Client 84 (User 84) local loss: 0.8105\n",
      "  Client 85 (User 85) local loss: 0.8290\n",
      "  Client 86 (User 86) local loss: 0.7874\n",
      "  Client 87 (User 87) local loss: 0.8260\n",
      "  Client 88 (User 88) local loss: 0.8103\n",
      "  Client 89 (User 89) local loss: 0.7647\n",
      "  Client 90 (User 90) local loss: 0.8188\n",
      "  Client 91 (User 91) local loss: 0.7862\n",
      "  Client 92 (User 92) local loss: 0.8755\n",
      "  Client 93 (User 93) local loss: 0.9015\n",
      "  Client 94 (User 94) local loss: 0.7950\n",
      "  Client 95 (User 95) local loss: 0.8582\n",
      "  Client 96 (User 96) local loss: 0.8477\n",
      "  Client 97 (User 97) local loss: 0.8058\n",
      "  Client 98 (User 98) local loss: 0.8221\n",
      "  Client 99 (User 99) local loss: 0.8334\n",
      "Round 3 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 4/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7976\n",
      "  Client 1 (User 1) local loss: 0.8313\n",
      "  Client 2 (User 2) local loss: 0.8398\n",
      "  Client 3 (User 3) local loss: 0.7798\n",
      "  Client 4 (User 4) local loss: 0.7907\n",
      "  Client 5 (User 5) local loss: 0.8024\n",
      "  Client 6 (User 6) local loss: 0.8482\n",
      "  Client 7 (User 7) local loss: 0.8388\n",
      "  Client 8 (User 8) local loss: 0.8190\n",
      "  Client 9 (User 9) local loss: 0.7671\n",
      "  Client 10 (User 10) local loss: 0.9348\n",
      "  Client 11 (User 11) local loss: 0.8239\n",
      "  Client 12 (User 12) local loss: 0.8214\n",
      "  Client 13 (User 13) local loss: 0.7980\n",
      "  Client 14 (User 14) local loss: 0.8007\n",
      "  Client 15 (User 15) local loss: 0.7756\n",
      "  Client 16 (User 16) local loss: 0.8342\n",
      "  Client 17 (User 17) local loss: 0.7911\n",
      "  Client 18 (User 18) local loss: 0.8655\n",
      "  Client 19 (User 19) local loss: 0.8224\n",
      "  Client 20 (User 20) local loss: 0.8387\n",
      "  Client 21 (User 21) local loss: 0.8500\n",
      "  Client 22 (User 22) local loss: 0.8452\n",
      "  Client 23 (User 23) local loss: 0.8455\n",
      "  Client 24 (User 24) local loss: 0.7851\n",
      "  Client 25 (User 25) local loss: 0.7597\n",
      "  Client 26 (User 26) local loss: 0.7261\n",
      "  Client 27 (User 27) local loss: 0.8810\n",
      "  Client 28 (User 28) local loss: 0.8490\n",
      "  Client 29 (User 29) local loss: 0.8081\n",
      "  Client 30 (User 30) local loss: 0.7633\n",
      "  Client 31 (User 31) local loss: 0.8174\n",
      "  Client 32 (User 32) local loss: 0.7966\n",
      "  Client 33 (User 33) local loss: 0.8849\n",
      "  Client 34 (User 34) local loss: 0.8613\n",
      "  Client 35 (User 35) local loss: 0.8328\n",
      "  Client 36 (User 36) local loss: 0.8207\n",
      "  Client 37 (User 37) local loss: 0.7573\n",
      "  Client 38 (User 38) local loss: 0.8308\n",
      "  Client 39 (User 39) local loss: 0.8263\n",
      "  Client 40 (User 40) local loss: 0.7638\n",
      "  Client 41 (User 41) local loss: 0.7997\n",
      "  Client 42 (User 42) local loss: 0.7928\n",
      "  Client 43 (User 43) local loss: 0.8033\n",
      "  Client 44 (User 44) local loss: 0.8255\n",
      "  Client 45 (User 45) local loss: 0.7965\n",
      "  Client 46 (User 46) local loss: 0.8006\n",
      "  Client 47 (User 47) local loss: 0.8076\n",
      "  Client 48 (User 48) local loss: 0.7748\n",
      "  Client 49 (User 49) local loss: 0.8075\n",
      "  Client 50 (User 50) local loss: 0.8496\n",
      "  Client 51 (User 51) local loss: 0.7481\n",
      "  Client 52 (User 52) local loss: 0.7998\n",
      "  Client 53 (User 53) local loss: 0.8253\n",
      "  Client 54 (User 54) local loss: 0.8216\n",
      "  Client 55 (User 55) local loss: 0.8462\n",
      "  Client 56 (User 56) local loss: 0.8095\n",
      "  Client 57 (User 57) local loss: 0.8390\n",
      "  Client 58 (User 58) local loss: 0.8357\n",
      "  Client 59 (User 59) local loss: 0.8418\n",
      "  Client 60 (User 60) local loss: 0.8515\n",
      "  Client 61 (User 61) local loss: 0.8452\n",
      "  Client 62 (User 62) local loss: 0.7781\n",
      "  Client 63 (User 63) local loss: 0.7572\n",
      "  Client 64 (User 64) local loss: 0.8816\n",
      "  Client 65 (User 65) local loss: 0.7858\n",
      "  Client 66 (User 66) local loss: 0.7530\n",
      "  Client 67 (User 67) local loss: 0.8086\n",
      "  Client 68 (User 68) local loss: 0.7912\n",
      "  Client 69 (User 69) local loss: 0.8170\n",
      "  Client 70 (User 70) local loss: 0.8781\n",
      "  Client 71 (User 71) local loss: 0.7642\n",
      "  Client 72 (User 72) local loss: 0.7945\n",
      "  Client 73 (User 73) local loss: 0.8356\n",
      "  Client 74 (User 74) local loss: 0.8119\n",
      "  Client 75 (User 75) local loss: 0.8036\n",
      "  Client 76 (User 76) local loss: 0.8576\n",
      "  Client 77 (User 77) local loss: 0.8677\n",
      "  Client 78 (User 78) local loss: 0.7955\n",
      "  Client 79 (User 79) local loss: 0.8513\n",
      "  Client 80 (User 80) local loss: 0.8730\n",
      "  Client 81 (User 81) local loss: 0.7747\n",
      "  Client 82 (User 82) local loss: 0.8338\n",
      "  Client 83 (User 83) local loss: 0.8508\n",
      "  Client 84 (User 84) local loss: 0.7830\n",
      "  Client 85 (User 85) local loss: 0.8360\n",
      "  Client 86 (User 86) local loss: 0.7997\n",
      "  Client 87 (User 87) local loss: 0.8310\n",
      "  Client 88 (User 88) local loss: 0.8096\n",
      "  Client 89 (User 89) local loss: 0.7484\n",
      "  Client 90 (User 90) local loss: 0.8409\n",
      "  Client 91 (User 91) local loss: 0.7878\n",
      "  Client 92 (User 92) local loss: 0.8594\n",
      "  Client 93 (User 93) local loss: 0.9249\n",
      "  Client 94 (User 94) local loss: 0.7921\n",
      "  Client 95 (User 95) local loss: 0.8492\n",
      "  Client 96 (User 96) local loss: 0.8464\n",
      "  Client 97 (User 97) local loss: 0.7972\n",
      "  Client 98 (User 98) local loss: 0.8241\n",
      "  Client 99 (User 99) local loss: 0.8361\n",
      "Round 4 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 5/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7840\n",
      "  Client 1 (User 1) local loss: 0.8411\n",
      "  Client 2 (User 2) local loss: 0.8306\n",
      "  Client 3 (User 3) local loss: 0.7816\n",
      "  Client 4 (User 4) local loss: 0.8018\n",
      "  Client 5 (User 5) local loss: 0.8030\n",
      "  Client 6 (User 6) local loss: 0.8131\n",
      "  Client 7 (User 7) local loss: 0.8356\n",
      "  Client 8 (User 8) local loss: 0.8274\n",
      "  Client 9 (User 9) local loss: 0.7726\n",
      "  Client 10 (User 10) local loss: 0.9330\n",
      "  Client 11 (User 11) local loss: 0.8169\n",
      "  Client 12 (User 12) local loss: 0.7902\n",
      "  Client 13 (User 13) local loss: 0.8024\n",
      "  Client 14 (User 14) local loss: 0.8114\n",
      "  Client 15 (User 15) local loss: 0.7749\n",
      "  Client 16 (User 16) local loss: 0.8361\n",
      "  Client 17 (User 17) local loss: 0.8248\n",
      "  Client 18 (User 18) local loss: 0.8575\n",
      "  Client 19 (User 19) local loss: 0.7998\n",
      "  Client 20 (User 20) local loss: 0.8360\n",
      "  Client 21 (User 21) local loss: 0.8418\n",
      "  Client 22 (User 22) local loss: 0.8719\n",
      "  Client 23 (User 23) local loss: 0.8383\n",
      "  Client 24 (User 24) local loss: 0.7764\n",
      "  Client 25 (User 25) local loss: 0.7699\n",
      "  Client 26 (User 26) local loss: 0.7316\n",
      "  Client 27 (User 27) local loss: 0.8793\n",
      "  Client 28 (User 28) local loss: 0.8473\n",
      "  Client 29 (User 29) local loss: 0.7938\n",
      "  Client 30 (User 30) local loss: 0.7619\n",
      "  Client 31 (User 31) local loss: 0.8103\n",
      "  Client 32 (User 32) local loss: 0.7838\n",
      "  Client 33 (User 33) local loss: 0.8616\n",
      "  Client 34 (User 34) local loss: 0.8662\n",
      "  Client 35 (User 35) local loss: 0.8291\n",
      "  Client 36 (User 36) local loss: 0.8497\n",
      "  Client 37 (User 37) local loss: 0.7642\n",
      "  Client 38 (User 38) local loss: 0.8155\n",
      "  Client 39 (User 39) local loss: 0.8242\n",
      "  Client 40 (User 40) local loss: 0.7707\n",
      "  Client 41 (User 41) local loss: 0.8001\n",
      "  Client 42 (User 42) local loss: 0.7818\n",
      "  Client 43 (User 43) local loss: 0.8076\n",
      "  Client 44 (User 44) local loss: 0.8346\n",
      "  Client 45 (User 45) local loss: 0.7944\n",
      "  Client 46 (User 46) local loss: 0.7997\n",
      "  Client 47 (User 47) local loss: 0.7878\n",
      "  Client 48 (User 48) local loss: 0.7722\n",
      "  Client 49 (User 49) local loss: 0.8022\n",
      "  Client 50 (User 50) local loss: 0.8406\n",
      "  Client 51 (User 51) local loss: 0.7476\n",
      "  Client 52 (User 52) local loss: 0.7653\n",
      "  Client 53 (User 53) local loss: 0.8368\n",
      "  Client 54 (User 54) local loss: 0.8060\n",
      "  Client 55 (User 55) local loss: 0.8479\n",
      "  Client 56 (User 56) local loss: 0.7883\n",
      "  Client 57 (User 57) local loss: 0.8412\n",
      "  Client 58 (User 58) local loss: 0.8149\n",
      "  Client 59 (User 59) local loss: 0.8274\n",
      "  Client 60 (User 60) local loss: 0.8330\n",
      "  Client 61 (User 61) local loss: 0.8613\n",
      "  Client 62 (User 62) local loss: 0.7639\n",
      "  Client 63 (User 63) local loss: 0.7562\n",
      "  Client 64 (User 64) local loss: 0.8911\n",
      "  Client 65 (User 65) local loss: 0.7703\n",
      "  Client 66 (User 66) local loss: 0.7600\n",
      "  Client 67 (User 67) local loss: 0.8320\n",
      "  Client 68 (User 68) local loss: 0.7901\n",
      "  Client 69 (User 69) local loss: 0.8452\n",
      "  Client 70 (User 70) local loss: 0.8742\n",
      "  Client 71 (User 71) local loss: 0.7630\n",
      "  Client 72 (User 72) local loss: 0.7872\n",
      "  Client 73 (User 73) local loss: 0.8346\n",
      "  Client 74 (User 74) local loss: 0.8234\n",
      "  Client 75 (User 75) local loss: 0.8029\n",
      "  Client 76 (User 76) local loss: 0.8435\n",
      "  Client 77 (User 77) local loss: 0.8527\n",
      "  Client 78 (User 78) local loss: 0.7884\n",
      "  Client 79 (User 79) local loss: 0.8417\n",
      "  Client 80 (User 80) local loss: 0.8594\n",
      "  Client 81 (User 81) local loss: 0.7612\n",
      "  Client 82 (User 82) local loss: 0.8402\n",
      "  Client 83 (User 83) local loss: 0.8332\n",
      "  Client 84 (User 84) local loss: 0.8027\n",
      "  Client 85 (User 85) local loss: 0.8279\n",
      "  Client 86 (User 86) local loss: 0.7786\n",
      "  Client 87 (User 87) local loss: 0.8290\n",
      "  Client 88 (User 88) local loss: 0.8087\n",
      "  Client 89 (User 89) local loss: 0.7609\n",
      "  Client 90 (User 90) local loss: 0.8324\n",
      "  Client 91 (User 91) local loss: 0.7837\n",
      "  Client 92 (User 92) local loss: 0.8680\n",
      "  Client 93 (User 93) local loss: 0.9079\n",
      "  Client 94 (User 94) local loss: 0.7989\n",
      "  Client 95 (User 95) local loss: 0.8543\n",
      "  Client 96 (User 96) local loss: 0.8507\n",
      "  Client 97 (User 97) local loss: 0.8075\n",
      "  Client 98 (User 98) local loss: 0.8079\n",
      "  Client 99 (User 99) local loss: 0.8421\n",
      "Round 5 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 6/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7629\n",
      "  Client 1 (User 1) local loss: 0.8436\n",
      "  Client 2 (User 2) local loss: 0.8339\n",
      "  Client 3 (User 3) local loss: 0.7948\n",
      "  Client 4 (User 4) local loss: 0.7814\n",
      "  Client 5 (User 5) local loss: 0.7941\n",
      "  Client 6 (User 6) local loss: 0.8314\n",
      "  Client 7 (User 7) local loss: 0.8394\n",
      "  Client 8 (User 8) local loss: 0.8138\n",
      "  Client 9 (User 9) local loss: 0.7595\n",
      "  Client 10 (User 10) local loss: 0.9178\n",
      "  Client 11 (User 11) local loss: 0.8227\n",
      "  Client 12 (User 12) local loss: 0.7995\n",
      "  Client 13 (User 13) local loss: 0.8119\n",
      "  Client 14 (User 14) local loss: 0.8088\n",
      "  Client 15 (User 15) local loss: 0.7847\n",
      "  Client 16 (User 16) local loss: 0.8209\n",
      "  Client 17 (User 17) local loss: 0.8021\n",
      "  Client 18 (User 18) local loss: 0.8811\n",
      "  Client 19 (User 19) local loss: 0.8037\n",
      "  Client 20 (User 20) local loss: 0.8272\n",
      "  Client 21 (User 21) local loss: 0.8341\n",
      "  Client 22 (User 22) local loss: 0.8433\n",
      "  Client 23 (User 23) local loss: 0.8475\n",
      "  Client 24 (User 24) local loss: 0.7795\n",
      "  Client 25 (User 25) local loss: 0.7848\n",
      "  Client 26 (User 26) local loss: 0.7136\n",
      "  Client 27 (User 27) local loss: 0.8838\n",
      "  Client 28 (User 28) local loss: 0.8453\n",
      "  Client 29 (User 29) local loss: 0.7836\n",
      "  Client 30 (User 30) local loss: 0.7812\n",
      "  Client 31 (User 31) local loss: 0.8192\n",
      "  Client 32 (User 32) local loss: 0.7824\n",
      "  Client 33 (User 33) local loss: 0.8853\n",
      "  Client 34 (User 34) local loss: 0.8645\n",
      "  Client 35 (User 35) local loss: 0.8137\n",
      "  Client 36 (User 36) local loss: 0.8285\n",
      "  Client 37 (User 37) local loss: 0.7549\n",
      "  Client 38 (User 38) local loss: 0.8053\n",
      "  Client 39 (User 39) local loss: 0.8340\n",
      "  Client 40 (User 40) local loss: 0.7697\n",
      "  Client 41 (User 41) local loss: 0.7852\n",
      "  Client 42 (User 42) local loss: 0.7759\n",
      "  Client 43 (User 43) local loss: 0.7912\n",
      "  Client 44 (User 44) local loss: 0.8423\n",
      "  Client 45 (User 45) local loss: 0.7986\n",
      "  Client 46 (User 46) local loss: 0.7985\n",
      "  Client 47 (User 47) local loss: 0.7976\n",
      "  Client 48 (User 48) local loss: 0.7800\n",
      "  Client 49 (User 49) local loss: 0.7843\n",
      "  Client 50 (User 50) local loss: 0.8547\n",
      "  Client 51 (User 51) local loss: 0.7461\n",
      "  Client 52 (User 52) local loss: 0.7905\n",
      "  Client 53 (User 53) local loss: 0.8347\n",
      "  Client 54 (User 54) local loss: 0.8015\n",
      "  Client 55 (User 55) local loss: 0.8505\n",
      "  Client 56 (User 56) local loss: 0.7866\n",
      "  Client 57 (User 57) local loss: 0.8460\n",
      "  Client 58 (User 58) local loss: 0.8135\n",
      "  Client 59 (User 59) local loss: 0.8360\n",
      "  Client 60 (User 60) local loss: 0.8406\n",
      "  Client 61 (User 61) local loss: 0.8530\n",
      "  Client 62 (User 62) local loss: 0.7685\n",
      "  Client 63 (User 63) local loss: 0.7595\n",
      "  Client 64 (User 64) local loss: 0.8661\n",
      "  Client 65 (User 65) local loss: 0.7549\n",
      "  Client 66 (User 66) local loss: 0.7551\n",
      "  Client 67 (User 67) local loss: 0.8473\n",
      "  Client 68 (User 68) local loss: 0.7826\n",
      "  Client 69 (User 69) local loss: 0.8322\n",
      "  Client 70 (User 70) local loss: 0.8544\n",
      "  Client 71 (User 71) local loss: 0.7709\n",
      "  Client 72 (User 72) local loss: 0.8034\n",
      "  Client 73 (User 73) local loss: 0.8195\n",
      "  Client 74 (User 74) local loss: 0.8074\n",
      "  Client 75 (User 75) local loss: 0.7912\n",
      "  Client 76 (User 76) local loss: 0.8429\n",
      "  Client 77 (User 77) local loss: 0.8302\n",
      "  Client 78 (User 78) local loss: 0.8034\n",
      "  Client 79 (User 79) local loss: 0.8572\n",
      "  Client 80 (User 80) local loss: 0.8616\n",
      "  Client 81 (User 81) local loss: 0.7596\n",
      "  Client 82 (User 82) local loss: 0.8300\n",
      "  Client 83 (User 83) local loss: 0.8243\n",
      "  Client 84 (User 84) local loss: 0.8021\n",
      "  Client 85 (User 85) local loss: 0.8143\n",
      "  Client 86 (User 86) local loss: 0.7676\n",
      "  Client 87 (User 87) local loss: 0.8267\n",
      "  Client 88 (User 88) local loss: 0.7901\n",
      "  Client 89 (User 89) local loss: 0.7774\n",
      "  Client 90 (User 90) local loss: 0.8112\n",
      "  Client 91 (User 91) local loss: 0.7704\n",
      "  Client 92 (User 92) local loss: 0.8529\n",
      "  Client 93 (User 93) local loss: 0.8902\n",
      "  Client 94 (User 94) local loss: 0.7787\n",
      "  Client 95 (User 95) local loss: 0.8327\n",
      "  Client 96 (User 96) local loss: 0.8283\n",
      "  Client 97 (User 97) local loss: 0.7874\n",
      "  Client 98 (User 98) local loss: 0.8133\n",
      "  Client 99 (User 99) local loss: 0.8168\n",
      "Round 6 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 7/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7737\n",
      "  Client 1 (User 1) local loss: 0.8351\n",
      "  Client 2 (User 2) local loss: 0.8365\n",
      "  Client 3 (User 3) local loss: 0.7867\n",
      "  Client 4 (User 4) local loss: 0.8160\n",
      "  Client 5 (User 5) local loss: 0.7928\n",
      "  Client 6 (User 6) local loss: 0.8559\n",
      "  Client 7 (User 7) local loss: 0.8243\n",
      "  Client 8 (User 8) local loss: 0.8049\n",
      "  Client 9 (User 9) local loss: 0.7591\n",
      "  Client 10 (User 10) local loss: 0.8918\n",
      "  Client 11 (User 11) local loss: 0.8158\n",
      "  Client 12 (User 12) local loss: 0.7959\n",
      "  Client 13 (User 13) local loss: 0.8048\n",
      "  Client 14 (User 14) local loss: 0.8041\n",
      "  Client 15 (User 15) local loss: 0.7630\n",
      "  Client 16 (User 16) local loss: 0.8280\n",
      "  Client 17 (User 17) local loss: 0.7911\n",
      "  Client 18 (User 18) local loss: 0.8645\n",
      "  Client 19 (User 19) local loss: 0.7937\n",
      "  Client 20 (User 20) local loss: 0.8328\n",
      "  Client 21 (User 21) local loss: 0.8373\n",
      "  Client 22 (User 22) local loss: 0.8322\n",
      "  Client 23 (User 23) local loss: 0.8398\n",
      "  Client 24 (User 24) local loss: 0.7765\n",
      "  Client 25 (User 25) local loss: 0.7733\n",
      "  Client 26 (User 26) local loss: 0.7239\n",
      "  Client 27 (User 27) local loss: 0.8878\n",
      "  Client 28 (User 28) local loss: 0.8427\n",
      "  Client 29 (User 29) local loss: 0.7685\n",
      "  Client 30 (User 30) local loss: 0.7643\n",
      "  Client 31 (User 31) local loss: 0.8111\n",
      "  Client 32 (User 32) local loss: 0.8085\n",
      "  Client 33 (User 33) local loss: 0.8678\n",
      "  Client 34 (User 34) local loss: 0.8613\n",
      "  Client 35 (User 35) local loss: 0.8247\n",
      "  Client 36 (User 36) local loss: 0.8128\n",
      "  Client 37 (User 37) local loss: 0.7354\n",
      "  Client 38 (User 38) local loss: 0.8152\n",
      "  Client 39 (User 39) local loss: 0.8067\n",
      "  Client 40 (User 40) local loss: 0.7576\n",
      "  Client 41 (User 41) local loss: 0.7872\n",
      "  Client 42 (User 42) local loss: 0.7846\n",
      "  Client 43 (User 43) local loss: 0.7814\n",
      "  Client 44 (User 44) local loss: 0.8034\n",
      "  Client 45 (User 45) local loss: 0.7961\n",
      "  Client 46 (User 46) local loss: 0.7717\n",
      "  Client 47 (User 47) local loss: 0.7900\n",
      "  Client 48 (User 48) local loss: 0.7695\n",
      "  Client 49 (User 49) local loss: 0.7863\n",
      "  Client 50 (User 50) local loss: 0.8397\n",
      "  Client 51 (User 51) local loss: 0.7448\n",
      "  Client 52 (User 52) local loss: 0.7891\n",
      "  Client 53 (User 53) local loss: 0.8398\n",
      "  Client 54 (User 54) local loss: 0.7954\n",
      "  Client 55 (User 55) local loss: 0.8523\n",
      "  Client 56 (User 56) local loss: 0.7847\n",
      "  Client 57 (User 57) local loss: 0.8289\n",
      "  Client 58 (User 58) local loss: 0.8213\n",
      "  Client 59 (User 59) local loss: 0.8307\n",
      "  Client 60 (User 60) local loss: 0.8480\n",
      "  Client 61 (User 61) local loss: 0.8561\n",
      "  Client 62 (User 62) local loss: 0.7727\n",
      "  Client 63 (User 63) local loss: 0.7570\n",
      "  Client 64 (User 64) local loss: 0.8653\n",
      "  Client 65 (User 65) local loss: 0.7765\n",
      "  Client 66 (User 66) local loss: 0.7551\n",
      "  Client 67 (User 67) local loss: 0.8236\n",
      "  Client 68 (User 68) local loss: 0.7865\n",
      "  Client 69 (User 69) local loss: 0.8314\n",
      "  Client 70 (User 70) local loss: 0.8677\n",
      "  Client 71 (User 71) local loss: 0.7448\n",
      "  Client 72 (User 72) local loss: 0.7948\n",
      "  Client 73 (User 73) local loss: 0.7947\n",
      "  Client 74 (User 74) local loss: 0.7966\n",
      "  Client 75 (User 75) local loss: 0.7955\n",
      "  Client 76 (User 76) local loss: 0.8356\n",
      "  Client 77 (User 77) local loss: 0.8362\n",
      "  Client 78 (User 78) local loss: 0.8010\n",
      "  Client 79 (User 79) local loss: 0.8545\n",
      "  Client 80 (User 80) local loss: 0.8636\n",
      "  Client 81 (User 81) local loss: 0.7799\n",
      "  Client 82 (User 82) local loss: 0.8068\n",
      "  Client 83 (User 83) local loss: 0.8278\n",
      "  Client 84 (User 84) local loss: 0.8151\n",
      "  Client 85 (User 85) local loss: 0.8190\n",
      "  Client 86 (User 86) local loss: 0.7572\n",
      "  Client 87 (User 87) local loss: 0.8241\n",
      "  Client 88 (User 88) local loss: 0.7933\n",
      "  Client 89 (User 89) local loss: 0.7620\n",
      "  Client 90 (User 90) local loss: 0.8230\n",
      "  Client 91 (User 91) local loss: 0.7692\n",
      "  Client 92 (User 92) local loss: 0.8586\n",
      "  Client 93 (User 93) local loss: 0.9038\n",
      "  Client 94 (User 94) local loss: 0.7733\n",
      "  Client 95 (User 95) local loss: 0.8507\n",
      "  Client 96 (User 96) local loss: 0.8446\n",
      "  Client 97 (User 97) local loss: 0.7847\n",
      "  Client 98 (User 98) local loss: 0.7957\n",
      "  Client 99 (User 99) local loss: 0.8260\n",
      "Round 7 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 8/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7703\n",
      "  Client 1 (User 1) local loss: 0.8194\n",
      "  Client 2 (User 2) local loss: 0.8302\n",
      "  Client 3 (User 3) local loss: 0.7757\n",
      "  Client 4 (User 4) local loss: 0.7892\n",
      "  Client 5 (User 5) local loss: 0.7774\n",
      "  Client 6 (User 6) local loss: 0.8271\n",
      "  Client 7 (User 7) local loss: 0.8276\n",
      "  Client 8 (User 8) local loss: 0.7961\n",
      "  Client 9 (User 9) local loss: 0.7627\n",
      "  Client 10 (User 10) local loss: 0.8664\n",
      "  Client 11 (User 11) local loss: 0.8349\n",
      "  Client 12 (User 12) local loss: 0.7783\n",
      "  Client 13 (User 13) local loss: 0.8017\n",
      "  Client 14 (User 14) local loss: 0.7882\n",
      "  Client 15 (User 15) local loss: 0.7832\n",
      "  Client 16 (User 16) local loss: 0.8079\n",
      "  Client 17 (User 17) local loss: 0.7828\n",
      "  Client 18 (User 18) local loss: 0.8589\n",
      "  Client 19 (User 19) local loss: 0.8212\n",
      "  Client 20 (User 20) local loss: 0.8256\n",
      "  Client 21 (User 21) local loss: 0.8277\n",
      "  Client 22 (User 22) local loss: 0.8212\n",
      "  Client 23 (User 23) local loss: 0.8373\n",
      "  Client 24 (User 24) local loss: 0.7731\n",
      "  Client 25 (User 25) local loss: 0.7667\n",
      "  Client 26 (User 26) local loss: 0.7125\n",
      "  Client 27 (User 27) local loss: 0.8712\n",
      "  Client 28 (User 28) local loss: 0.8265\n",
      "  Client 29 (User 29) local loss: 0.7818\n",
      "  Client 30 (User 30) local loss: 0.7634\n",
      "  Client 31 (User 31) local loss: 0.8018\n",
      "  Client 32 (User 32) local loss: 0.8008\n",
      "  Client 33 (User 33) local loss: 0.8746\n",
      "  Client 34 (User 34) local loss: 0.8511\n",
      "  Client 35 (User 35) local loss: 0.8026\n",
      "  Client 36 (User 36) local loss: 0.8193\n",
      "  Client 37 (User 37) local loss: 0.7375\n",
      "  Client 38 (User 38) local loss: 0.7950\n",
      "  Client 39 (User 39) local loss: 0.8082\n",
      "  Client 40 (User 40) local loss: 0.7440\n",
      "  Client 41 (User 41) local loss: 0.7765\n",
      "  Client 42 (User 42) local loss: 0.7687\n",
      "  Client 43 (User 43) local loss: 0.7811\n",
      "  Client 44 (User 44) local loss: 0.7880\n",
      "  Client 45 (User 45) local loss: 0.7872\n",
      "  Client 46 (User 46) local loss: 0.7748\n",
      "  Client 47 (User 47) local loss: 0.7978\n",
      "  Client 48 (User 48) local loss: 0.7554\n",
      "  Client 49 (User 49) local loss: 0.7787\n",
      "  Client 50 (User 50) local loss: 0.8338\n",
      "  Client 51 (User 51) local loss: 0.7316\n",
      "  Client 52 (User 52) local loss: 0.7810\n",
      "  Client 53 (User 53) local loss: 0.8185\n",
      "  Client 54 (User 54) local loss: 0.7876\n",
      "  Client 55 (User 55) local loss: 0.8180\n",
      "  Client 56 (User 56) local loss: 0.7872\n",
      "  Client 57 (User 57) local loss: 0.8108\n",
      "  Client 58 (User 58) local loss: 0.8049\n",
      "  Client 59 (User 59) local loss: 0.8267\n",
      "  Client 60 (User 60) local loss: 0.8138\n",
      "  Client 61 (User 61) local loss: 0.8468\n",
      "  Client 62 (User 62) local loss: 0.7698\n",
      "  Client 63 (User 63) local loss: 0.7680\n",
      "  Client 64 (User 64) local loss: 0.8617\n",
      "  Client 65 (User 65) local loss: 0.7669\n",
      "  Client 66 (User 66) local loss: 0.7512\n",
      "  Client 67 (User 67) local loss: 0.8178\n",
      "  Client 68 (User 68) local loss: 0.7847\n",
      "  Client 69 (User 69) local loss: 0.8019\n",
      "  Client 70 (User 70) local loss: 0.8699\n",
      "  Client 71 (User 71) local loss: 0.7619\n",
      "  Client 72 (User 72) local loss: 0.7857\n",
      "  Client 73 (User 73) local loss: 0.7972\n",
      "  Client 74 (User 74) local loss: 0.8000\n",
      "  Client 75 (User 75) local loss: 0.8048\n",
      "  Client 76 (User 76) local loss: 0.8219\n",
      "  Client 77 (User 77) local loss: 0.8178\n",
      "  Client 78 (User 78) local loss: 0.7873\n",
      "  Client 79 (User 79) local loss: 0.8360\n",
      "  Client 80 (User 80) local loss: 0.8537\n",
      "  Client 81 (User 81) local loss: 0.7783\n",
      "  Client 82 (User 82) local loss: 0.7974\n",
      "  Client 83 (User 83) local loss: 0.8103\n",
      "  Client 84 (User 84) local loss: 0.8010\n",
      "  Client 85 (User 85) local loss: 0.8040\n",
      "  Client 86 (User 86) local loss: 0.7533\n",
      "  Client 87 (User 87) local loss: 0.8184\n",
      "  Client 88 (User 88) local loss: 0.7945\n",
      "  Client 89 (User 89) local loss: 0.7472\n",
      "  Client 90 (User 90) local loss: 0.7992\n",
      "  Client 91 (User 91) local loss: 0.7651\n",
      "  Client 92 (User 92) local loss: 0.8548\n",
      "  Client 93 (User 93) local loss: 0.8907\n",
      "  Client 94 (User 94) local loss: 0.7741\n",
      "  Client 95 (User 95) local loss: 0.8622\n",
      "  Client 96 (User 96) local loss: 0.8535\n",
      "  Client 97 (User 97) local loss: 0.8015\n",
      "  Client 98 (User 98) local loss: 0.7861\n",
      "  Client 99 (User 99) local loss: 0.8211\n",
      "Round 8 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 9/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7729\n",
      "  Client 1 (User 1) local loss: 0.8210\n",
      "  Client 2 (User 2) local loss: 0.7963\n",
      "  Client 3 (User 3) local loss: 0.7723\n",
      "  Client 4 (User 4) local loss: 0.7801\n",
      "  Client 5 (User 5) local loss: 0.7729\n",
      "  Client 6 (User 6) local loss: 0.8306\n",
      "  Client 7 (User 7) local loss: 0.8003\n",
      "  Client 8 (User 8) local loss: 0.7927\n",
      "  Client 9 (User 9) local loss: 0.7402\n",
      "  Client 10 (User 10) local loss: 0.8613\n",
      "  Client 11 (User 11) local loss: 0.8086\n",
      "  Client 12 (User 12) local loss: 0.7645\n",
      "  Client 13 (User 13) local loss: 0.7724\n",
      "  Client 14 (User 14) local loss: 0.7885\n",
      "  Client 15 (User 15) local loss: 0.7621\n",
      "  Client 16 (User 16) local loss: 0.8077\n",
      "  Client 17 (User 17) local loss: 0.7766\n",
      "  Client 18 (User 18) local loss: 0.8507\n",
      "  Client 19 (User 19) local loss: 0.7835\n",
      "  Client 20 (User 20) local loss: 0.8211\n",
      "  Client 21 (User 21) local loss: 0.8220\n",
      "  Client 22 (User 22) local loss: 0.8263\n",
      "  Client 23 (User 23) local loss: 0.8185\n",
      "  Client 24 (User 24) local loss: 0.7444\n",
      "  Client 25 (User 25) local loss: 0.7596\n",
      "  Client 26 (User 26) local loss: 0.7343\n",
      "  Client 27 (User 27) local loss: 0.8669\n",
      "  Client 28 (User 28) local loss: 0.8353\n",
      "  Client 29 (User 29) local loss: 0.7720\n",
      "  Client 30 (User 30) local loss: 0.7606\n",
      "  Client 31 (User 31) local loss: 0.7963\n",
      "  Client 32 (User 32) local loss: 0.7872\n",
      "  Client 33 (User 33) local loss: 0.8478\n",
      "  Client 34 (User 34) local loss: 0.8535\n",
      "  Client 35 (User 35) local loss: 0.7976\n",
      "  Client 36 (User 36) local loss: 0.8116\n",
      "  Client 37 (User 37) local loss: 0.7315\n",
      "  Client 38 (User 38) local loss: 0.7873\n",
      "  Client 39 (User 39) local loss: 0.7920\n",
      "  Client 40 (User 40) local loss: 0.7378\n",
      "  Client 41 (User 41) local loss: 0.7578\n",
      "  Client 42 (User 42) local loss: 0.7865\n",
      "  Client 43 (User 43) local loss: 0.7738\n",
      "  Client 44 (User 44) local loss: 0.8025\n",
      "  Client 45 (User 45) local loss: 0.7942\n",
      "  Client 46 (User 46) local loss: 0.7618\n",
      "  Client 47 (User 47) local loss: 0.8047\n",
      "  Client 48 (User 48) local loss: 0.7535\n",
      "  Client 49 (User 49) local loss: 0.7535\n",
      "  Client 50 (User 50) local loss: 0.8307\n",
      "  Client 51 (User 51) local loss: 0.7426\n",
      "  Client 52 (User 52) local loss: 0.7600\n",
      "  Client 53 (User 53) local loss: 0.8085\n",
      "  Client 54 (User 54) local loss: 0.7794\n",
      "  Client 55 (User 55) local loss: 0.7988\n",
      "  Client 56 (User 56) local loss: 0.7793\n",
      "  Client 57 (User 57) local loss: 0.8003\n",
      "  Client 58 (User 58) local loss: 0.7787\n",
      "  Client 59 (User 59) local loss: 0.8191\n",
      "  Client 60 (User 60) local loss: 0.8245\n",
      "  Client 61 (User 61) local loss: 0.8459\n",
      "  Client 62 (User 62) local loss: 0.7653\n",
      "  Client 63 (User 63) local loss: 0.7359\n",
      "  Client 64 (User 64) local loss: 0.8340\n",
      "  Client 65 (User 65) local loss: 0.7627\n",
      "  Client 66 (User 66) local loss: 0.7367\n",
      "  Client 67 (User 67) local loss: 0.7987\n",
      "  Client 68 (User 68) local loss: 0.7815\n",
      "  Client 69 (User 69) local loss: 0.8347\n",
      "  Client 70 (User 70) local loss: 0.8613\n",
      "  Client 71 (User 71) local loss: 0.7531\n",
      "  Client 72 (User 72) local loss: 0.7865\n",
      "  Client 73 (User 73) local loss: 0.7771\n",
      "  Client 74 (User 74) local loss: 0.7874\n",
      "  Client 75 (User 75) local loss: 0.7880\n",
      "  Client 76 (User 76) local loss: 0.8611\n",
      "  Client 77 (User 77) local loss: 0.8027\n",
      "  Client 78 (User 78) local loss: 0.7876\n",
      "  Client 79 (User 79) local loss: 0.8503\n",
      "  Client 80 (User 80) local loss: 0.8468\n",
      "  Client 81 (User 81) local loss: 0.7497\n",
      "  Client 82 (User 82) local loss: 0.7684\n",
      "  Client 83 (User 83) local loss: 0.7871\n",
      "  Client 84 (User 84) local loss: 0.7869\n",
      "  Client 85 (User 85) local loss: 0.7981\n",
      "  Client 86 (User 86) local loss: 0.7458\n",
      "  Client 87 (User 87) local loss: 0.8193\n",
      "  Client 88 (User 88) local loss: 0.7808\n",
      "  Client 89 (User 89) local loss: 0.7476\n",
      "  Client 90 (User 90) local loss: 0.7858\n",
      "  Client 91 (User 91) local loss: 0.7543\n",
      "  Client 92 (User 92) local loss: 0.8421\n",
      "  Client 93 (User 93) local loss: 0.8698\n",
      "  Client 94 (User 94) local loss: 0.7593\n",
      "  Client 95 (User 95) local loss: 0.8607\n",
      "  Client 96 (User 96) local loss: 0.8241\n",
      "  Client 97 (User 97) local loss: 0.7843\n",
      "  Client 98 (User 98) local loss: 0.7631\n",
      "  Client 99 (User 99) local loss: 0.7999\n",
      "Round 9 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 10/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7571\n",
      "  Client 1 (User 1) local loss: 0.8043\n",
      "  Client 2 (User 2) local loss: 0.7836\n",
      "  Client 3 (User 3) local loss: 0.7558\n",
      "  Client 4 (User 4) local loss: 0.7760\n",
      "  Client 5 (User 5) local loss: 0.7625\n",
      "  Client 6 (User 6) local loss: 0.8262\n",
      "  Client 7 (User 7) local loss: 0.7989\n",
      "  Client 8 (User 8) local loss: 0.7869\n",
      "  Client 9 (User 9) local loss: 0.7302\n",
      "  Client 10 (User 10) local loss: 0.8231\n",
      "  Client 11 (User 11) local loss: 0.8342\n",
      "  Client 12 (User 12) local loss: 0.7616\n",
      "  Client 13 (User 13) local loss: 0.7888\n",
      "  Client 14 (User 14) local loss: 0.7801\n",
      "  Client 15 (User 15) local loss: 0.7567\n",
      "  Client 16 (User 16) local loss: 0.7838\n",
      "  Client 17 (User 17) local loss: 0.7654\n",
      "  Client 18 (User 18) local loss: 0.8303\n",
      "  Client 19 (User 19) local loss: 0.7933\n",
      "  Client 20 (User 20) local loss: 0.8109\n",
      "  Client 21 (User 21) local loss: 0.8155\n",
      "  Client 22 (User 22) local loss: 0.8084\n",
      "  Client 23 (User 23) local loss: 0.8306\n",
      "  Client 24 (User 24) local loss: 0.7350\n",
      "  Client 25 (User 25) local loss: 0.7771\n",
      "  Client 26 (User 26) local loss: 0.7115\n",
      "  Client 27 (User 27) local loss: 0.8680\n",
      "  Client 28 (User 28) local loss: 0.8290\n",
      "  Client 29 (User 29) local loss: 0.7565\n",
      "  Client 30 (User 30) local loss: 0.7568\n",
      "  Client 31 (User 31) local loss: 0.7974\n",
      "  Client 32 (User 32) local loss: 0.7945\n",
      "  Client 33 (User 33) local loss: 0.8677\n",
      "  Client 34 (User 34) local loss: 0.8590\n",
      "  Client 35 (User 35) local loss: 0.7800\n",
      "  Client 36 (User 36) local loss: 0.7909\n",
      "  Client 37 (User 37) local loss: 0.7155\n",
      "  Client 38 (User 38) local loss: 0.7737\n",
      "  Client 39 (User 39) local loss: 0.7835\n",
      "  Client 40 (User 40) local loss: 0.7291\n",
      "  Client 41 (User 41) local loss: 0.7537\n",
      "  Client 42 (User 42) local loss: 0.7746\n",
      "  Client 43 (User 43) local loss: 0.7634\n",
      "  Client 44 (User 44) local loss: 0.8010\n",
      "  Client 45 (User 45) local loss: 0.7756\n",
      "  Client 46 (User 46) local loss: 0.7469\n",
      "  Client 47 (User 47) local loss: 0.7682\n",
      "  Client 48 (User 48) local loss: 0.7350\n",
      "  Client 49 (User 49) local loss: 0.7461\n",
      "  Client 50 (User 50) local loss: 0.8196\n",
      "  Client 51 (User 51) local loss: 0.7395\n",
      "  Client 52 (User 52) local loss: 0.7687\n",
      "  Client 53 (User 53) local loss: 0.8039\n",
      "  Client 54 (User 54) local loss: 0.7722\n",
      "  Client 55 (User 55) local loss: 0.7764\n",
      "  Client 56 (User 56) local loss: 0.7857\n",
      "  Client 57 (User 57) local loss: 0.7886\n",
      "  Client 58 (User 58) local loss: 0.7699\n",
      "  Client 59 (User 59) local loss: 0.8141\n",
      "  Client 60 (User 60) local loss: 0.8183\n",
      "  Client 61 (User 61) local loss: 0.8336\n",
      "  Client 62 (User 62) local loss: 0.7622\n",
      "  Client 63 (User 63) local loss: 0.7389\n",
      "  Client 64 (User 64) local loss: 0.8209\n",
      "  Client 65 (User 65) local loss: 0.7521\n",
      "  Client 66 (User 66) local loss: 0.7211\n",
      "  Client 67 (User 67) local loss: 0.8056\n",
      "  Client 68 (User 68) local loss: 0.7813\n",
      "  Client 69 (User 69) local loss: 0.8052\n",
      "  Client 70 (User 70) local loss: 0.8614\n",
      "  Client 71 (User 71) local loss: 0.7451\n",
      "  Client 72 (User 72) local loss: 0.7807\n",
      "  Client 73 (User 73) local loss: 0.7617\n",
      "  Client 74 (User 74) local loss: 0.7646\n",
      "  Client 75 (User 75) local loss: 0.7911\n",
      "  Client 76 (User 76) local loss: 0.8407\n",
      "  Client 77 (User 77) local loss: 0.7878\n",
      "  Client 78 (User 78) local loss: 0.7869\n",
      "  Client 79 (User 79) local loss: 0.8355\n",
      "  Client 80 (User 80) local loss: 0.8392\n",
      "  Client 81 (User 81) local loss: 0.7590\n",
      "  Client 82 (User 82) local loss: 0.7434\n",
      "  Client 83 (User 83) local loss: 0.7671\n",
      "  Client 84 (User 84) local loss: 0.8127\n",
      "  Client 85 (User 85) local loss: 0.7850\n",
      "  Client 86 (User 86) local loss: 0.7338\n",
      "  Client 87 (User 87) local loss: 0.8006\n",
      "  Client 88 (User 88) local loss: 0.7981\n",
      "  Client 89 (User 89) local loss: 0.7393\n",
      "  Client 90 (User 90) local loss: 0.7956\n",
      "  Client 91 (User 91) local loss: 0.7412\n",
      "  Client 92 (User 92) local loss: 0.8187\n",
      "  Client 93 (User 93) local loss: 0.8624\n",
      "  Client 94 (User 94) local loss: 0.7552\n",
      "  Client 95 (User 95) local loss: 0.8395\n",
      "  Client 96 (User 96) local loss: 0.8366\n",
      "  Client 97 (User 97) local loss: 0.7677\n",
      "  Client 98 (User 98) local loss: 0.7618\n",
      "  Client 99 (User 99) local loss: 0.7857\n",
      "Round 10 completed. Global item embeddings updated.\n",
      "Federated training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 軽量 LLM 埋め込みモデルのロード (変更なし)\n",
    "plm_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "plm_tokenizer = AutoTokenizer.from_pretrained(plm_model_name)\n",
    "plm_model = AutoModel.from_pretrained(plm_model_name)\n",
    "\n",
    "# PLMは学習済みモデルのため、勾配計算を無効化\n",
    "for param in plm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "plm_embedding_dim = plm_model.config.hidden_size\n",
    "print(f\"PLM embedding dimension: {plm_embedding_dim}\")\n",
    "\n",
    "\n",
    "class ClientModel(nn.Module):\n",
    "    def __init__(self, num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.plm_model = plm_model\n",
    "        \n",
    "        # Joint Embedding Layer (module parameter θ_user)\n",
    "        self.user_joint_embedding_linear = nn.Linear(plm_embedding_dim, joint_embedding_output_dim)\n",
    "        \n",
    "        # Item Embedding Layer (module parameter θ_item)\n",
    "        self.local_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        # User Feature Refinement MLP (module parameter θ_umlp)\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(joint_embedding_output_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "        # Predictive Scoring Function (module parameter θ_score)\n",
    "        self.prediction_mlp = nn.Sequential(\n",
    "            nn.Linear(item_embedding_dim + joint_embedding_output_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, item_ids, user_texts_batch): \n",
    "        encoded_input = plm_tokenizer(user_texts_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        plm_output = self.plm_model(**encoded_input).last_hidden_state[:, 0, :]\n",
    "\n",
    "        user_raw_embedding = self.user_joint_embedding_linear(plm_output)\n",
    "        user_embedding = self.user_mlp(user_raw_embedding)\n",
    "\n",
    "        item_embedding = self.local_item_embedding(item_ids)\n",
    "\n",
    "        combined_features = torch.cat((user_embedding, item_embedding), dim=1)\n",
    "        logits = self.prediction_mlp(combined_features)\n",
    "        predictions = torch.sigmoid(logits)\n",
    "\n",
    "        return predictions, self.user_joint_embedding_linear.weight, self.local_item_embedding.weight\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, num_users, num_items, item_embedding_dim, joint_embedding_output_dim):\n",
    "        self.global_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "        # サーバーのグローバルアイテム埋め込みのためのオプティマイザ\n",
    "        # 学習率 (lr) はクライアントとは別に設定可能\n",
    "        self.global_item_optimizer = optim.Adam(self.global_item_embedding.parameters(), lr=0.01) # サーバー側の学習率\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        self.joint_embedding_output_dim = joint_embedding_output_dim\n",
    "    \n",
    "    def build_user_relationship_graph(self, user_linear_weights_map):\n",
    "        sorted_user_ids = sorted(user_linear_weights_map.keys())\n",
    "        if not sorted_user_ids:\n",
    "            return np.zeros((0, 0)), []\n",
    "\n",
    "        user_weight_vectors = np.array([\n",
    "            user_linear_weights_map[u_id].cpu().numpy() for u_id in sorted_user_ids\n",
    "        ])\n",
    "\n",
    "        similarity_matrix = cosine_similarity(user_weight_vectors)\n",
    "        user_graph_adj = similarity_matrix \n",
    "        \n",
    "        return user_graph_adj, sorted_user_ids\n",
    "\n",
    "    def update_global_item_embedding(self, user_local_item_weights, user_graph_adj, sorted_user_ids, client_data_sizes):\n",
    "        \"\"\"\n",
    "        ユーザー関係グラフに基づいてアイテム埋め込みを集約し、サーバーのオプティマイザでグローバル埋め込みを学習・更新します。\n",
    "        \n",
    "        Args:\n",
    "            user_local_item_weights (dict): {user_id: local_item_embedding.weight.data (Tensor)}\n",
    "            user_graph_adj (np.ndarray): ユーザーグラフの隣接行列\n",
    "            sorted_user_ids (list): user_graph_adj のノード順に対応するユーザーIDのリスト\n",
    "            client_data_sizes (dict): {user_id: そのユーザーのデータセットサイズ}\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: 更新されたグローバルアイテム埋め込みの重み\n",
    "        \"\"\"\n",
    "        if not user_local_item_weights:\n",
    "            return self.global_item_embedding.weight.data\n",
    "\n",
    "        item_embedding_matrix_A = torch.stack([\n",
    "            user_local_item_weights[u_id] for u_id in sorted_user_ids\n",
    "        ]) # (num_users, num_items, item_embedding_dim)\n",
    "\n",
    "        row_sums_graph = np.sum(user_graph_adj, axis=1, keepdims=True)\n",
    "        row_sums_graph[row_sums_graph == 0] = 1 \n",
    "        normalized_user_graph_adj = user_graph_adj / row_sums_graph\n",
    "        \n",
    "        normalized_user_graph_adj_tensor = torch.tensor(normalized_user_graph_adj, dtype=torch.float32)\n",
    "\n",
    "        R_tensor = torch.einsum('ij, jkd -> ikd', normalized_user_graph_adj_tensor, item_embedding_matrix_A)\n",
    "\n",
    "        # FedAvg: D = degree matrix at the time of aggregation\n",
    "        total_data_size = sum(client_data_sizes[u_id] for u_id in sorted_user_ids)\n",
    "        if total_data_size == 0:\n",
    "            return self.global_item_embedding.weight.data \n",
    "\n",
    "        weighted_sum_item_embeddings = torch.zeros_like(self.global_item_embedding.weight) # .dataは使わない\n",
    "        \n",
    "        for i, u_id in enumerate(sorted_user_ids):\n",
    "            weight = client_data_sizes[u_id] / total_data_size\n",
    "            weighted_sum_item_embeddings += weight * R_tensor[i]\n",
    "\n",
    "        # ここで、サーバーのグローバルアイテム埋め込みを学習させる\n",
    "        self.global_item_optimizer.zero_grad()\n",
    "        \n",
    "        # 現在のグローバル埋め込みと目標値 (weighted_sum_item_embeddings) との間のロスを計算\n",
    "        # MSELoss を使用して、目標値に近づけるように学習\n",
    "        loss_fn = nn.MSELoss()\n",
    "        # detach()を使ってweighted_sum_item_embeddingsからの勾配伝播は行わない\n",
    "        # サーバーがこの目標値に向けて自身を更新するイメージ\n",
    "        loss = loss_fn(self.global_item_embedding.weight, weighted_sum_item_embeddings.detach())\n",
    "        \n",
    "        loss.backward() # 勾配を計算\n",
    "        self.global_item_optimizer.step() # パラメータを更新\n",
    "        \n",
    "        return self.global_item_embedding.weight.data # 更新後のデータを返す\n",
    "\n",
    "# データセットの準備とクライアントへの分割 (1クライアント1ユーザー)\n",
    "num_users = 100\n",
    "num_items = 50\n",
    "num_clients = num_users \n",
    "\n",
    "user_texts = {i: f\"This user likes movies about {i % 5} and enjoys {i % 3}.\" for i in range(num_users)}\n",
    "\n",
    "interactions_list = []\n",
    "user_interaction_history = defaultdict(list) \n",
    "\n",
    "for u_id in range(num_users):\n",
    "    for i_id in range(num_items):\n",
    "        if np.random.rand() > 0.7:\n",
    "            interactions_list.append([u_id, i_id, 1])\n",
    "            user_interaction_history[u_id].append(i_id) \n",
    "        else:\n",
    "            interactions_list.append([u_id, i_id, 0])\n",
    "\n",
    "interactions = torch.tensor(interactions_list, dtype=torch.float32)\n",
    "\n",
    "client_user_map = {} \n",
    "client_datasets = {}\n",
    "client_original_data_sizes = {} \n",
    "for u_id in range(num_users):\n",
    "    client_id = u_id \n",
    "    client_user_map[client_id] = u_id \n",
    "    \n",
    "    client_interactions_indices = [i for i, (u, _, _) in enumerate(interactions_list) if u == u_id]\n",
    "    \n",
    "    if not client_interactions_indices:\n",
    "        print(f\"Warning: User {u_id} has no interactions. Client {client_id} will have an empty dataset.\")\n",
    "        client_subset = TensorDataset(\n",
    "            torch.empty(0, dtype=torch.long), \n",
    "            torch.empty(0, dtype=torch.long), \n",
    "            torch.empty(0, dtype=torch.float32)\n",
    "        )\n",
    "        client_original_data_sizes[client_id] = 0\n",
    "    else:\n",
    "        user_interaction_data_for_client = []\n",
    "        for idx in client_interactions_indices:\n",
    "            u_id_data, i_id_data, label_data = interactions_list[idx]\n",
    "            user_interaction_data_for_client.append((u_id_data, i_id_data, label_data))\n",
    "\n",
    "        users_tensor = torch.tensor([d[0] for d in user_interaction_data_for_client], dtype=torch.long)\n",
    "        items_tensor = torch.tensor([d[1] for d in user_interaction_data_for_client], dtype=torch.long)\n",
    "        labels_tensor = torch.tensor([d[2] for d in user_interaction_data_for_client], dtype=torch.float32)\n",
    "\n",
    "        client_subset = TensorDataset(users_tensor, items_tensor, labels_tensor)\n",
    "        client_original_data_sizes[client_id] = len(client_subset)\n",
    "    \n",
    "    client_datasets[client_id] = DataLoader(client_subset, batch_size=min(32, max(1, len(client_subset))), shuffle=True)\n",
    "\n",
    "print(f\"Number of users: {num_users}\")\n",
    "print(f\"Number of items: {num_items}\")\n",
    "print(f\"Total interactions: {len(interactions)}\")\n",
    "print(f\"Number of clients (1 client per user): {num_clients}\")\n",
    "\n",
    "\n",
    "# モデルのハイパーパラメータ\n",
    "item_embedding_dim = 32\n",
    "joint_embedding_output_dim = 32 \n",
    "\n",
    "# サーバーのインスタンス化\n",
    "server = Server(num_users, num_items, item_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "# 各クライアントのモデルを辞書で保持\n",
    "client_models = {}\n",
    "client_optimizers = {}\n",
    "for client_id in range(num_clients):\n",
    "    client_models[client_id] = ClientModel(\n",
    "        num_items,\n",
    "        item_embedding_dim,\n",
    "        plm_model,\n",
    "        plm_embedding_dim,\n",
    "        joint_embedding_output_dim\n",
    "    )\n",
    "    # NOTE:\n",
    "    # クライアントごとに最適化するパラメータを設定\n",
    "    # ここでは、user_joint_embedding_linear, local_item_embedding, prediction_layer が対象\n",
    "    # 単純にoptim.Adam(params = client_models[client_id].parameters(), lr=0.001)とすると、\n",
    "    # PLMも学習可能パラメータとなってしまうので、\n",
    "    # PLMのパラメータを除外したパラメータのみを取得してから、設定する.\n",
    "    trainable_params = [\n",
    "        p for name, p in client_models[client_id].named_parameters()\n",
    "        if not name.startswith('plm_model.')\n",
    "    ]\n",
    "\n",
    "    client_optimizers[client_id] = optim.Adam(\n",
    "        params=trainable_params,\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "# 学習ループ (フェデレーテッド学習ラウンド)\n",
    "num_communication_rounds = 10\n",
    "local_epochs = 1 \n",
    "\n",
    "for round_num in range(num_communication_rounds):\n",
    "    print(f\"\\n--- Communication Round {round_num + 1}/{num_communication_rounds} ---\")\n",
    "    \n",
    "    # サーバーからグローバルアイテム埋め込みをクライアントに配布\n",
    "    for client_id in range(num_clients):\n",
    "        client_models[client_id].local_item_embedding.weight.data.copy_(server.global_item_embedding.weight.data)\n",
    "\n",
    "    user_linear_weights_for_graph = {} \n",
    "    user_local_item_weights_to_server = {} \n",
    "    client_reported_data_sizes = {} \n",
    "    \n",
    "    # クライアントのローカル学習\n",
    "    for client_id in range(num_clients):\n",
    "        model = client_models[client_id]\n",
    "        optimizer = client_optimizers[client_id]\n",
    "        dataloader = client_datasets[client_id]\n",
    "        \n",
    "        model.train()\n",
    "        local_loss = 0\n",
    "        \n",
    "        current_user_id = client_user_map[client_id] \n",
    "        \n",
    "        client_reported_data_sizes[current_user_id] = client_original_data_sizes[client_id]\n",
    "\n",
    "        if len(dataloader.dataset) == 0:\n",
    "            print(f\"  Client {client_id} (User {current_user_id}) has no interactions, skipping local training.\")\n",
    "            user_linear_weights_for_graph[current_user_id] = model.user_joint_embedding_linear.weight.data.clone().flatten()\n",
    "            user_local_item_weights_to_server[current_user_id] = model.local_item_embedding.weight.data.clone()\n",
    "            continue\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            for user_ids_batch, item_ids_batch, labels_batch in dataloader:\n",
    "                assert torch.all(user_ids_batch == current_user_id) \n",
    "                current_user_texts = [user_texts[uid.item()] for uid in user_ids_batch]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions, user_joint_embedding_linear_weight, local_item_embedding_weight = model(\n",
    "                    user_ids_batch, item_ids_batch, current_user_texts\n",
    "                )\n",
    "                \n",
    "                loss = nn.BCEWithLogitsLoss()(predictions.squeeze(), labels_batch)\n",
    "                \n",
    "                lambda_reg = 0.01 \n",
    "                \n",
    "                # Note: `local_item_embedding_weight` は `requires_grad=True` ですが、\n",
    "                # `server.global_item_embedding.weight.data` は `requires_grad=False` です。\n",
    "                # このため、`regularization_term` の勾配は `local_item_embedding_weight` にのみ伝播します。\n",
    "                # これは意図された動作です。\n",
    "                regularization_term = torch.mean(\n",
    "                    (local_item_embedding_weight - server.global_item_embedding.weight.data)**2\n",
    "                )\n",
    "                \n",
    "                loss = loss + lambda_reg * regularization_term\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                local_loss += loss.item()\n",
    "\n",
    "        user_linear_weights_for_graph[current_user_id] = user_joint_embedding_linear_weight.data.clone().flatten()\n",
    "        user_local_item_weights_to_server[current_user_id] = local_item_embedding_weight.data.clone()\n",
    "\n",
    "        print(f\"  Client {client_id} (User {current_user_id}) local loss: {local_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # サーバーでの処理\n",
    "    user_graph_adj, sorted_user_ids_for_graph = server.build_user_relationship_graph(\n",
    "        user_linear_weights_for_graph\n",
    "    )\n",
    "    \n",
    "    # グローバルアイテム埋め込みの更新を、サーバーのオプティマイザで行う関数を呼び出す\n",
    "    server.update_global_item_embedding(\n",
    "        user_local_item_weights_to_server, \n",
    "        user_graph_adj, \n",
    "        sorted_user_ids_for_graph,\n",
    "        client_reported_data_sizes \n",
    "    )\n",
    "\n",
    "    print(f\"Round {round_num + 1} completed. Global item embeddings updated.\")\n",
    "\n",
    "print(\"Federated training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-UD7q69fU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
