{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410653fb",
   "metadata": {},
   "source": [
    "005に対して以下の変更を入れた。\n",
    "\n",
    "承知いたしました。「サーバーのグローバルアイテム埋め込みを直接更新」するのではなく、サーバー側でオプティマイザを使って「学習」させる形に修正を加えます。\n",
    "\n",
    "この変更により、サーバーの`global_item_embedding`は、勾配降下法によって更新される通常のPyTorchモジュールのパラメータとして扱われるようになります。\n",
    "\n",
    "**主な変更点:**\n",
    "\n",
    "1.  **`Server` クラスにオプティマイザを追加**: `__init__` メソッドで `self.global_item_optimizer` を初期化します。\n",
    "\n",
    "2.  **`aggregate_item_embeddings` 関数を修正**:\n",
    "\n",
    "      * この関数は、グラフ畳み込みとFedAvgによる加重平均の結果として得られた `new_global_item_embedding_weight` を直接 `copy_` するのではなく、サーバーのオプティマイザが最適化するための「ターゲット」または「参照」として利用します。\n",
    "      * **重要な概念**: Federated Learningにおけるサーバー側の更新は、ローカルモデルの平均化が「サーバーモデルの勾配」と見なされることが多いです。ここでは、`R_tensor` から得られた `new_global_item_embedding_weight` を、サーバーの`global_item_embedding`が目指すべき理想的な状態として扱い、その状態に近づくようにオプティマイザを動かす、という解釈を取ります。\n",
    "      * ただし、PyTorchの通常の学習ループでは、損失を計算し、`backward()` を呼び出して勾配を計算し、`optimizer.step()` でパラメータを更新します。サーバー側での「学習」を厳密に再現するには、`new_global_item_embedding_weight` を用いて何らかの「損失」を定義し、それを最小化する形で`global_item_embedding`を更新する必要があります。\n",
    "\n",
    "    最もシンプルで一般的なアプローチは、FedAvgにおける「サーバーモデルは、クライアントモデルの重み付き平均に更新される」という概念をPyTorchの最適化パスに変換することです。これは通常、以下のように行われます。\n",
    "\n",
    "      * サーバーのオプティマイザの勾配をゼロにする。\n",
    "      * サーバーの`global_item_embedding`の現在の重みと、クライアントから集約された新しいターゲット重みとの間の「差」を損失として扱う（例えば、MSEロス）。\n",
    "      * この損失に基づいて勾配を計算し、オプティマイザでステップを実行する。\n",
    "\n",
    "    しかし、論文の文脈では、この「学習」は必ずしも厳密な意味でのロス最小化を伴うとは限りません。FedAvgの多くは、単に重み付き平均を計算して直接適用します。そこで、今回は`optimizer.step()`を利用しつつ、**グラフ集約された結果をサーバーモデルが「学習」する**という解釈を強調するために、`new_global_item_embedding_weight`をターゲットとして、サーバーの埋め込みを更新する形にします。\n",
    "\n",
    "    **より実践的なアプローチ**: グローバルアイテム埋め込みを直接最適化するには、集約された `new_global_item_embedding_weight` を「擬似的な勾配」として利用するか、あるいはそれを「ターゲット」として、現在の `self.global_item_embedding.weight` との差分を損失として最適化する方法が考えられます。後者の方法を採用します。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2443e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embedding dimension: 384\n",
      "Number of users: 100\n",
      "Number of items: 50\n",
      "Total interactions: 5000\n",
      "Number of clients (1 client per user): 100\n",
      "\n",
      "--- Communication Round 1/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6973\n",
      "  Client 1 (User 1) local loss: 0.6308\n",
      "  Client 2 (User 2) local loss: 0.7723\n",
      "  Client 3 (User 3) local loss: 0.6414\n",
      "  Client 4 (User 4) local loss: 0.7141\n",
      "  Client 5 (User 5) local loss: 0.6628\n",
      "  Client 6 (User 6) local loss: 0.6346\n",
      "  Client 7 (User 7) local loss: 0.6773\n",
      "  Client 8 (User 8) local loss: 0.6707\n",
      "  Client 9 (User 9) local loss: 0.7314\n",
      "  Client 10 (User 10) local loss: 0.6869\n",
      "  Client 11 (User 11) local loss: 0.6752\n",
      "  Client 12 (User 12) local loss: 0.7447\n",
      "  Client 13 (User 13) local loss: 0.6484\n",
      "  Client 14 (User 14) local loss: 0.7786\n",
      "  Client 15 (User 15) local loss: 0.6727\n",
      "  Client 16 (User 16) local loss: 0.6882\n",
      "  Client 17 (User 17) local loss: 0.6948\n",
      "  Client 18 (User 18) local loss: 0.7436\n",
      "  Client 19 (User 19) local loss: 0.7568\n",
      "  Client 20 (User 20) local loss: 0.7391\n",
      "  Client 21 (User 21) local loss: 0.7254\n",
      "  Client 22 (User 22) local loss: 0.7001\n",
      "  Client 23 (User 23) local loss: 0.7259\n",
      "  Client 24 (User 24) local loss: 0.6972\n",
      "  Client 25 (User 25) local loss: 0.6742\n",
      "  Client 26 (User 26) local loss: 0.6320\n",
      "  Client 27 (User 27) local loss: 0.6401\n",
      "  Client 28 (User 28) local loss: 0.6912\n",
      "  Client 29 (User 29) local loss: 0.6708\n",
      "  Client 30 (User 30) local loss: 0.7501\n",
      "  Client 31 (User 31) local loss: 0.6657\n",
      "  Client 32 (User 32) local loss: 0.6892\n",
      "  Client 33 (User 33) local loss: 0.6714\n",
      "  Client 34 (User 34) local loss: 0.6821\n",
      "  Client 35 (User 35) local loss: 0.6328\n",
      "  Client 36 (User 36) local loss: 0.6611\n",
      "  Client 37 (User 37) local loss: 0.7479\n",
      "  Client 38 (User 38) local loss: 0.6469\n",
      "  Client 39 (User 39) local loss: 0.7521\n",
      "  Client 40 (User 40) local loss: 0.6290\n",
      "  Client 41 (User 41) local loss: 0.7106\n",
      "  Client 42 (User 42) local loss: 0.6413\n",
      "  Client 43 (User 43) local loss: 0.6154\n",
      "  Client 44 (User 44) local loss: 0.7045\n",
      "  Client 45 (User 45) local loss: 0.7097\n",
      "  Client 46 (User 46) local loss: 0.7314\n",
      "  Client 47 (User 47) local loss: 0.7327\n",
      "  Client 48 (User 48) local loss: 0.6126\n",
      "  Client 49 (User 49) local loss: 0.6709\n",
      "  Client 50 (User 50) local loss: 0.6739\n",
      "  Client 51 (User 51) local loss: 0.7278\n",
      "  Client 52 (User 52) local loss: 0.6445\n",
      "  Client 53 (User 53) local loss: 0.7788\n",
      "  Client 54 (User 54) local loss: 0.6353\n",
      "  Client 55 (User 55) local loss: 0.6343\n",
      "  Client 56 (User 56) local loss: 0.6447\n",
      "  Client 57 (User 57) local loss: 0.6494\n",
      "  Client 58 (User 58) local loss: 0.6909\n",
      "  Client 59 (User 59) local loss: 0.6417\n",
      "  Client 60 (User 60) local loss: 0.7471\n",
      "  Client 61 (User 61) local loss: 0.6728\n",
      "  Client 62 (User 62) local loss: 0.6627\n",
      "  Client 63 (User 63) local loss: 0.6720\n",
      "  Client 64 (User 64) local loss: 0.6601\n",
      "  Client 65 (User 65) local loss: 0.6401\n",
      "  Client 66 (User 66) local loss: 0.7079\n",
      "  Client 67 (User 67) local loss: 0.6927\n",
      "  Client 68 (User 68) local loss: 0.6191\n",
      "  Client 69 (User 69) local loss: 0.7092\n",
      "  Client 70 (User 70) local loss: 0.6987\n",
      "  Client 71 (User 71) local loss: 0.7532\n",
      "  Client 72 (User 72) local loss: 0.6427\n",
      "  Client 73 (User 73) local loss: 0.6512\n",
      "  Client 74 (User 74) local loss: 0.6912\n",
      "  Client 75 (User 75) local loss: 0.6890\n",
      "  Client 76 (User 76) local loss: 0.7255\n",
      "  Client 77 (User 77) local loss: 0.6735\n",
      "  Client 78 (User 78) local loss: 0.7397\n",
      "  Client 79 (User 79) local loss: 0.7115\n",
      "  Client 80 (User 80) local loss: 0.7754\n",
      "  Client 81 (User 81) local loss: 0.6488\n",
      "  Client 82 (User 82) local loss: 0.6443\n",
      "  Client 83 (User 83) local loss: 0.7250\n",
      "  Client 84 (User 84) local loss: 0.6734\n",
      "  Client 85 (User 85) local loss: 0.6169\n",
      "  Client 86 (User 86) local loss: 0.7108\n",
      "  Client 87 (User 87) local loss: 0.7468\n",
      "  Client 88 (User 88) local loss: 0.7379\n",
      "  Client 89 (User 89) local loss: 0.6400\n",
      "  Client 90 (User 90) local loss: 0.7021\n",
      "  Client 91 (User 91) local loss: 0.6808\n",
      "  Client 92 (User 92) local loss: 0.6924\n",
      "  Client 93 (User 93) local loss: 0.7258\n",
      "  Client 94 (User 94) local loss: 0.7182\n",
      "  Client 95 (User 95) local loss: 0.6896\n",
      "  Client 96 (User 96) local loss: 0.6216\n",
      "  Client 97 (User 97) local loss: 0.6919\n",
      "  Client 98 (User 98) local loss: 0.6581\n",
      "  Client 99 (User 99) local loss: 0.7237\n",
      "Round 1 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 2/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6912\n",
      "  Client 1 (User 1) local loss: 0.6450\n",
      "  Client 2 (User 2) local loss: 0.7608\n",
      "  Client 3 (User 3) local loss: 0.6470\n",
      "  Client 4 (User 4) local loss: 0.7055\n",
      "  Client 5 (User 5) local loss: 0.6623\n",
      "  Client 6 (User 6) local loss: 0.6336\n",
      "  Client 7 (User 7) local loss: 0.6674\n",
      "  Client 8 (User 8) local loss: 0.6770\n",
      "  Client 9 (User 9) local loss: 0.7232\n",
      "  Client 10 (User 10) local loss: 0.6833\n",
      "  Client 11 (User 11) local loss: 0.6745\n",
      "  Client 12 (User 12) local loss: 0.7348\n",
      "  Client 13 (User 13) local loss: 0.6412\n",
      "  Client 14 (User 14) local loss: 0.7660\n",
      "  Client 15 (User 15) local loss: 0.6695\n",
      "  Client 16 (User 16) local loss: 0.6803\n",
      "  Client 17 (User 17) local loss: 0.6906\n",
      "  Client 18 (User 18) local loss: 0.7418\n",
      "  Client 19 (User 19) local loss: 0.7501\n",
      "  Client 20 (User 20) local loss: 0.7316\n",
      "  Client 21 (User 21) local loss: 0.7257\n",
      "  Client 22 (User 22) local loss: 0.6948\n",
      "  Client 23 (User 23) local loss: 0.7198\n",
      "  Client 24 (User 24) local loss: 0.6879\n",
      "  Client 25 (User 25) local loss: 0.6714\n",
      "  Client 26 (User 26) local loss: 0.6284\n",
      "  Client 27 (User 27) local loss: 0.6405\n",
      "  Client 28 (User 28) local loss: 0.6896\n",
      "  Client 29 (User 29) local loss: 0.6678\n",
      "  Client 30 (User 30) local loss: 0.7402\n",
      "  Client 31 (User 31) local loss: 0.6524\n",
      "  Client 32 (User 32) local loss: 0.6827\n",
      "  Client 33 (User 33) local loss: 0.6670\n",
      "  Client 34 (User 34) local loss: 0.6916\n",
      "  Client 35 (User 35) local loss: 0.6191\n",
      "  Client 36 (User 36) local loss: 0.6629\n",
      "  Client 37 (User 37) local loss: 0.7346\n",
      "  Client 38 (User 38) local loss: 0.6288\n",
      "  Client 39 (User 39) local loss: 0.7417\n",
      "  Client 40 (User 40) local loss: 0.6231\n",
      "  Client 41 (User 41) local loss: 0.7037\n",
      "  Client 42 (User 42) local loss: 0.6416\n",
      "  Client 43 (User 43) local loss: 0.6163\n",
      "  Client 44 (User 44) local loss: 0.7095\n",
      "  Client 45 (User 45) local loss: 0.7122\n",
      "  Client 46 (User 46) local loss: 0.7257\n",
      "  Client 47 (User 47) local loss: 0.7287\n",
      "  Client 48 (User 48) local loss: 0.6014\n",
      "  Client 49 (User 49) local loss: 0.6702\n",
      "  Client 50 (User 50) local loss: 0.6809\n",
      "  Client 51 (User 51) local loss: 0.7279\n",
      "  Client 52 (User 52) local loss: 0.6656\n",
      "  Client 53 (User 53) local loss: 0.7766\n",
      "  Client 54 (User 54) local loss: 0.6247\n",
      "  Client 55 (User 55) local loss: 0.6265\n",
      "  Client 56 (User 56) local loss: 0.6408\n",
      "  Client 57 (User 57) local loss: 0.6472\n",
      "  Client 58 (User 58) local loss: 0.6869\n",
      "  Client 59 (User 59) local loss: 0.6391\n",
      "  Client 60 (User 60) local loss: 0.7405\n",
      "  Client 61 (User 61) local loss: 0.6640\n",
      "  Client 62 (User 62) local loss: 0.6571\n",
      "  Client 63 (User 63) local loss: 0.6692\n",
      "  Client 64 (User 64) local loss: 0.6695\n",
      "  Client 65 (User 65) local loss: 0.5992\n",
      "  Client 66 (User 66) local loss: 0.6978\n",
      "  Client 67 (User 67) local loss: 0.6866\n",
      "  Client 68 (User 68) local loss: 0.6190\n",
      "  Client 69 (User 69) local loss: 0.7049\n",
      "  Client 70 (User 70) local loss: 0.6898\n",
      "  Client 71 (User 71) local loss: 0.7369\n",
      "  Client 72 (User 72) local loss: 0.6340\n",
      "  Client 73 (User 73) local loss: 0.6456\n",
      "  Client 74 (User 74) local loss: 0.6878\n",
      "  Client 75 (User 75) local loss: 0.6812\n",
      "  Client 76 (User 76) local loss: 0.7080\n",
      "  Client 77 (User 77) local loss: 0.6726\n",
      "  Client 78 (User 78) local loss: 0.7401\n",
      "  Client 79 (User 79) local loss: 0.7011\n",
      "  Client 80 (User 80) local loss: 0.7642\n",
      "  Client 81 (User 81) local loss: 0.6443\n",
      "  Client 82 (User 82) local loss: 0.6273\n",
      "  Client 83 (User 83) local loss: 0.7166\n",
      "  Client 84 (User 84) local loss: 0.6720\n",
      "  Client 85 (User 85) local loss: 0.6009\n",
      "  Client 86 (User 86) local loss: 0.7038\n",
      "  Client 87 (User 87) local loss: 0.7426\n",
      "  Client 88 (User 88) local loss: 0.7313\n",
      "  Client 89 (User 89) local loss: 0.6385\n",
      "  Client 90 (User 90) local loss: 0.6996\n",
      "  Client 91 (User 91) local loss: 0.6803\n",
      "  Client 92 (User 92) local loss: 0.6874\n",
      "  Client 93 (User 93) local loss: 0.7237\n",
      "  Client 94 (User 94) local loss: 0.7097\n",
      "  Client 95 (User 95) local loss: 0.6861\n",
      "  Client 96 (User 96) local loss: 0.6275\n",
      "  Client 97 (User 97) local loss: 0.6874\n",
      "  Client 98 (User 98) local loss: 0.6546\n",
      "  Client 99 (User 99) local loss: 0.7163\n",
      "Round 2 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 3/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6903\n",
      "  Client 1 (User 1) local loss: 0.6202\n",
      "  Client 2 (User 2) local loss: 0.7725\n",
      "  Client 3 (User 3) local loss: 0.6311\n",
      "  Client 4 (User 4) local loss: 0.7000\n",
      "  Client 5 (User 5) local loss: 0.6615\n",
      "  Client 6 (User 6) local loss: 0.6382\n",
      "  Client 7 (User 7) local loss: 0.6582\n",
      "  Client 8 (User 8) local loss: 0.6654\n",
      "  Client 9 (User 9) local loss: 0.7206\n",
      "  Client 10 (User 10) local loss: 0.6808\n",
      "  Client 11 (User 11) local loss: 0.6691\n",
      "  Client 12 (User 12) local loss: 0.7252\n",
      "  Client 13 (User 13) local loss: 0.6337\n",
      "  Client 14 (User 14) local loss: 0.7489\n",
      "  Client 15 (User 15) local loss: 0.6674\n",
      "  Client 16 (User 16) local loss: 0.6721\n",
      "  Client 17 (User 17) local loss: 0.6879\n",
      "  Client 18 (User 18) local loss: 0.7292\n",
      "  Client 19 (User 19) local loss: 0.7514\n",
      "  Client 20 (User 20) local loss: 0.7257\n",
      "  Client 21 (User 21) local loss: 0.7167\n",
      "  Client 22 (User 22) local loss: 0.6881\n",
      "  Client 23 (User 23) local loss: 0.7069\n",
      "  Client 24 (User 24) local loss: 0.6849\n",
      "  Client 25 (User 25) local loss: 0.6685\n",
      "  Client 26 (User 26) local loss: 0.6361\n",
      "  Client 27 (User 27) local loss: 0.6134\n",
      "  Client 28 (User 28) local loss: 0.6872\n",
      "  Client 29 (User 29) local loss: 0.6644\n",
      "  Client 30 (User 30) local loss: 0.7487\n",
      "  Client 31 (User 31) local loss: 0.6520\n",
      "  Client 32 (User 32) local loss: 0.6749\n",
      "  Client 33 (User 33) local loss: 0.6541\n",
      "  Client 34 (User 34) local loss: 0.6940\n",
      "  Client 35 (User 35) local loss: 0.6057\n",
      "  Client 36 (User 36) local loss: 0.6596\n",
      "  Client 37 (User 37) local loss: 0.7379\n",
      "  Client 38 (User 38) local loss: 0.6355\n",
      "  Client 39 (User 39) local loss: 0.7350\n",
      "  Client 40 (User 40) local loss: 0.6043\n",
      "  Client 41 (User 41) local loss: 0.6968\n",
      "  Client 42 (User 42) local loss: 0.6409\n",
      "  Client 43 (User 43) local loss: 0.6118\n",
      "  Client 44 (User 44) local loss: 0.7042\n",
      "  Client 45 (User 45) local loss: 0.7050\n",
      "  Client 46 (User 46) local loss: 0.7199\n",
      "  Client 47 (User 47) local loss: 0.7365\n",
      "  Client 48 (User 48) local loss: 0.6106\n",
      "  Client 49 (User 49) local loss: 0.6620\n",
      "  Client 50 (User 50) local loss: 0.6729\n",
      "  Client 51 (User 51) local loss: 0.7230\n",
      "  Client 52 (User 52) local loss: 0.6573\n",
      "  Client 53 (User 53) local loss: 0.7782\n",
      "  Client 54 (User 54) local loss: 0.6430\n",
      "  Client 55 (User 55) local loss: 0.6222\n",
      "  Client 56 (User 56) local loss: 0.6299\n",
      "  Client 57 (User 57) local loss: 0.6435\n",
      "  Client 58 (User 58) local loss: 0.6830\n",
      "  Client 59 (User 59) local loss: 0.6316\n",
      "  Client 60 (User 60) local loss: 0.7396\n",
      "  Client 61 (User 61) local loss: 0.6602\n",
      "  Client 62 (User 62) local loss: 0.6479\n",
      "  Client 63 (User 63) local loss: 0.6664\n",
      "  Client 64 (User 64) local loss: 0.6528\n",
      "  Client 65 (User 65) local loss: 0.6084\n",
      "  Client 66 (User 66) local loss: 0.6912\n",
      "  Client 67 (User 67) local loss: 0.6797\n",
      "  Client 68 (User 68) local loss: 0.6052\n",
      "  Client 69 (User 69) local loss: 0.6968\n",
      "  Client 70 (User 70) local loss: 0.6800\n",
      "  Client 71 (User 71) local loss: 0.7343\n",
      "  Client 72 (User 72) local loss: 0.6278\n",
      "  Client 73 (User 73) local loss: 0.6421\n",
      "  Client 74 (User 74) local loss: 0.6867\n",
      "  Client 75 (User 75) local loss: 0.6810\n",
      "  Client 76 (User 76) local loss: 0.7000\n",
      "  Client 77 (User 77) local loss: 0.6677\n",
      "  Client 78 (User 78) local loss: 0.7321\n",
      "  Client 79 (User 79) local loss: 0.6894\n",
      "  Client 80 (User 80) local loss: 0.7577\n",
      "  Client 81 (User 81) local loss: 0.6350\n",
      "  Client 82 (User 82) local loss: 0.6245\n",
      "  Client 83 (User 83) local loss: 0.7113\n",
      "  Client 84 (User 84) local loss: 0.6618\n",
      "  Client 85 (User 85) local loss: 0.6014\n",
      "  Client 86 (User 86) local loss: 0.6967\n",
      "  Client 87 (User 87) local loss: 0.7349\n",
      "  Client 88 (User 88) local loss: 0.7324\n",
      "  Client 89 (User 89) local loss: 0.6419\n",
      "  Client 90 (User 90) local loss: 0.6945\n",
      "  Client 91 (User 91) local loss: 0.6790\n",
      "  Client 92 (User 92) local loss: 0.6800\n",
      "  Client 93 (User 93) local loss: 0.7183\n",
      "  Client 94 (User 94) local loss: 0.7058\n",
      "  Client 95 (User 95) local loss: 0.6809\n",
      "  Client 96 (User 96) local loss: 0.6266\n",
      "  Client 97 (User 97) local loss: 0.6845\n",
      "  Client 98 (User 98) local loss: 0.6506\n",
      "  Client 99 (User 99) local loss: 0.7115\n",
      "Round 3 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 4/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6825\n",
      "  Client 1 (User 1) local loss: 0.6281\n",
      "  Client 2 (User 2) local loss: 0.7637\n",
      "  Client 3 (User 3) local loss: 0.6295\n",
      "  Client 4 (User 4) local loss: 0.6926\n",
      "  Client 5 (User 5) local loss: 0.6578\n",
      "  Client 6 (User 6) local loss: 0.6385\n",
      "  Client 7 (User 7) local loss: 0.6495\n",
      "  Client 8 (User 8) local loss: 0.6580\n",
      "  Client 9 (User 9) local loss: 0.7131\n",
      "  Client 10 (User 10) local loss: 0.6766\n",
      "  Client 11 (User 11) local loss: 0.6758\n",
      "  Client 12 (User 12) local loss: 0.7101\n",
      "  Client 13 (User 13) local loss: 0.6298\n",
      "  Client 14 (User 14) local loss: 0.7300\n",
      "  Client 15 (User 15) local loss: 0.6588\n",
      "  Client 16 (User 16) local loss: 0.6718\n",
      "  Client 17 (User 17) local loss: 0.6837\n",
      "  Client 18 (User 18) local loss: 0.7200\n",
      "  Client 19 (User 19) local loss: 0.7468\n",
      "  Client 20 (User 20) local loss: 0.7234\n",
      "  Client 21 (User 21) local loss: 0.7185\n",
      "  Client 22 (User 22) local loss: 0.6847\n",
      "  Client 23 (User 23) local loss: 0.6941\n",
      "  Client 24 (User 24) local loss: 0.6774\n",
      "  Client 25 (User 25) local loss: 0.6711\n",
      "  Client 26 (User 26) local loss: 0.6154\n",
      "  Client 27 (User 27) local loss: 0.6222\n",
      "  Client 28 (User 28) local loss: 0.6836\n",
      "  Client 29 (User 29) local loss: 0.6570\n",
      "  Client 30 (User 30) local loss: 0.7459\n",
      "  Client 31 (User 31) local loss: 0.6375\n",
      "  Client 32 (User 32) local loss: 0.6681\n",
      "  Client 33 (User 33) local loss: 0.6565\n",
      "  Client 34 (User 34) local loss: 0.6969\n",
      "  Client 35 (User 35) local loss: 0.5941\n",
      "  Client 36 (User 36) local loss: 0.6496\n",
      "  Client 37 (User 37) local loss: 0.7312\n",
      "  Client 38 (User 38) local loss: 0.6252\n",
      "  Client 39 (User 39) local loss: 0.7387\n",
      "  Client 40 (User 40) local loss: 0.6172\n",
      "  Client 41 (User 41) local loss: 0.6854\n",
      "  Client 42 (User 42) local loss: 0.6342\n",
      "  Client 43 (User 43) local loss: 0.6010\n",
      "  Client 44 (User 44) local loss: 0.6976\n",
      "  Client 45 (User 45) local loss: 0.7019\n",
      "  Client 46 (User 46) local loss: 0.7072\n",
      "  Client 47 (User 47) local loss: 0.7168\n",
      "  Client 48 (User 48) local loss: 0.5969\n",
      "  Client 49 (User 49) local loss: 0.6570\n",
      "  Client 50 (User 50) local loss: 0.6695\n",
      "  Client 51 (User 51) local loss: 0.7210\n",
      "  Client 52 (User 52) local loss: 0.6401\n",
      "  Client 53 (User 53) local loss: 0.7624\n",
      "  Client 54 (User 54) local loss: 0.6325\n",
      "  Client 55 (User 55) local loss: 0.6260\n",
      "  Client 56 (User 56) local loss: 0.6001\n",
      "  Client 57 (User 57) local loss: 0.6380\n",
      "  Client 58 (User 58) local loss: 0.6833\n",
      "  Client 59 (User 59) local loss: 0.6212\n",
      "  Client 60 (User 60) local loss: 0.7266\n",
      "  Client 61 (User 61) local loss: 0.6525\n",
      "  Client 62 (User 62) local loss: 0.6582\n",
      "  Client 63 (User 63) local loss: 0.6541\n",
      "  Client 64 (User 64) local loss: 0.6599\n",
      "  Client 65 (User 65) local loss: 0.6099\n",
      "  Client 66 (User 66) local loss: 0.6789\n",
      "  Client 67 (User 67) local loss: 0.6737\n",
      "  Client 68 (User 68) local loss: 0.6011\n",
      "  Client 69 (User 69) local loss: 0.6897\n",
      "  Client 70 (User 70) local loss: 0.6757\n",
      "  Client 71 (User 71) local loss: 0.7277\n",
      "  Client 72 (User 72) local loss: 0.6183\n",
      "  Client 73 (User 73) local loss: 0.6310\n",
      "  Client 74 (User 74) local loss: 0.6810\n",
      "  Client 75 (User 75) local loss: 0.6758\n",
      "  Client 76 (User 76) local loss: 0.6818\n",
      "  Client 77 (User 77) local loss: 0.6638\n",
      "  Client 78 (User 78) local loss: 0.7264\n",
      "  Client 79 (User 79) local loss: 0.6684\n",
      "  Client 80 (User 80) local loss: 0.7563\n",
      "  Client 81 (User 81) local loss: 0.6331\n",
      "  Client 82 (User 82) local loss: 0.6361\n",
      "  Client 83 (User 83) local loss: 0.7078\n",
      "  Client 84 (User 84) local loss: 0.6455\n",
      "  Client 85 (User 85) local loss: 0.6011\n",
      "  Client 86 (User 86) local loss: 0.6924\n",
      "  Client 87 (User 87) local loss: 0.7300\n",
      "  Client 88 (User 88) local loss: 0.7325\n",
      "  Client 89 (User 89) local loss: 0.6306\n",
      "  Client 90 (User 90) local loss: 0.6895\n",
      "  Client 91 (User 91) local loss: 0.6717\n",
      "  Client 92 (User 92) local loss: 0.6757\n",
      "  Client 93 (User 93) local loss: 0.7144\n",
      "  Client 94 (User 94) local loss: 0.7002\n",
      "  Client 95 (User 95) local loss: 0.6779\n",
      "  Client 96 (User 96) local loss: 0.6127\n",
      "  Client 97 (User 97) local loss: 0.6775\n",
      "  Client 98 (User 98) local loss: 0.6421\n",
      "  Client 99 (User 99) local loss: 0.7075\n",
      "Round 4 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 5/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6665\n",
      "  Client 1 (User 1) local loss: 0.6183\n",
      "  Client 2 (User 2) local loss: 0.7525\n",
      "  Client 3 (User 3) local loss: 0.6297\n",
      "  Client 4 (User 4) local loss: 0.6873\n",
      "  Client 5 (User 5) local loss: 0.6508\n",
      "  Client 6 (User 6) local loss: 0.6284\n",
      "  Client 7 (User 7) local loss: 0.6442\n",
      "  Client 8 (User 8) local loss: 0.6675\n",
      "  Client 9 (User 9) local loss: 0.7064\n",
      "  Client 10 (User 10) local loss: 0.6696\n",
      "  Client 11 (User 11) local loss: 0.6600\n",
      "  Client 12 (User 12) local loss: 0.7006\n",
      "  Client 13 (User 13) local loss: 0.6239\n",
      "  Client 14 (User 14) local loss: 0.7114\n",
      "  Client 15 (User 15) local loss: 0.6546\n",
      "  Client 16 (User 16) local loss: 0.6675\n",
      "  Client 17 (User 17) local loss: 0.6788\n",
      "  Client 18 (User 18) local loss: 0.7155\n",
      "  Client 19 (User 19) local loss: 0.7459\n",
      "  Client 20 (User 20) local loss: 0.7056\n",
      "  Client 21 (User 21) local loss: 0.7147\n",
      "  Client 22 (User 22) local loss: 0.6785\n",
      "  Client 23 (User 23) local loss: 0.6781\n",
      "  Client 24 (User 24) local loss: 0.6759\n",
      "  Client 25 (User 25) local loss: 0.6603\n",
      "  Client 26 (User 26) local loss: 0.6203\n",
      "  Client 27 (User 27) local loss: 0.6248\n",
      "  Client 28 (User 28) local loss: 0.6819\n",
      "  Client 29 (User 29) local loss: 0.6453\n",
      "  Client 30 (User 30) local loss: 0.7420\n",
      "  Client 31 (User 31) local loss: 0.6589\n",
      "  Client 32 (User 32) local loss: 0.6610\n",
      "  Client 33 (User 33) local loss: 0.6591\n",
      "  Client 34 (User 34) local loss: 0.6920\n",
      "  Client 35 (User 35) local loss: 0.5975\n",
      "  Client 36 (User 36) local loss: 0.6505\n",
      "  Client 37 (User 37) local loss: 0.7276\n",
      "  Client 38 (User 38) local loss: 0.6354\n",
      "  Client 39 (User 39) local loss: 0.7363\n",
      "  Client 40 (User 40) local loss: 0.6058\n",
      "  Client 41 (User 41) local loss: 0.6721\n",
      "  Client 42 (User 42) local loss: 0.6366\n",
      "  Client 43 (User 43) local loss: 0.6038\n",
      "  Client 44 (User 44) local loss: 0.6967\n",
      "  Client 45 (User 45) local loss: 0.6922\n",
      "  Client 46 (User 46) local loss: 0.7000\n",
      "  Client 47 (User 47) local loss: 0.7276\n",
      "  Client 48 (User 48) local loss: 0.5862\n",
      "  Client 49 (User 49) local loss: 0.6607\n",
      "  Client 50 (User 50) local loss: 0.6612\n",
      "  Client 51 (User 51) local loss: 0.7150\n",
      "  Client 52 (User 52) local loss: 0.6212\n",
      "  Client 53 (User 53) local loss: 0.7583\n",
      "  Client 54 (User 54) local loss: 0.6250\n",
      "  Client 55 (User 55) local loss: 0.6345\n",
      "  Client 56 (User 56) local loss: 0.5876\n",
      "  Client 57 (User 57) local loss: 0.6444\n",
      "  Client 58 (User 58) local loss: 0.6778\n",
      "  Client 59 (User 59) local loss: 0.6251\n",
      "  Client 60 (User 60) local loss: 0.7270\n",
      "  Client 61 (User 61) local loss: 0.6493\n",
      "  Client 62 (User 62) local loss: 0.6486\n",
      "  Client 63 (User 63) local loss: 0.6469\n",
      "  Client 64 (User 64) local loss: 0.6514\n",
      "  Client 65 (User 65) local loss: 0.6013\n",
      "  Client 66 (User 66) local loss: 0.6705\n",
      "  Client 67 (User 67) local loss: 0.6721\n",
      "  Client 68 (User 68) local loss: 0.5982\n",
      "  Client 69 (User 69) local loss: 0.6824\n",
      "  Client 70 (User 70) local loss: 0.6693\n",
      "  Client 71 (User 71) local loss: 0.7169\n",
      "  Client 72 (User 72) local loss: 0.6088\n",
      "  Client 73 (User 73) local loss: 0.6181\n",
      "  Client 74 (User 74) local loss: 0.6799\n",
      "  Client 75 (User 75) local loss: 0.6696\n",
      "  Client 76 (User 76) local loss: 0.6614\n",
      "  Client 77 (User 77) local loss: 0.6571\n",
      "  Client 78 (User 78) local loss: 0.7271\n",
      "  Client 79 (User 79) local loss: 0.6480\n",
      "  Client 80 (User 80) local loss: 0.7565\n",
      "  Client 81 (User 81) local loss: 0.6133\n",
      "  Client 82 (User 82) local loss: 0.6312\n",
      "  Client 83 (User 83) local loss: 0.7043\n",
      "  Client 84 (User 84) local loss: 0.6366\n",
      "  Client 85 (User 85) local loss: 0.5909\n",
      "  Client 86 (User 86) local loss: 0.6878\n",
      "  Client 87 (User 87) local loss: 0.7264\n",
      "  Client 88 (User 88) local loss: 0.7332\n",
      "  Client 89 (User 89) local loss: 0.6234\n",
      "  Client 90 (User 90) local loss: 0.6864\n",
      "  Client 91 (User 91) local loss: 0.6813\n",
      "  Client 92 (User 92) local loss: 0.6711\n",
      "  Client 93 (User 93) local loss: 0.7063\n",
      "  Client 94 (User 94) local loss: 0.6949\n",
      "  Client 95 (User 95) local loss: 0.6734\n",
      "  Client 96 (User 96) local loss: 0.6063\n",
      "  Client 97 (User 97) local loss: 0.6728\n",
      "  Client 98 (User 98) local loss: 0.6414\n",
      "  Client 99 (User 99) local loss: 0.7042\n",
      "Round 5 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 6/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6550\n",
      "  Client 1 (User 1) local loss: 0.6166\n",
      "  Client 2 (User 2) local loss: 0.7586\n",
      "  Client 3 (User 3) local loss: 0.6128\n",
      "  Client 4 (User 4) local loss: 0.6842\n",
      "  Client 5 (User 5) local loss: 0.6478\n",
      "  Client 6 (User 6) local loss: 0.6139\n",
      "  Client 7 (User 7) local loss: 0.6267\n",
      "  Client 8 (User 8) local loss: 0.6649\n",
      "  Client 9 (User 9) local loss: 0.6996\n",
      "  Client 10 (User 10) local loss: 0.6652\n",
      "  Client 11 (User 11) local loss: 0.6682\n",
      "  Client 12 (User 12) local loss: 0.6857\n",
      "  Client 13 (User 13) local loss: 0.6210\n",
      "  Client 14 (User 14) local loss: 0.6882\n",
      "  Client 15 (User 15) local loss: 0.6398\n",
      "  Client 16 (User 16) local loss: 0.6688\n",
      "  Client 17 (User 17) local loss: 0.6788\n",
      "  Client 18 (User 18) local loss: 0.6999\n",
      "  Client 19 (User 19) local loss: 0.7392\n",
      "  Client 20 (User 20) local loss: 0.6910\n",
      "  Client 21 (User 21) local loss: 0.7100\n",
      "  Client 22 (User 22) local loss: 0.6720\n",
      "  Client 23 (User 23) local loss: 0.6708\n",
      "  Client 24 (User 24) local loss: 0.6640\n",
      "  Client 25 (User 25) local loss: 0.6729\n",
      "  Client 26 (User 26) local loss: 0.5951\n",
      "  Client 27 (User 27) local loss: 0.6177\n",
      "  Client 28 (User 28) local loss: 0.6789\n",
      "  Client 29 (User 29) local loss: 0.6405\n",
      "  Client 30 (User 30) local loss: 0.7399\n",
      "  Client 31 (User 31) local loss: 0.6437\n",
      "  Client 32 (User 32) local loss: 0.6576\n",
      "  Client 33 (User 33) local loss: 0.6566\n",
      "  Client 34 (User 34) local loss: 0.6864\n",
      "  Client 35 (User 35) local loss: 0.5818\n",
      "  Client 36 (User 36) local loss: 0.6472\n",
      "  Client 37 (User 37) local loss: 0.7246\n",
      "  Client 38 (User 38) local loss: 0.6065\n",
      "  Client 39 (User 39) local loss: 0.7271\n",
      "  Client 40 (User 40) local loss: 0.5928\n",
      "  Client 41 (User 41) local loss: 0.6633\n",
      "  Client 42 (User 42) local loss: 0.6276\n",
      "  Client 43 (User 43) local loss: 0.6001\n",
      "  Client 44 (User 44) local loss: 0.6953\n",
      "  Client 45 (User 45) local loss: 0.6881\n",
      "  Client 46 (User 46) local loss: 0.6937\n",
      "  Client 47 (User 47) local loss: 0.7263\n",
      "  Client 48 (User 48) local loss: 0.5908\n",
      "  Client 49 (User 49) local loss: 0.6525\n",
      "  Client 50 (User 50) local loss: 0.6665\n",
      "  Client 51 (User 51) local loss: 0.7052\n",
      "  Client 52 (User 52) local loss: 0.6357\n",
      "  Client 53 (User 53) local loss: 0.7451\n",
      "  Client 54 (User 54) local loss: 0.6168\n",
      "  Client 55 (User 55) local loss: 0.6193\n",
      "  Client 56 (User 56) local loss: 0.5933\n",
      "  Client 57 (User 57) local loss: 0.6348\n",
      "  Client 58 (User 58) local loss: 0.6759\n",
      "  Client 59 (User 59) local loss: 0.6126\n",
      "  Client 60 (User 60) local loss: 0.7192\n",
      "  Client 61 (User 61) local loss: 0.6508\n",
      "  Client 62 (User 62) local loss: 0.6376\n",
      "  Client 63 (User 63) local loss: 0.6322\n",
      "  Client 64 (User 64) local loss: 0.6366\n",
      "  Client 65 (User 65) local loss: 0.5819\n",
      "  Client 66 (User 66) local loss: 0.6550\n",
      "  Client 67 (User 67) local loss: 0.6670\n",
      "  Client 68 (User 68) local loss: 0.6190\n",
      "  Client 69 (User 69) local loss: 0.6769\n",
      "  Client 70 (User 70) local loss: 0.6595\n",
      "  Client 71 (User 71) local loss: 0.7053\n",
      "  Client 72 (User 72) local loss: 0.6097\n",
      "  Client 73 (User 73) local loss: 0.6174\n",
      "  Client 74 (User 74) local loss: 0.6779\n",
      "  Client 75 (User 75) local loss: 0.6685\n",
      "  Client 76 (User 76) local loss: 0.6437\n",
      "  Client 77 (User 77) local loss: 0.6562\n",
      "  Client 78 (User 78) local loss: 0.7268\n",
      "  Client 79 (User 79) local loss: 0.6195\n",
      "  Client 80 (User 80) local loss: 0.7486\n",
      "  Client 81 (User 81) local loss: 0.6170\n",
      "  Client 82 (User 82) local loss: 0.6190\n",
      "  Client 83 (User 83) local loss: 0.7014\n",
      "  Client 84 (User 84) local loss: 0.6303\n",
      "  Client 85 (User 85) local loss: 0.5815\n",
      "  Client 86 (User 86) local loss: 0.6816\n",
      "  Client 87 (User 87) local loss: 0.7220\n",
      "  Client 88 (User 88) local loss: 0.7293\n",
      "  Client 89 (User 89) local loss: 0.6196\n",
      "  Client 90 (User 90) local loss: 0.6841\n",
      "  Client 91 (User 91) local loss: 0.6741\n",
      "  Client 92 (User 92) local loss: 0.6629\n",
      "  Client 93 (User 93) local loss: 0.7034\n",
      "  Client 94 (User 94) local loss: 0.6900\n",
      "  Client 95 (User 95) local loss: 0.6732\n",
      "  Client 96 (User 96) local loss: 0.6099\n",
      "  Client 97 (User 97) local loss: 0.6604\n",
      "  Client 98 (User 98) local loss: 0.6378\n",
      "  Client 99 (User 99) local loss: 0.7008\n",
      "Round 6 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 7/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6469\n",
      "  Client 1 (User 1) local loss: 0.6093\n",
      "  Client 2 (User 2) local loss: 0.7482\n",
      "  Client 3 (User 3) local loss: 0.6187\n",
      "  Client 4 (User 4) local loss: 0.6774\n",
      "  Client 5 (User 5) local loss: 0.6479\n",
      "  Client 6 (User 6) local loss: 0.6042\n",
      "  Client 7 (User 7) local loss: 0.6049\n",
      "  Client 8 (User 8) local loss: 0.6547\n",
      "  Client 9 (User 9) local loss: 0.6925\n",
      "  Client 10 (User 10) local loss: 0.6627\n",
      "  Client 11 (User 11) local loss: 0.6649\n",
      "  Client 12 (User 12) local loss: 0.6700\n",
      "  Client 13 (User 13) local loss: 0.6097\n",
      "  Client 14 (User 14) local loss: 0.6576\n",
      "  Client 15 (User 15) local loss: 0.6374\n",
      "  Client 16 (User 16) local loss: 0.6675\n",
      "  Client 17 (User 17) local loss: 0.6702\n",
      "  Client 18 (User 18) local loss: 0.6941\n",
      "  Client 19 (User 19) local loss: 0.7334\n",
      "  Client 20 (User 20) local loss: 0.6736\n",
      "  Client 21 (User 21) local loss: 0.7069\n",
      "  Client 22 (User 22) local loss: 0.6686\n",
      "  Client 23 (User 23) local loss: 0.6434\n",
      "  Client 24 (User 24) local loss: 0.6643\n",
      "  Client 25 (User 25) local loss: 0.6663\n",
      "  Client 26 (User 26) local loss: 0.6074\n",
      "  Client 27 (User 27) local loss: 0.6203\n",
      "  Client 28 (User 28) local loss: 0.6770\n",
      "  Client 29 (User 29) local loss: 0.6225\n",
      "  Client 30 (User 30) local loss: 0.7368\n",
      "  Client 31 (User 31) local loss: 0.6507\n",
      "  Client 32 (User 32) local loss: 0.6454\n",
      "  Client 33 (User 33) local loss: 0.6457\n",
      "  Client 34 (User 34) local loss: 0.6896\n",
      "  Client 35 (User 35) local loss: 0.5489\n",
      "  Client 36 (User 36) local loss: 0.6364\n",
      "  Client 37 (User 37) local loss: 0.7186\n",
      "  Client 38 (User 38) local loss: 0.6065\n",
      "  Client 39 (User 39) local loss: 0.7234\n",
      "  Client 40 (User 40) local loss: 0.5830\n",
      "  Client 41 (User 41) local loss: 0.6451\n",
      "  Client 42 (User 42) local loss: 0.6255\n",
      "  Client 43 (User 43) local loss: 0.5827\n",
      "  Client 44 (User 44) local loss: 0.6917\n",
      "  Client 45 (User 45) local loss: 0.6862\n",
      "  Client 46 (User 46) local loss: 0.6820\n",
      "  Client 47 (User 47) local loss: 0.7189\n",
      "  Client 48 (User 48) local loss: 0.5683\n",
      "  Client 49 (User 49) local loss: 0.6508\n",
      "  Client 50 (User 50) local loss: 0.6529\n",
      "  Client 51 (User 51) local loss: 0.6920\n",
      "  Client 52 (User 52) local loss: 0.6063\n",
      "  Client 53 (User 53) local loss: 0.7380\n",
      "  Client 54 (User 54) local loss: 0.6016\n",
      "  Client 55 (User 55) local loss: 0.6116\n",
      "  Client 56 (User 56) local loss: 0.5767\n",
      "  Client 57 (User 57) local loss: 0.6408\n",
      "  Client 58 (User 58) local loss: 0.6704\n",
      "  Client 59 (User 59) local loss: 0.6008\n",
      "  Client 60 (User 60) local loss: 0.7159\n",
      "  Client 61 (User 61) local loss: 0.6323\n",
      "  Client 62 (User 62) local loss: 0.6398\n",
      "  Client 63 (User 63) local loss: 0.6344\n",
      "  Client 64 (User 64) local loss: 0.6616\n",
      "  Client 65 (User 65) local loss: 0.5893\n",
      "  Client 66 (User 66) local loss: 0.6450\n",
      "  Client 67 (User 67) local loss: 0.6616\n",
      "  Client 68 (User 68) local loss: 0.6175\n",
      "  Client 69 (User 69) local loss: 0.6696\n",
      "  Client 70 (User 70) local loss: 0.6520\n",
      "  Client 71 (User 71) local loss: 0.6887\n",
      "  Client 72 (User 72) local loss: 0.6065\n",
      "  Client 73 (User 73) local loss: 0.6163\n",
      "  Client 74 (User 74) local loss: 0.6796\n",
      "  Client 75 (User 75) local loss: 0.6631\n",
      "  Client 76 (User 76) local loss: 0.6212\n",
      "  Client 77 (User 77) local loss: 0.6485\n",
      "  Client 78 (User 78) local loss: 0.7182\n",
      "  Client 79 (User 79) local loss: 0.5987\n",
      "  Client 80 (User 80) local loss: 0.7502\n",
      "  Client 81 (User 81) local loss: 0.6365\n",
      "  Client 82 (User 82) local loss: 0.6212\n",
      "  Client 83 (User 83) local loss: 0.6936\n",
      "  Client 84 (User 84) local loss: 0.6209\n",
      "  Client 85 (User 85) local loss: 0.5781\n",
      "  Client 86 (User 86) local loss: 0.6652\n",
      "  Client 87 (User 87) local loss: 0.7185\n",
      "  Client 88 (User 88) local loss: 0.7223\n",
      "  Client 89 (User 89) local loss: 0.6219\n",
      "  Client 90 (User 90) local loss: 0.6809\n",
      "  Client 91 (User 91) local loss: 0.6632\n",
      "  Client 92 (User 92) local loss: 0.6552\n",
      "  Client 93 (User 93) local loss: 0.7025\n",
      "  Client 94 (User 94) local loss: 0.6871\n",
      "  Client 95 (User 95) local loss: 0.6641\n",
      "  Client 96 (User 96) local loss: 0.6173\n",
      "  Client 97 (User 97) local loss: 0.6558\n",
      "  Client 98 (User 98) local loss: 0.6382\n",
      "  Client 99 (User 99) local loss: 0.6978\n",
      "Round 7 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 8/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6428\n",
      "  Client 1 (User 1) local loss: 0.6059\n",
      "  Client 2 (User 2) local loss: 0.7407\n",
      "  Client 3 (User 3) local loss: 0.5950\n",
      "  Client 4 (User 4) local loss: 0.6809\n",
      "  Client 5 (User 5) local loss: 0.6432\n",
      "  Client 6 (User 6) local loss: 0.6187\n",
      "  Client 7 (User 7) local loss: 0.5834\n",
      "  Client 8 (User 8) local loss: 0.6561\n",
      "  Client 9 (User 9) local loss: 0.6832\n",
      "  Client 10 (User 10) local loss: 0.6687\n",
      "  Client 11 (User 11) local loss: 0.6481\n",
      "  Client 12 (User 12) local loss: 0.6463\n",
      "  Client 13 (User 13) local loss: 0.6192\n",
      "  Client 14 (User 14) local loss: 0.6292\n",
      "  Client 15 (User 15) local loss: 0.6303\n",
      "  Client 16 (User 16) local loss: 0.6705\n",
      "  Client 17 (User 17) local loss: 0.6730\n",
      "  Client 18 (User 18) local loss: 0.6814\n",
      "  Client 19 (User 19) local loss: 0.7221\n",
      "  Client 20 (User 20) local loss: 0.6574\n",
      "  Client 21 (User 21) local loss: 0.7090\n",
      "  Client 22 (User 22) local loss: 0.6549\n",
      "  Client 23 (User 23) local loss: 0.6380\n",
      "  Client 24 (User 24) local loss: 0.6514\n",
      "  Client 25 (User 25) local loss: 0.6719\n",
      "  Client 26 (User 26) local loss: 0.6088\n",
      "  Client 27 (User 27) local loss: 0.6184\n",
      "  Client 28 (User 28) local loss: 0.6753\n",
      "  Client 29 (User 29) local loss: 0.6111\n",
      "  Client 30 (User 30) local loss: 0.7257\n",
      "  Client 31 (User 31) local loss: 0.6359\n",
      "  Client 32 (User 32) local loss: 0.6299\n",
      "  Client 33 (User 33) local loss: 0.6476\n",
      "  Client 34 (User 34) local loss: 0.6799\n",
      "  Client 35 (User 35) local loss: 0.5474\n",
      "  Client 36 (User 36) local loss: 0.6547\n",
      "  Client 37 (User 37) local loss: 0.7183\n",
      "  Client 38 (User 38) local loss: 0.6004\n",
      "  Client 39 (User 39) local loss: 0.7133\n",
      "  Client 40 (User 40) local loss: 0.5906\n",
      "  Client 41 (User 41) local loss: 0.6255\n",
      "  Client 42 (User 42) local loss: 0.6301\n",
      "  Client 43 (User 43) local loss: 0.5613\n",
      "  Client 44 (User 44) local loss: 0.6846\n",
      "  Client 45 (User 45) local loss: 0.6749\n",
      "  Client 46 (User 46) local loss: 0.6738\n",
      "  Client 47 (User 47) local loss: 0.7231\n",
      "  Client 48 (User 48) local loss: 0.5831\n",
      "  Client 49 (User 49) local loss: 0.6434\n",
      "  Client 50 (User 50) local loss: 0.6622\n",
      "  Client 51 (User 51) local loss: 0.6777\n",
      "  Client 52 (User 52) local loss: 0.6066\n",
      "  Client 53 (User 53) local loss: 0.7290\n",
      "  Client 54 (User 54) local loss: 0.6063\n",
      "  Client 55 (User 55) local loss: 0.5869\n",
      "  Client 56 (User 56) local loss: 0.5652\n",
      "  Client 57 (User 57) local loss: 0.6372\n",
      "  Client 58 (User 58) local loss: 0.6703\n",
      "  Client 59 (User 59) local loss: 0.5789\n",
      "  Client 60 (User 60) local loss: 0.7018\n",
      "  Client 61 (User 61) local loss: 0.6311\n",
      "  Client 62 (User 62) local loss: 0.6408\n",
      "  Client 63 (User 63) local loss: 0.6298\n",
      "  Client 64 (User 64) local loss: 0.6392\n",
      "  Client 65 (User 65) local loss: 0.5606\n",
      "  Client 66 (User 66) local loss: 0.6241\n",
      "  Client 67 (User 67) local loss: 0.6635\n",
      "  Client 68 (User 68) local loss: 0.6050\n",
      "  Client 69 (User 69) local loss: 0.6591\n",
      "  Client 70 (User 70) local loss: 0.6513\n",
      "  Client 71 (User 71) local loss: 0.6716\n",
      "  Client 72 (User 72) local loss: 0.6025\n",
      "  Client 73 (User 73) local loss: 0.6251\n",
      "  Client 74 (User 74) local loss: 0.6719\n",
      "  Client 75 (User 75) local loss: 0.6597\n",
      "  Client 76 (User 76) local loss: 0.6132\n",
      "  Client 77 (User 77) local loss: 0.6430\n",
      "  Client 78 (User 78) local loss: 0.7137\n",
      "  Client 79 (User 79) local loss: 0.5608\n",
      "  Client 80 (User 80) local loss: 0.7428\n",
      "  Client 81 (User 81) local loss: 0.6167\n",
      "  Client 82 (User 82) local loss: 0.6167\n",
      "  Client 83 (User 83) local loss: 0.6810\n",
      "  Client 84 (User 84) local loss: 0.6136\n",
      "  Client 85 (User 85) local loss: 0.5694\n",
      "  Client 86 (User 86) local loss: 0.6540\n",
      "  Client 87 (User 87) local loss: 0.7111\n",
      "  Client 88 (User 88) local loss: 0.7309\n",
      "  Client 89 (User 89) local loss: 0.6053\n",
      "  Client 90 (User 90) local loss: 0.6801\n",
      "  Client 91 (User 91) local loss: 0.6626\n",
      "  Client 92 (User 92) local loss: 0.6513\n",
      "  Client 93 (User 93) local loss: 0.6981\n",
      "  Client 94 (User 94) local loss: 0.6847\n",
      "  Client 95 (User 95) local loss: 0.6518\n",
      "  Client 96 (User 96) local loss: 0.5817\n",
      "  Client 97 (User 97) local loss: 0.6361\n",
      "  Client 98 (User 98) local loss: 0.6316\n",
      "  Client 99 (User 99) local loss: 0.6942\n",
      "Round 8 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 9/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6543\n",
      "  Client 1 (User 1) local loss: 0.6038\n",
      "  Client 2 (User 2) local loss: 0.7443\n",
      "  Client 3 (User 3) local loss: 0.6164\n",
      "  Client 4 (User 4) local loss: 0.6685\n",
      "  Client 5 (User 5) local loss: 0.6449\n",
      "  Client 6 (User 6) local loss: 0.6129\n",
      "  Client 7 (User 7) local loss: 0.5522\n",
      "  Client 8 (User 8) local loss: 0.6468\n",
      "  Client 9 (User 9) local loss: 0.6629\n",
      "  Client 10 (User 10) local loss: 0.6494\n",
      "  Client 11 (User 11) local loss: 0.6562\n",
      "  Client 12 (User 12) local loss: 0.6199\n",
      "  Client 13 (User 13) local loss: 0.6029\n",
      "  Client 14 (User 14) local loss: 0.5862\n",
      "  Client 15 (User 15) local loss: 0.6098\n",
      "  Client 16 (User 16) local loss: 0.6726\n",
      "  Client 17 (User 17) local loss: 0.6697\n",
      "  Client 18 (User 18) local loss: 0.6705\n",
      "  Client 19 (User 19) local loss: 0.7084\n",
      "  Client 20 (User 20) local loss: 0.6465\n",
      "  Client 21 (User 21) local loss: 0.7031\n",
      "  Client 22 (User 22) local loss: 0.6580\n",
      "  Client 23 (User 23) local loss: 0.6223\n",
      "  Client 24 (User 24) local loss: 0.6541\n",
      "  Client 25 (User 25) local loss: 0.6700\n",
      "  Client 26 (User 26) local loss: 0.5786\n",
      "  Client 27 (User 27) local loss: 0.6149\n",
      "  Client 28 (User 28) local loss: 0.6744\n",
      "  Client 29 (User 29) local loss: 0.5844\n",
      "  Client 30 (User 30) local loss: 0.7131\n",
      "  Client 31 (User 31) local loss: 0.6158\n",
      "  Client 32 (User 32) local loss: 0.6227\n",
      "  Client 33 (User 33) local loss: 0.6410\n",
      "  Client 34 (User 34) local loss: 0.6919\n",
      "  Client 35 (User 35) local loss: 0.5191\n",
      "  Client 36 (User 36) local loss: 0.6461\n",
      "  Client 37 (User 37) local loss: 0.7090\n",
      "  Client 38 (User 38) local loss: 0.5939\n",
      "  Client 39 (User 39) local loss: 0.7043\n",
      "  Client 40 (User 40) local loss: 0.5725\n",
      "  Client 41 (User 41) local loss: 0.6011\n",
      "  Client 42 (User 42) local loss: 0.6265\n",
      "  Client 43 (User 43) local loss: 0.5653\n",
      "  Client 44 (User 44) local loss: 0.6810\n",
      "  Client 45 (User 45) local loss: 0.6657\n",
      "  Client 46 (User 46) local loss: 0.6466\n",
      "  Client 47 (User 47) local loss: 0.7095\n",
      "  Client 48 (User 48) local loss: 0.5415\n",
      "  Client 49 (User 49) local loss: 0.6209\n",
      "  Client 50 (User 50) local loss: 0.6649\n",
      "  Client 51 (User 51) local loss: 0.6643\n",
      "  Client 52 (User 52) local loss: 0.6089\n",
      "  Client 53 (User 53) local loss: 0.7225\n",
      "  Client 54 (User 54) local loss: 0.6291\n",
      "  Client 55 (User 55) local loss: 0.6023\n",
      "  Client 56 (User 56) local loss: 0.5675\n",
      "  Client 57 (User 57) local loss: 0.6281\n",
      "  Client 58 (User 58) local loss: 0.6625\n",
      "  Client 59 (User 59) local loss: 0.5727\n",
      "  Client 60 (User 60) local loss: 0.6935\n",
      "  Client 61 (User 61) local loss: 0.6304\n",
      "  Client 62 (User 62) local loss: 0.6275\n",
      "  Client 63 (User 63) local loss: 0.6149\n",
      "  Client 64 (User 64) local loss: 0.6378\n",
      "  Client 65 (User 65) local loss: 0.5482\n",
      "  Client 66 (User 66) local loss: 0.6115\n",
      "  Client 67 (User 67) local loss: 0.6546\n",
      "  Client 68 (User 68) local loss: 0.5720\n",
      "  Client 69 (User 69) local loss: 0.6484\n",
      "  Client 70 (User 70) local loss: 0.6439\n",
      "  Client 71 (User 71) local loss: 0.6533\n",
      "  Client 72 (User 72) local loss: 0.5949\n",
      "  Client 73 (User 73) local loss: 0.6011\n",
      "  Client 74 (User 74) local loss: 0.6736\n",
      "  Client 75 (User 75) local loss: 0.6511\n",
      "  Client 76 (User 76) local loss: 0.6202\n",
      "  Client 77 (User 77) local loss: 0.6377\n",
      "  Client 78 (User 78) local loss: 0.7061\n",
      "  Client 79 (User 79) local loss: 0.5614\n",
      "  Client 80 (User 80) local loss: 0.7403\n",
      "  Client 81 (User 81) local loss: 0.6008\n",
      "  Client 82 (User 82) local loss: 0.6289\n",
      "  Client 83 (User 83) local loss: 0.6639\n",
      "  Client 84 (User 84) local loss: 0.5995\n",
      "  Client 85 (User 85) local loss: 0.5432\n",
      "  Client 86 (User 86) local loss: 0.6671\n",
      "  Client 87 (User 87) local loss: 0.7017\n",
      "  Client 88 (User 88) local loss: 0.7244\n",
      "  Client 89 (User 89) local loss: 0.6077\n",
      "  Client 90 (User 90) local loss: 0.6789\n",
      "  Client 91 (User 91) local loss: 0.6534\n",
      "  Client 92 (User 92) local loss: 0.6417\n",
      "  Client 93 (User 93) local loss: 0.6897\n",
      "  Client 94 (User 94) local loss: 0.6815\n",
      "  Client 95 (User 95) local loss: 0.6476\n",
      "  Client 96 (User 96) local loss: 0.5789\n",
      "  Client 97 (User 97) local loss: 0.6276\n",
      "  Client 98 (User 98) local loss: 0.6321\n",
      "  Client 99 (User 99) local loss: 0.6905\n",
      "Round 9 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 10/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6339\n",
      "  Client 1 (User 1) local loss: 0.5896\n",
      "  Client 2 (User 2) local loss: 0.7370\n",
      "  Client 3 (User 3) local loss: 0.5999\n",
      "  Client 4 (User 4) local loss: 0.6698\n",
      "  Client 5 (User 5) local loss: 0.6411\n",
      "  Client 6 (User 6) local loss: 0.5978\n",
      "  Client 7 (User 7) local loss: 0.5037\n",
      "  Client 8 (User 8) local loss: 0.6553\n",
      "  Client 9 (User 9) local loss: 0.6391\n",
      "  Client 10 (User 10) local loss: 0.6545\n",
      "  Client 11 (User 11) local loss: 0.6374\n",
      "  Client 12 (User 12) local loss: 0.6043\n",
      "  Client 13 (User 13) local loss: 0.6084\n",
      "  Client 14 (User 14) local loss: 0.5226\n",
      "  Client 15 (User 15) local loss: 0.6028\n",
      "  Client 16 (User 16) local loss: 0.6677\n",
      "  Client 17 (User 17) local loss: 0.6601\n",
      "  Client 18 (User 18) local loss: 0.6512\n",
      "  Client 19 (User 19) local loss: 0.6917\n",
      "  Client 20 (User 20) local loss: 0.6235\n",
      "  Client 21 (User 21) local loss: 0.7033\n",
      "  Client 22 (User 22) local loss: 0.6282\n",
      "  Client 23 (User 23) local loss: 0.5834\n",
      "  Client 24 (User 24) local loss: 0.6519\n",
      "  Client 25 (User 25) local loss: 0.6605\n",
      "  Client 26 (User 26) local loss: 0.6103\n",
      "  Client 27 (User 27) local loss: 0.6105\n",
      "  Client 28 (User 28) local loss: 0.6729\n",
      "  Client 29 (User 29) local loss: 0.5837\n",
      "  Client 30 (User 30) local loss: 0.7033\n",
      "  Client 31 (User 31) local loss: 0.6198\n",
      "  Client 32 (User 32) local loss: 0.6039\n",
      "  Client 33 (User 33) local loss: 0.6335\n",
      "  Client 34 (User 34) local loss: 0.6809\n",
      "  Client 35 (User 35) local loss: 0.5114\n",
      "  Client 36 (User 36) local loss: 0.6465\n",
      "  Client 37 (User 37) local loss: 0.7032\n",
      "  Client 38 (User 38) local loss: 0.5925\n",
      "  Client 39 (User 39) local loss: 0.6945\n",
      "  Client 40 (User 40) local loss: 0.5627\n",
      "  Client 41 (User 41) local loss: 0.5585\n",
      "  Client 42 (User 42) local loss: 0.6161\n",
      "  Client 43 (User 43) local loss: 0.5503\n",
      "  Client 44 (User 44) local loss: 0.6752\n",
      "  Client 45 (User 45) local loss: 0.6598\n",
      "  Client 46 (User 46) local loss: 0.6258\n",
      "  Client 47 (User 47) local loss: 0.7073\n",
      "  Client 48 (User 48) local loss: 0.5750\n",
      "  Client 49 (User 49) local loss: 0.6240\n",
      "  Client 50 (User 50) local loss: 0.6578\n",
      "  Client 51 (User 51) local loss: 0.6558\n",
      "  Client 52 (User 52) local loss: 0.6221\n",
      "  Client 53 (User 53) local loss: 0.7013\n",
      "  Client 54 (User 54) local loss: 0.6083\n",
      "  Client 55 (User 55) local loss: 0.5921\n",
      "  Client 56 (User 56) local loss: 0.5352\n",
      "  Client 57 (User 57) local loss: 0.6457\n",
      "  Client 58 (User 58) local loss: 0.6547\n",
      "  Client 59 (User 59) local loss: 0.5581\n",
      "  Client 60 (User 60) local loss: 0.6912\n",
      "  Client 61 (User 61) local loss: 0.6100\n",
      "  Client 62 (User 62) local loss: 0.6324\n",
      "  Client 63 (User 63) local loss: 0.6120\n",
      "  Client 64 (User 64) local loss: 0.6509\n",
      "  Client 65 (User 65) local loss: 0.5336\n",
      "  Client 66 (User 66) local loss: 0.6041\n",
      "  Client 67 (User 67) local loss: 0.6505\n",
      "  Client 68 (User 68) local loss: 0.5715\n",
      "  Client 69 (User 69) local loss: 0.6516\n",
      "  Client 70 (User 70) local loss: 0.6157\n",
      "  Client 71 (User 71) local loss: 0.6113\n",
      "  Client 72 (User 72) local loss: 0.5585\n",
      "  Client 73 (User 73) local loss: 0.6048\n",
      "  Client 74 (User 74) local loss: 0.6688\n",
      "  Client 75 (User 75) local loss: 0.6523\n",
      "  Client 76 (User 76) local loss: 0.6143\n",
      "  Client 77 (User 77) local loss: 0.6292\n",
      "  Client 78 (User 78) local loss: 0.6914\n",
      "  Client 79 (User 79) local loss: 0.5981\n",
      "  Client 80 (User 80) local loss: 0.7280\n",
      "  Client 81 (User 81) local loss: 0.6142\n",
      "  Client 82 (User 82) local loss: 0.6000\n",
      "  Client 83 (User 83) local loss: 0.6466\n",
      "  Client 84 (User 84) local loss: 0.5601\n",
      "  Client 85 (User 85) local loss: 0.5393\n",
      "  Client 86 (User 86) local loss: 0.6586\n",
      "  Client 87 (User 87) local loss: 0.6921\n",
      "  Client 88 (User 88) local loss: 0.7211\n",
      "  Client 89 (User 89) local loss: 0.5706\n",
      "  Client 90 (User 90) local loss: 0.6730\n",
      "  Client 91 (User 91) local loss: 0.6554\n",
      "  Client 92 (User 92) local loss: 0.6406\n",
      "  Client 93 (User 93) local loss: 0.6809\n",
      "  Client 94 (User 94) local loss: 0.6751\n",
      "  Client 95 (User 95) local loss: 0.6237\n",
      "  Client 96 (User 96) local loss: 0.5737\n",
      "  Client 97 (User 97) local loss: 0.6247\n",
      "  Client 98 (User 98) local loss: 0.6268\n",
      "  Client 99 (User 99) local loss: 0.6885\n",
      "Round 10 completed. Global item embeddings updated.\n",
      "Federated training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 軽量 LLM 埋め込みモデルのロード (変更なし)\n",
    "plm_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "plm_tokenizer = AutoTokenizer.from_pretrained(plm_model_name)\n",
    "plm_model = AutoModel.from_pretrained(plm_model_name)\n",
    "\n",
    "# PLMは学習済みモデルのため、勾配計算を無効化\n",
    "for param in plm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "plm_embedding_dim = plm_model.config.hidden_size\n",
    "print(f\"PLM embedding dimension: {plm_embedding_dim}\")\n",
    "\n",
    "\n",
    "class ClientModel(nn.Module):\n",
    "    def __init__(self, num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.plm_model = plm_model\n",
    "        \n",
    "        # Joint Embedding Layer (module parameter θ_user)\n",
    "        self.user_joint_embedding_linear = nn.Linear(plm_embedding_dim, joint_embedding_output_dim)\n",
    "        \n",
    "        # Item Embedding Layer (module parameter θ_item)\n",
    "        self.local_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        # User Feature Refinement MLP (module parameter θ_umlp)\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(joint_embedding_output_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "        # Predictive Scoring Function (module parameter θ_score)\n",
    "        self.prediction_mlp = nn.Sequential(\n",
    "            nn.Linear(item_embedding_dim + joint_embedding_output_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, item_ids, user_texts_batch): \n",
    "        encoded_input = plm_tokenizer(user_texts_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        plm_output = self.plm_model(**encoded_input).last_hidden_state[:, 0, :]\n",
    "\n",
    "        user_raw_embedding = self.user_joint_embedding_linear(plm_output)\n",
    "        user_embedding = self.user_mlp(user_raw_embedding)\n",
    "\n",
    "        item_embedding = self.local_item_embedding(item_ids)\n",
    "\n",
    "        combined_features = torch.cat((user_embedding, item_embedding), dim=1)\n",
    "        logits = self.prediction_mlp(combined_features)\n",
    "        predictions = torch.sigmoid(logits)\n",
    "\n",
    "        return predictions, self.user_joint_embedding_linear.weight, self.local_item_embedding.weight\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, num_users, num_items, item_embedding_dim, joint_embedding_output_dim):\n",
    "        self.global_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "        # サーバーのグローバルアイテム埋め込みのためのオプティマイザ\n",
    "        # 学習率 (lr) はクライアントとは別に設定可能\n",
    "        self.global_item_optimizer = optim.Adam(self.global_item_embedding.parameters(), lr=0.01) # サーバー側の学習率\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        self.joint_embedding_output_dim = joint_embedding_output_dim\n",
    "    \n",
    "    def build_user_relationship_graph(self, user_linear_weights_map):\n",
    "        \"\"\"\n",
    "        各ユーザーのuser_joint_embedding_linear.weightからユーザー関係グラフを構築します。\n",
    "        論文の式 (15) に基づいています。 [cite: 106]\n",
    "\n",
    "        Args:\n",
    "            user_linear_weights_map (dict): {user_id: user_joint_embedding_linear.weight.data (d1, d2) Tensor}\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: ユーザーグラフの隣接行列 (NumPy配列)\n",
    "            list: グラフのノード順に対応するユーザーIDのリスト\n",
    "        \"\"\"\n",
    "        sorted_user_ids = sorted(user_linear_weights_map.keys())\n",
    "        if not sorted_user_ids:\n",
    "            return np.zeros((0, 0)), []\n",
    "\n",
    "        user_weight_vectors = np.array([\n",
    "            user_linear_weights_map[u_id].flatten().cpu().numpy() for u_id in sorted_user_ids\n",
    "        ])\n",
    "\n",
    "        similarity_matrix = cosine_similarity(user_weight_vectors)\n",
    "        user_graph_adj = similarity_matrix \n",
    "        \n",
    "        return user_graph_adj, sorted_user_ids\n",
    "\n",
    "    def update_global_item_embedding(self, user_local_item_weights, user_graph_adj, sorted_user_ids, client_data_sizes):\n",
    "        \"\"\"\n",
    "        ユーザー関係グラフに基づいてアイテム埋め込みを集約し、サーバーのオプティマイザでグローバル埋め込みを学習・更新します。\n",
    "        \n",
    "        Args:\n",
    "            user_local_item_weights (dict): {user_id: local_item_embedding.weight.data (Tensor)}\n",
    "            user_graph_adj (np.ndarray): ユーザーグラフの隣接行列\n",
    "            sorted_user_ids (list): user_graph_adj のノード順に対応するユーザーIDのリスト\n",
    "            client_data_sizes (dict): {user_id: そのユーザーのデータセットサイズ}\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: 更新されたグローバルアイテム埋め込みの重み\n",
    "        \"\"\"\n",
    "        if not user_local_item_weights:\n",
    "            return self.global_item_embedding.weight.data\n",
    "\n",
    "        item_embedding_matrix_A = torch.stack([\n",
    "            user_local_item_weights[u_id] for u_id in sorted_user_ids\n",
    "        ]) # (num_users, num_items, item_embedding_dim)\n",
    "\n",
    "        row_sums_graph = np.sum(user_graph_adj, axis=1, keepdims=True)\n",
    "        row_sums_graph[row_sums_graph == 0] = 1 \n",
    "        normalized_user_graph_adj = user_graph_adj / row_sums_graph\n",
    "        \n",
    "        normalized_user_graph_adj_tensor = torch.tensor(normalized_user_graph_adj, dtype=torch.float32)\n",
    "\n",
    "        R_tensor = torch.einsum('ij, jkd -> ikd', normalized_user_graph_adj_tensor, item_embedding_matrix_A)\n",
    "\n",
    "        # FedAvg: D = degree matrix at the time of aggregation\n",
    "        total_data_size = sum(client_data_sizes[u_id] for u_id in sorted_user_ids)\n",
    "        if total_data_size == 0:\n",
    "            return self.global_item_embedding.weight.data \n",
    "\n",
    "        weighted_sum_item_embeddings = torch.zeros_like(self.global_item_embedding.weight) # .dataは使わない\n",
    "        \n",
    "        for i, u_id in enumerate(sorted_user_ids):\n",
    "            weight = client_data_sizes[u_id] / total_data_size\n",
    "            weighted_sum_item_embeddings += weight * R_tensor[i]\n",
    "\n",
    "        # ここで、サーバーのグローバルアイテム埋め込みを学習させる\n",
    "        self.global_item_optimizer.zero_grad()\n",
    "        \n",
    "        # 現在のグローバル埋め込みと目標値 (weighted_sum_item_embeddings) との間のロスを計算\n",
    "        # MSELoss を使用して、目標値に近づけるように学習\n",
    "        loss_fn = nn.MSELoss()\n",
    "        # detach()を使ってweighted_sum_item_embeddingsからの勾配伝播は行わない\n",
    "        # サーバーがこの目標値に向けて自身を更新するイメージ\n",
    "        loss = loss_fn(self.global_item_embedding.weight, weighted_sum_item_embeddings.detach())\n",
    "        \n",
    "        loss.backward() # 勾配を計算\n",
    "        self.global_item_optimizer.step() # パラメータを更新\n",
    "        \n",
    "        return self.global_item_embedding.weight.data # 更新後のデータを返す\n",
    "\n",
    "# データセットの準備とクライアントへの分割 (1クライアント1ユーザー)\n",
    "num_users = 100\n",
    "num_items = 50\n",
    "num_clients = num_users \n",
    "\n",
    "user_texts = {i: f\"This user likes movies about {i % 5} and enjoys {i % 3}.\" for i in range(num_users)}\n",
    "\n",
    "interactions_list = []\n",
    "user_interaction_history = defaultdict(list) \n",
    "\n",
    "for u_id in range(num_users):\n",
    "    for i_id in range(num_items):\n",
    "        if np.random.rand() > 0.7:\n",
    "            interactions_list.append([u_id, i_id, 1])\n",
    "            user_interaction_history[u_id].append(i_id) \n",
    "        else:\n",
    "            interactions_list.append([u_id, i_id, 0])\n",
    "\n",
    "interactions = torch.tensor(interactions_list, dtype=torch.float32)\n",
    "\n",
    "client_user_map = {} \n",
    "client_datasets = {}\n",
    "client_original_data_sizes = {} \n",
    "for u_id in range(num_users):\n",
    "    client_id = u_id \n",
    "    client_user_map[client_id] = u_id \n",
    "    \n",
    "    client_interactions_indices = [i for i, (u, _, _) in enumerate(interactions_list) if u == u_id]\n",
    "    \n",
    "    if not client_interactions_indices:\n",
    "        print(f\"Warning: User {u_id} has no interactions. Client {client_id} will have an empty dataset.\")\n",
    "        client_subset = TensorDataset(\n",
    "            torch.empty(0, dtype=torch.long), \n",
    "            torch.empty(0, dtype=torch.long), \n",
    "            torch.empty(0, dtype=torch.float32)\n",
    "        )\n",
    "        client_original_data_sizes[client_id] = 0\n",
    "    else:\n",
    "        user_interaction_data_for_client = []\n",
    "        for idx in client_interactions_indices:\n",
    "            u_id_data, i_id_data, label_data = interactions_list[idx]\n",
    "            user_interaction_data_for_client.append((u_id_data, i_id_data, label_data))\n",
    "\n",
    "        users_tensor = torch.tensor([d[0] for d in user_interaction_data_for_client], dtype=torch.long)\n",
    "        items_tensor = torch.tensor([d[1] for d in user_interaction_data_for_client], dtype=torch.long)\n",
    "        labels_tensor = torch.tensor([d[2] for d in user_interaction_data_for_client], dtype=torch.float32)\n",
    "\n",
    "        client_subset = TensorDataset(users_tensor, items_tensor, labels_tensor)\n",
    "        client_original_data_sizes[client_id] = len(client_subset)\n",
    "    \n",
    "    client_datasets[client_id] = DataLoader(client_subset, batch_size=min(32, max(1, len(client_subset))), shuffle=True)\n",
    "\n",
    "print(f\"Number of users: {num_users}\")\n",
    "print(f\"Number of items: {num_items}\")\n",
    "print(f\"Total interactions: {len(interactions)}\")\n",
    "print(f\"Number of clients (1 client per user): {num_clients}\")\n",
    "\n",
    "\n",
    "# モデルのハイパーパラメータ\n",
    "item_embedding_dim = 32\n",
    "joint_embedding_output_dim = 32 \n",
    "\n",
    "# サーバーのインスタンス化\n",
    "server = Server(num_users, num_items, item_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "# 各クライアントのモデルを辞書で保持\n",
    "client_models = {}\n",
    "client_optimizers = {}\n",
    "for client_id in range(num_clients):\n",
    "    client_models[client_id] = ClientModel(\n",
    "        num_items,\n",
    "        item_embedding_dim,\n",
    "        plm_model,\n",
    "        plm_embedding_dim,\n",
    "        joint_embedding_output_dim\n",
    "    )\n",
    "    # NOTE:\n",
    "    # クライアントごとに最適化するパラメータを設定\n",
    "    # ここでは、user_joint_embedding_linear, local_item_embedding, prediction_layer が対象\n",
    "    # 単純にoptim.Adam(params = client_models[client_id].parameters(), lr=0.001)とすると、\n",
    "    # PLMも学習可能パラメータとなってしまうので、\n",
    "    # PLMのパラメータを除外したパラメータのみを取得してから、設定する.\n",
    "    trainable_params = [\n",
    "        p for name, p in client_models[client_id].named_parameters()\n",
    "        if not name.startswith('plm_model.')\n",
    "    ]\n",
    "\n",
    "    client_optimizers[client_id] = optim.Adam(\n",
    "        params=trainable_params,\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "# 学習ループ (フェデレーテッド学習ラウンド)\n",
    "num_communication_rounds = 10\n",
    "local_epochs = 1 \n",
    "\n",
    "for round_num in range(num_communication_rounds):\n",
    "    print(f\"\\n--- Communication Round {round_num + 1}/{num_communication_rounds} ---\")\n",
    "    \n",
    "    # サーバーからグローバルアイテム埋め込みをクライアントに配布\n",
    "    for client_id in range(num_clients):\n",
    "        client_models[client_id].local_item_embedding.weight.data.copy_(server.global_item_embedding.weight.data)\n",
    "\n",
    "    user_linear_weights_for_graph = {} # {user_id: user_joint_embedding_linear.weight.data (d1, d2) Tensor}\n",
    "    user_local_item_weights_to_server = {} # {user_id: local_item_embedding.weight.data (Tensor)}\n",
    "    client_reported_data_sizes = {} # クライアントが報告するデータセットサイズ\n",
    "    \n",
    "    # クライアントのローカル学習\n",
    "    for client_id in range(num_clients):\n",
    "        model = client_models[client_id]\n",
    "        optimizer = client_optimizers[client_id]\n",
    "        dataloader = client_datasets[client_id]\n",
    "        \n",
    "        model.train()\n",
    "        local_loss = 0\n",
    "        \n",
    "        current_user_id = client_user_map[client_id] \n",
    "        \n",
    "        client_reported_data_sizes[current_user_id] = client_original_data_sizes[client_id]\n",
    "\n",
    "        if len(dataloader.dataset) == 0:\n",
    "            print(f\"  Client {client_id} (User {current_user_id}) has no interactions, skipping local training.\")\n",
    "            user_linear_weights_for_graph[current_user_id] = model.user_joint_embedding_linear.weight.data.clone().flatten()\n",
    "            user_local_item_weights_to_server[current_user_id] = model.local_item_embedding.weight.data.clone()\n",
    "            continue\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            for user_ids_batch, item_ids_batch, labels_batch in dataloader:\n",
    "                assert torch.all(user_ids_batch == current_user_id) \n",
    "                current_user_texts = [user_texts[uid.item()] for uid in user_ids_batch]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions, user_joint_embedding_linear_weight, local_item_embedding_weight = model(\n",
    "                    user_ids_batch, item_ids_batch, current_user_texts\n",
    "                )\n",
    "                \n",
    "                loss = nn.BCELoss()(predictions.squeeze(), labels_batch)\n",
    "                \n",
    "                lambda_reg = 0.01 \n",
    "                \n",
    "                # Note: `local_item_embedding_weight` は `requires_grad=True` ですが、\n",
    "                # `server.global_item_embedding.weight.data` は `requires_grad=False` です。\n",
    "                # このため、`regularization_term` の勾配は `local_item_embedding_weight` にのみ伝播します。\n",
    "                # これは意図された動作です。\n",
    "                regularization_term = torch.mean(\n",
    "                    (local_item_embedding_weight - server.global_item_embedding.weight.data)**2\n",
    "                )\n",
    "                \n",
    "                loss = loss + lambda_reg * regularization_term\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                local_loss += loss.item()\n",
    "\n",
    "        user_linear_weights_for_graph[current_user_id] = user_joint_embedding_linear_weight.data.clone()\n",
    "        user_local_item_weights_to_server[current_user_id] = local_item_embedding_weight.data.clone()\n",
    "\n",
    "        print(f\"  Client {client_id} (User {current_user_id}) local loss: {local_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # サーバーでの処理\n",
    "    user_graph_adj, sorted_user_ids_for_graph = server.build_user_relationship_graph(\n",
    "        user_linear_weights_for_graph\n",
    "    )\n",
    "    \n",
    "    # グローバルアイテム埋め込みの更新を、サーバーのオプティマイザで行う関数を呼び出す\n",
    "    server.update_global_item_embedding(\n",
    "        user_local_item_weights_to_server, \n",
    "        user_graph_adj, \n",
    "        sorted_user_ids_for_graph,\n",
    "        client_reported_data_sizes \n",
    "    )\n",
    "\n",
    "    print(f\"Round {round_num + 1} completed. Global item embeddings updated.\")\n",
    "\n",
    "print(\"Federated training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-UD7q69fU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
