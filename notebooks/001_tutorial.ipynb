{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40617c9e",
   "metadata": {},
   "source": [
    "## 1. 必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8354aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f81cb7",
   "metadata": {},
   "source": [
    "## 2. データセットの準備 (ダミーデータ)\n",
    "\n",
    "この例では、MovieLens-100K データセットに似たダミーデータを使用します。ユーザーのテキスト特徴は単純な文字列とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d38ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasetの内容を確認\n",
      "(tensor(0), tensor(0), tensor(1.))\n",
      "(tensor(0), tensor(1), tensor(0.))\n",
      "(tensor(0), tensor(2), tensor(0.))\n",
      "(tensor(0), tensor(3), tensor(0.))\n",
      "(tensor(0), tensor(4), tensor(1.))\n",
      "(tensor(0), tensor(5), tensor(0.))\n",
      "(tensor(0), tensor(6), tensor(0.))\n",
      "(tensor(0), tensor(7), tensor(0.))\n",
      "(tensor(0), tensor(8), tensor(0.))\n",
      "(tensor(0), tensor(9), tensor(0.))\n",
      "len(dataset)=5000\n",
      "dataloaderの内容を確認\n",
      "len(dataloader)=100\n",
      " len(batch)=3\n",
      " batch=[tensor([17, 14,  0, 13, 85, 26, 59, 50, 38, 21, 19, 59, 17,  8, 76, 34, 88, 61,\n",
      "        30, 54, 42,  2, 46, 95,  0,  4, 10, 90, 38, 49, 62, 57, 46, 48, 80, 28,\n",
      "        68, 82, 95, 58, 12, 22, 84, 68,  9, 60, 36, 12, 93, 44]), tensor([ 0,  0, 19, 45, 38, 49,  6, 36, 24, 46, 33, 29, 13, 17, 39, 38,  6,  9,\n",
      "        36, 36, 11, 37, 13, 45, 44, 30, 40, 13, 44, 21, 40, 46, 44, 22, 47, 33,\n",
      "        21, 12, 30,  4, 28, 18, 21,  7, 23, 23, 31, 43, 20, 25]), tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "num_users = 100\n",
    "num_items = 50\n",
    "\n",
    "\n",
    "# ユーザーのテキスト特徴 (例: 趣味、自己紹介など)\n",
    "user_texts = [f\"This user likes movies about {i % 5} and enjoys {i % 3}.\" for i in range(num_users)]\n",
    "\n",
    "# ユーザーアイテムインタラクション (implicit feedback)\n",
    "# ユーザーID, アイテムID, 評価 (1: インタラクションあり, 0: なし)\n",
    "# 簡単のため、ランダムなインタラクションを生成\n",
    "interactions = []\n",
    "for u_id in range(num_users):\n",
    "    for i_id in range(num_items):\n",
    "        if np.random.rand() > 0.7:  # 約30%の確率でインタラクションあり\n",
    "            interactions.append([u_id, i_id, 1])\n",
    "        else:\n",
    "            interactions.append([u_id, i_id, 0])\n",
    "\n",
    "interactions = torch.tensor(interactions, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "dataset = TensorDataset(interactions[:, 0].long(), interactions[:, 1].long(), interactions[:, 2])\n",
    "dataloader = DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"datasetの内容を確認\")\n",
    "for i in range(10):\n",
    "    print(dataset[i])\n",
    "print(f\"{len(dataset)=}\")\n",
    "\n",
    "print(\"dataloaderの内容を確認\")\n",
    "for batch in dataloader:\n",
    "    break  # 最初のバッチだけ確認\n",
    "print(f\"{len(dataloader)=}\\n\" ,f\"{len(batch)=}\\n\", f\"{batch=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf5380",
   "metadata": {},
   "source": [
    "## 3. 軽量 LLM 埋め込みモデルのロード\n",
    "Hugging Face の all-MiniLM-L6-v2 を使用します。これは軽量で、文の埋め込みに適しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6789a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face の軽量 LLM 埋め込みモデルのロード\n",
    "plm_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "plm_tokenizer = AutoTokenizer.from_pretrained(plm_model_name)\n",
    "plm_model = AutoModel.from_pretrained(plm_model_name)\n",
    "\n",
    "# PLMは学習済みモデルのため、勾配計算を無効化\n",
    "for param in plm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# PLMの埋め込み次元を取得\n",
    "plm_embedding_dim = plm_model.config.hidden_size\n",
    "print(f\"PLM embedding dimension: {plm_embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6605620",
   "metadata": {},
   "source": [
    "## 4. モデルの定義 (Transformer Block と PLM / PromptOutputLayer を線形層で代替)\n",
    "ここでは、論文の図2 (Client Model) を参考に、以下の点を変更してモデルを定義します。\n",
    "\n",
    "- **Joint Embedding Layer**: PLM と PromptOutputLayer の代わりに、直接 Hugging Face の LLM 埋め込みモデルを使用し、その出力に線形層を適用します。ユーザーのテキスト特徴から直接ユーザー埋め込みを生成します。\n",
    "\n",
    "- **Transformer Block**: 単純な線形層に置き換えます。ユーザー埋め込みとアイテム埋め込みを結合し、予測を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleUFGraphFR(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        item_embedding_dim: int,\n",
    "        plm_model,\n",
    "        plm_embedding_dim: int,\n",
    "        joint_embedding_output_dim: int\n",
    "    ):\n",
    "        super(SimpleUFGraphFR, self).__init__()\n",
    "        self.plm_model = plm_model\n",
    "        self.item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        self.user_joint_embedding_linear = nn.Linear(plm_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "        # ユーザ埋め込みとアイテム埋め込みを結合して予測する.\n",
    "        self.prediction_layer = nn.Linear(joint_embedding_output_dim + item_embedding_dim, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, user_texts_batch):\n",
    "        # =========================\n",
    "        # まずはユーザ埋め込みを作成する\n",
    "\n",
    "        # NOTE バッチ毎にテキストを処理する\n",
    "        encoded_input = plm_tokenizer(user_texts_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "        plm_output = self.plm_model(**encoded_input).last_hidden_state[:, 0, :] # [CLS]トークンの埋め込みを使用\n",
    "\n",
    "        # joint embedding layerの線形変換\n",
    "        user_embedding = self.user_joint_embedding_linear(plm_output)  # (batch_size, joint_embedding_output_dim)\n",
    "        # ユーザ埋め込み作成完了\n",
    "        # =========================\n",
    "\n",
    "        # =========================\n",
    "        # アイテム埋め込みを取得\n",
    "        item_embedding = self.item_embedding(item_ids)  # (batch_size, item_embedding_dim)\n",
    "        # アイテム埋め込み完了\n",
    "        # =========================\n",
    "\n",
    "\n",
    "        # ユーザー埋め込みとアイテム埋め込みを結合\n",
    "        combined_features = torch.cat((user_embedding, item_embedding), dim=1)\n",
    "        # 予測\n",
    "        prediction = torch.sigmoid(self.prediction_layer(combined_features))\n",
    "        return prediction, self.user_joint_embedding_linear.weight # 線形層の重みを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459a20c",
   "metadata": {},
   "source": [
    "## 5. モデルの初期化と学習ループ\n",
    "このステップでは、グラフ構築やサーバー側での集約は行わず、各クライアント（この単純な実装では全体で1つのモデル）がローカルで学習する形式とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "809d70d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6218\n",
      "Epoch 2/10, Loss: 0.6172\n",
      "Epoch 3/10, Loss: 0.6141\n",
      "Epoch 4/10, Loss: 0.6121\n",
      "Epoch 5/10, Loss: 0.6134\n",
      "Epoch 6/10, Loss: 0.6108\n",
      "Epoch 7/10, Loss: 0.6105\n",
      "Epoch 8/10, Loss: 0.6104\n",
      "Epoch 9/10, Loss: 0.6102\n",
      "Epoch 10/10, Loss: 0.6113\n"
     ]
    }
   ],
   "source": [
    "item_embedding_dim = 32\n",
    "joint_embedding_output_dim = 100 # NOTE: 論文では、32だった.\n",
    "\n",
    "# モデルのインスタンス化\n",
    "model = SimpleUFGraphFR(num_users, num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "# オプティマイザと損失関数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# NOTE:\n",
    "# PyTorchで分類問題での損失関数は一般的には、nn.BCEWithLogitsLoss()を使うが、\n",
    "# 今回は、予測層でsigmoidを使っているのでBCELossを利用する。\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "# 学習ループ\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for user_ids_batch, item_ids_batch, labels_batch in dataloader:\n",
    "        # バッチ内のユーザIDに対応するテキスト特徴を取得\n",
    "        current_user_texts = [user_texts[uid.item()] for uid in user_ids_batch]\n",
    "\n",
    "        # 勾配初期化\n",
    "        optimizer.zero_grad()\n",
    "        predictions, _ = model(user_ids_batch, item_ids_batch, current_user_texts)\n",
    "\n",
    "        # 損失計算\n",
    "        loss = criterion(predictions.squeeze(), labels_batch)\n",
    "\n",
    "        # 勾配計算とパラメータ更新\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e39a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-UD7q69fU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
