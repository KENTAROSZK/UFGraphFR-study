{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a757f5de",
   "metadata": {},
   "source": [
    "003に対して以下を追加.\n",
    "\n",
    "- 損失関数への正則化項の追加: 論文の式(12)にある、グローバルアイテム埋め込みとユーザー固有のネガティブサンプリングアイテム埋め込み間の正則化項 \n",
    "mathcalR(e_global,e_i −) を損失関数に含めます 。これにより、ローカルモデルがグローバルな知識から逸脱しすぎないように制約します\n",
    "- ユーザー特徴抽出 MLP の導入: ユーザー特徴のより高次な表現を抽出するために、User Feature Refinement MLP を導入します "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdae4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0def4c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 100\n",
      "Number of items: 50\n",
      "Total interactions: 5000\n",
      "Number of clients (1 client per user): 100\n"
     ]
    }
   ],
   "source": [
    "# データセットの準備とクライアントへの分割 (1クライアント1ユーザー)\n",
    "num_users = 100\n",
    "num_items = 50\n",
    "num_clients = num_users # 1クライアント1ユーザー\n",
    "\n",
    "user_texts = {i: f\"This user likes movies about {i % 5} and enjoys {i % 3}.\" for i in range(num_users)}\n",
    "\n",
    "interactions_list = []\n",
    "# ユーザーのインタラクション履歴はTransformer Blockがないため不要ですが、\n",
    "# ダミーデータの整合性のために残します。\n",
    "user_interaction_history = defaultdict(list) \n",
    "\n",
    "for u_id in range(num_users):\n",
    "    for i_id in range(num_items):\n",
    "        if np.random.rand() > 0.7:\n",
    "            interactions_list.append([u_id, i_id, 1])\n",
    "            user_interaction_history[u_id].append(i_id) \n",
    "        else:\n",
    "            interactions_list.append([u_id, i_id, 0])\n",
    "\n",
    "interactions = torch.tensor(interactions_list, dtype=torch.float32)\n",
    "\n",
    "client_user_map = {} # {client_id: user_id}\n",
    "client_datasets = {}\n",
    "for u_id in range(num_users):\n",
    "    client_id = u_id\n",
    "    client_user_map[client_id] = u_id\n",
    "\n",
    "    client_interactions_indices = [i for i, (u, _, _) in enumerate(interactions_list) if u == u_id]\n",
    "\n",
    "    # Transformer Blockがないため、 historical_item_sequences は DataLoader に含めない\n",
    "    user_interaction_data_for_client = []\n",
    "    for idx in client_interactions_indices:\n",
    "        u_id_data, i_id_data, label_data = interactions_list[idx]\n",
    "        user_interaction_data_for_client.append((u_id_data, i_id_data, label_data))\n",
    "\n",
    "    users_tensor = torch.tensor([d[0] for d in user_interaction_data_for_client], dtype=torch.long)\n",
    "    items_tensor = torch.tensor([d[1] for d in user_interaction_data_for_client], dtype=torch.long)\n",
    "    labels_tensor = torch.tensor([d[2] for d in user_interaction_data_for_client], dtype=torch.float32)\n",
    "\n",
    "    client_subset = TensorDataset(users_tensor, items_tensor, labels_tensor)\n",
    "\n",
    "    client_datasets[client_id] = DataLoader(client_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Number of users: {num_users}\")\n",
    "print(f\"Number of items: {num_items}\")\n",
    "print(f\"Total interactions: {len(interactions)}\")\n",
    "print(f\"Number of clients (1 client per user): {num_clients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a62e8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# 軽量 LLM 埋め込みモデルのロード (変更なし)\n",
    "plm_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "plm_tokenizer = AutoTokenizer.from_pretrained(plm_model_name)\n",
    "plm_model = AutoModel.from_pretrained(plm_model_name)\n",
    "\n",
    "# PLMは学習済みモデルのため、勾配計算を無効化\n",
    "for param in plm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "plm_embedding_dim = plm_model.config.hidden_size\n",
    "print(f\"PLM embedding dimension: {plm_embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b01e0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientModel(nn.Module):\n",
    "    def __init__(self, num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.plm_model = plm_model\n",
    "\n",
    "        # Joint Embedding Layer (module parameter θ_user) [cite: 64]\n",
    "        # 論文の式(3) e_u = h(v_u) = v_u W_d1xd + b [cite: 78]\n",
    "        self.user_joint_embedding_linear = nn.Linear(plm_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "        # Item Embedding Layer (module parameter θ_item) [cite: 64]\n",
    "        self.local_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        # User Feature Refinement MLP (module parameter θ_umlp) [cite: 66]\n",
    "        # 論文のImplementation Detailsで「user's mlp layer uses a two-layer mlp layer with a 32-64-32 architecture」とある [cite: 169]\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(joint_embedding_output_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32) # 出力次元はユーザー埋め込み次元と同じ32に設定 [cite: 169]\n",
    "        )\n",
    "\n",
    "        # Predictive Scoring Function (module parameter θ_score) [cite: 67]\n",
    "        # 論文のImplementation Detailsで「32->16->8->1」のスキーマを持つMLPを使用とある [cite: 168]\n",
    "        self.prediction_mlp = nn.Sequential(\n",
    "            nn.Linear(item_embedding_dim + joint_embedding_output_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    # Transformer Block は削除されたため、historical_item_sequences は不要\n",
    "    def forward(self, user_ids, item_ids, user_texts_batch): \n",
    "        # ユーザーのテキスト特徴をPLMで埋め込み\n",
    "        encoded_input = plm_tokenizer(user_texts_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        plm_output = self.plm_model(**encoded_input).last_hidden_state[:, 0, :] # [CLS]トークンの埋め込みを使用\n",
    "\n",
    "        # Joint Embedding Layer: テキスト埋め込みからユーザー特徴ベクトルを生成\n",
    "        user_raw_embedding = self.user_joint_embedding_linear(plm_output)\n",
    "\n",
    "        # User Feature Refinement MLP: ユーザー特徴の高次表現を抽出 [cite: 66]\n",
    "        user_embedding = self.user_mlp(user_raw_embedding) # (batch_size, joint_embedding_output_dim)\n",
    "\n",
    "        # アイテム埋め込み\n",
    "        item_embedding = self.local_item_embedding(item_ids) # (batch_size, item_embedding_dim)\n",
    "\n",
    "        # 予測層への入力は、User MLPの出力（ユーザー特徴）とターゲットアイテムの埋め込みを結合 [cite: 67]\n",
    "        combined_features = torch.cat((user_embedding, item_embedding), dim=1)\n",
    "        logits = self.prediction_mlp(combined_features)\n",
    "        predictions = torch.sigmoid(logits)\n",
    "\n",
    "        # グラフ構築とアイテム集約のために、user_joint_embedding_linear.weight と local_item_embedding.weight を返す\n",
    "        # 論文の「Parameter Uploading: Clients transmit user joint embedding weights and local item embeddings to the server.」 [cite: 61]\n",
    "        return predictions, self.user_joint_embedding_linear.weight, self.local_item_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45c765b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, num_users, num_items, item_embedding_dim, joint_embedding_output_dim):\n",
    "        self.global_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        self.joint_embedding_output_dim = joint_embedding_output_dim\n",
    "\n",
    "    def build_user_relationship_graph(self, user_linear_weights_map):\n",
    "        \"\"\"\n",
    "        各ユーザーのuser_joint_embedding_linear.weightからユーザー関係グラフを構築します。\n",
    "        論文の式 (15) に基づいています。 [cite: 106]\n",
    "\n",
    "        Args:\n",
    "            user_linear_weights_map (dict): {user_id: user_joint_embedding_linear.weight.data (d1, d2) Tensor}\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: ユーザーグラフの隣接行列 (NumPy配列)\n",
    "            list: グラフのノード順に対応するユーザーIDのリスト\n",
    "        \"\"\"\n",
    "        sorted_user_ids = sorted(user_linear_weights_map.keys())\n",
    "        if not sorted_user_ids:\n",
    "            return np.zeros((0, 0)), []\n",
    "\n",
    "        # 各ユーザーの線形層の重みベクトルを収集\n",
    "        # 論文の「w_i = vec(W_i)」に相当 [cite: 105]\n",
    "        user_weight_vectors = np.array([\n",
    "            user_linear_weights_map[u_id].flatten().cpu().numpy() for u_id in sorted_user_ids\n",
    "        ])\n",
    "\n",
    "        # コサイン類似度で類似度行列を計算 (S_ij) [cite: 106]\n",
    "        similarity_matrix = cosine_similarity(user_weight_vectors)\n",
    "\n",
    "        # ここでは簡単のため、完全な類似度グラフを使用 (S' に相当) [cite: 108]\n",
    "        # 論文の「take the top-N in the highest similarity list」 は、後のステップで実装可能 [cite: 108]\n",
    "        user_graph_adj = similarity_matrix\n",
    "\n",
    "        return user_graph_adj, sorted_user_ids\n",
    "\n",
    "    def aggregate_item_embeddings(self, user_local_item_weights, user_graph_adj, sorted_user_ids):\n",
    "        \"\"\"\n",
    "        ユーザー関係グラフに基づいて、アイテム埋め込みをグローバルに集約します。\n",
    "        論文の式 (16) と (17) に基づいています。 [cite: 111, 114]\n",
    "\n",
    "        Args:\n",
    "            user_local_item_weights (dict): {user_id: local_item_embedding.weight.data (Tensor)}\n",
    "            user_graph_adj (np.ndarray): ユーザーグラフの隣接行列\n",
    "            sorted_user_ids (list): user_graph_adj のノード順に対応するユーザーIDのリスト\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 更新されたグローバルアイテム埋め込みの重み\n",
    "        \"\"\"\n",
    "\n",
    "        # グラフの順序に合わせて各ユーザーのアイテム埋め込みを行列Aとしてまとめる\n",
    "        # A は (num_users, num_items, item_embedding_dim)\n",
    "        # 論文の「A is the round item embedding matrix, the I-th row represents the item embedding obtained from user i」に相当 [cite: 111]\n",
    "        item_embedding_matrix_A = torch.stack([\n",
    "            user_local_item_weights[u_id] for u_id in sorted_user_ids\n",
    "        ]) # (num_users, num_items, item_embedding_dim)\n",
    "\n",
    "        # グラフの正規化 (S'')\n",
    "        # NOTE: 正規化が必要な理由\n",
    "        ### スケール調整と数値安定性: 隣接行列をそのまま使うと、ノードの次数（接続数）が大きいほど、そのノードから受け取る情報の合計が非常に大きくなってしまいます。これにより、特徴量のスケールが大きくなりすぎたり、訓練中に勾配爆発を引き起こしたりする可能性があります。正規化は、この影響を均一化し、数値的な安定性を確保するのに役立ちます 。\n",
    "        ### 特徴量の平滑化と拡散: 正規化は、ノードの特徴量（この場合はアイテム埋め込み）が隣接ノードに適切に伝播・拡散されることを保証します。正規化されていない場合、高次数のノードが支配的になり、低次数のノードの情報が埋もれてしまう可能性があります。\n",
    "        ### GCNの理論的根拠: LightGCNのようなGCNモデルでは、グラフ畳み込み操作がグラフ上の情報の平滑化と拡散として機能します 。正規化は、この平滑化プロセスが効果的に機能するために不可欠です。\n",
    "        row_sums_graph = np.sum(user_graph_adj, axis=1, keepdims=True)\n",
    "        row_sums_graph[row_sums_graph == 0] = 1\n",
    "        normalized_user_graph_adj = user_graph_adj / row_sums_graph\n",
    "\n",
    "        normalized_user_graph_adj_tensor = torch.tensor(normalized_user_graph_adj, dtype=torch.float32)\n",
    "\n",
    "        # グラフ畳み込み (R = S'' A) [cite: 111]\n",
    "        # R は (num_users, num_items, item_embedding_dim) となる\n",
    "        # MatMul: (num_users, num_users) x (num_users, num_items, item_embedding_dim)\n",
    "        # Einstein Summation Convention: 'ij, jkd -> ikd'\n",
    "        R_tensor = torch.einsum('ij, jkd -> ikd', normalized_user_graph_adj_tensor, item_embedding_matrix_A)\n",
    "\n",
    "        # グローバルアイテム埋め込みの更新 (θ_global = DR) [cite: 113, 114]\n",
    "        # ここではDを全ユーザーの単純平均と解釈 (Rの0次元目を平均)\n",
    "        new_global_item_embedding_weight = R_tensor.mean(dim=0) # (num_items, item_embedding_dim)\n",
    "\n",
    "        # サーバーのグローバルアイテム埋め込みを直接更新\n",
    "        self.global_item_embedding.weight.data.copy_(new_global_item_embedding_weight)\n",
    "\n",
    "        return self.global_item_embedding.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c59d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Communication Round 1/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7057\n",
      "  Client 1 (User 1) local loss: 0.6584\n",
      "  Client 2 (User 2) local loss: 0.6494\n",
      "  Client 3 (User 3) local loss: 0.7032\n",
      "  Client 4 (User 4) local loss: 0.7420\n",
      "  Client 5 (User 5) local loss: 0.7785\n",
      "  Client 6 (User 6) local loss: 0.7540\n",
      "  Client 7 (User 7) local loss: 0.7494\n",
      "  Client 8 (User 8) local loss: 0.7111\n",
      "  Client 9 (User 9) local loss: 0.7557\n",
      "  Client 10 (User 10) local loss: 0.7830\n",
      "  Client 11 (User 11) local loss: 0.6777\n",
      "  Client 12 (User 12) local loss: 0.6591\n",
      "  Client 13 (User 13) local loss: 0.6994\n",
      "  Client 14 (User 14) local loss: 0.7935\n",
      "  Client 15 (User 15) local loss: 0.7966\n",
      "  Client 16 (User 16) local loss: 0.6800\n",
      "  Client 17 (User 17) local loss: 0.6641\n",
      "  Client 18 (User 18) local loss: 0.6642\n",
      "  Client 19 (User 19) local loss: 0.6925\n",
      "  Client 20 (User 20) local loss: 0.6919\n",
      "  Client 21 (User 21) local loss: 0.7463\n",
      "  Client 22 (User 22) local loss: 0.6502\n",
      "  Client 23 (User 23) local loss: 0.7519\n",
      "  Client 24 (User 24) local loss: 0.6470\n",
      "  Client 25 (User 25) local loss: 0.6534\n",
      "  Client 26 (User 26) local loss: 0.6618\n",
      "  Client 27 (User 27) local loss: 0.6549\n",
      "  Client 28 (User 28) local loss: 0.5973\n",
      "  Client 29 (User 29) local loss: 0.7181\n",
      "  Client 30 (User 30) local loss: 0.6902\n",
      "  Client 31 (User 31) local loss: 0.6324\n",
      "  Client 32 (User 32) local loss: 0.7023\n",
      "  Client 33 (User 33) local loss: 0.7234\n",
      "  Client 34 (User 34) local loss: 0.6751\n",
      "  Client 35 (User 35) local loss: 0.7830\n",
      "  Client 36 (User 36) local loss: 0.7322\n",
      "  Client 37 (User 37) local loss: 0.6213\n",
      "  Client 38 (User 38) local loss: 0.6979\n",
      "  Client 39 (User 39) local loss: 0.6791\n",
      "  Client 40 (User 40) local loss: 0.7667\n",
      "  Client 41 (User 41) local loss: 0.7725\n",
      "  Client 42 (User 42) local loss: 0.6324\n",
      "  Client 43 (User 43) local loss: 0.6998\n",
      "  Client 44 (User 44) local loss: 0.8059\n",
      "  Client 45 (User 45) local loss: 0.6966\n",
      "  Client 46 (User 46) local loss: 0.7456\n",
      "  Client 47 (User 47) local loss: 0.7276\n",
      "  Client 48 (User 48) local loss: 0.7382\n",
      "  Client 49 (User 49) local loss: 0.7715\n",
      "  Client 50 (User 50) local loss: 0.7913\n",
      "  Client 51 (User 51) local loss: 0.6857\n",
      "  Client 52 (User 52) local loss: 0.6658\n",
      "  Client 53 (User 53) local loss: 0.8264\n",
      "  Client 54 (User 54) local loss: 0.6769\n",
      "  Client 55 (User 55) local loss: 0.7115\n",
      "  Client 56 (User 56) local loss: 0.6652\n",
      "  Client 57 (User 57) local loss: 0.6392\n",
      "  Client 58 (User 58) local loss: 0.6695\n",
      "  Client 59 (User 59) local loss: 0.6947\n",
      "  Client 60 (User 60) local loss: 0.7907\n",
      "  Client 61 (User 61) local loss: 0.7763\n",
      "  Client 62 (User 62) local loss: 0.7604\n",
      "  Client 63 (User 63) local loss: 0.6409\n",
      "  Client 64 (User 64) local loss: 0.6330\n",
      "  Client 65 (User 65) local loss: 0.7669\n",
      "  Client 66 (User 66) local loss: 0.7362\n",
      "  Client 67 (User 67) local loss: 0.6564\n",
      "  Client 68 (User 68) local loss: 0.7415\n",
      "  Client 69 (User 69) local loss: 0.6804\n",
      "  Client 70 (User 70) local loss: 0.7861\n",
      "  Client 71 (User 71) local loss: 0.7009\n",
      "  Client 72 (User 72) local loss: 0.6567\n",
      "  Client 73 (User 73) local loss: 0.7550\n",
      "  Client 74 (User 74) local loss: 0.6724\n",
      "  Client 75 (User 75) local loss: 0.6834\n",
      "  Client 76 (User 76) local loss: 0.6877\n",
      "  Client 77 (User 77) local loss: 0.6213\n",
      "  Client 78 (User 78) local loss: 0.6754\n",
      "  Client 79 (User 79) local loss: 0.6308\n",
      "  Client 80 (User 80) local loss: 0.6345\n",
      "  Client 81 (User 81) local loss: 0.6711\n",
      "  Client 82 (User 82) local loss: 0.6391\n",
      "  Client 83 (User 83) local loss: 0.7302\n",
      "  Client 84 (User 84) local loss: 0.6789\n",
      "  Client 85 (User 85) local loss: 0.6369\n",
      "  Client 86 (User 86) local loss: 0.6517\n",
      "  Client 87 (User 87) local loss: 0.7485\n",
      "  Client 88 (User 88) local loss: 0.6884\n",
      "  Client 89 (User 89) local loss: 0.7475\n",
      "  Client 90 (User 90) local loss: 0.7132\n",
      "  Client 91 (User 91) local loss: 0.7294\n",
      "  Client 92 (User 92) local loss: 0.7120\n",
      "  Client 93 (User 93) local loss: 0.7532\n",
      "  Client 94 (User 94) local loss: 0.6735\n",
      "  Client 95 (User 95) local loss: 0.6631\n",
      "  Client 96 (User 96) local loss: 0.6495\n",
      "  Client 97 (User 97) local loss: 0.7188\n",
      "  Client 98 (User 98) local loss: 0.6674\n",
      "  Client 99 (User 99) local loss: 0.6965\n",
      "Round 1 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 2/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7042\n",
      "  Client 1 (User 1) local loss: 0.6596\n",
      "  Client 2 (User 2) local loss: 0.6413\n",
      "  Client 3 (User 3) local loss: 0.6991\n",
      "  Client 4 (User 4) local loss: 0.7340\n",
      "  Client 5 (User 5) local loss: 0.7648\n",
      "  Client 6 (User 6) local loss: 0.7418\n",
      "  Client 7 (User 7) local loss: 0.7447\n",
      "  Client 8 (User 8) local loss: 0.7042\n",
      "  Client 9 (User 9) local loss: 0.7441\n",
      "  Client 10 (User 10) local loss: 0.7729\n",
      "  Client 11 (User 11) local loss: 0.6696\n",
      "  Client 12 (User 12) local loss: 0.6564\n",
      "  Client 13 (User 13) local loss: 0.6935\n",
      "  Client 14 (User 14) local loss: 0.7926\n",
      "  Client 15 (User 15) local loss: 0.7792\n",
      "  Client 16 (User 16) local loss: 0.6761\n",
      "  Client 17 (User 17) local loss: 0.6576\n",
      "  Client 18 (User 18) local loss: 0.6652\n",
      "  Client 19 (User 19) local loss: 0.6916\n",
      "  Client 20 (User 20) local loss: 0.6894\n",
      "  Client 21 (User 21) local loss: 0.7188\n",
      "  Client 22 (User 22) local loss: 0.6473\n",
      "  Client 23 (User 23) local loss: 0.7626\n",
      "  Client 24 (User 24) local loss: 0.6417\n",
      "  Client 25 (User 25) local loss: 0.6429\n",
      "  Client 26 (User 26) local loss: 0.6586\n",
      "  Client 27 (User 27) local loss: 0.6510\n",
      "  Client 28 (User 28) local loss: 0.6087\n",
      "  Client 29 (User 29) local loss: 0.7096\n",
      "  Client 30 (User 30) local loss: 0.6856\n",
      "  Client 31 (User 31) local loss: 0.6234\n",
      "  Client 32 (User 32) local loss: 0.6928\n",
      "  Client 33 (User 33) local loss: 0.7185\n",
      "  Client 34 (User 34) local loss: 0.6724\n",
      "  Client 35 (User 35) local loss: 0.7734\n",
      "  Client 36 (User 36) local loss: 0.7242\n",
      "  Client 37 (User 37) local loss: 0.6277\n",
      "  Client 38 (User 38) local loss: 0.6917\n",
      "  Client 39 (User 39) local loss: 0.6711\n",
      "  Client 40 (User 40) local loss: 0.7518\n",
      "  Client 41 (User 41) local loss: 0.7646\n",
      "  Client 42 (User 42) local loss: 0.6347\n",
      "  Client 43 (User 43) local loss: 0.6869\n",
      "  Client 44 (User 44) local loss: 0.7888\n",
      "  Client 45 (User 45) local loss: 0.6909\n",
      "  Client 46 (User 46) local loss: 0.7501\n",
      "  Client 47 (User 47) local loss: 0.7183\n",
      "  Client 48 (User 48) local loss: 0.7329\n",
      "  Client 49 (User 49) local loss: 0.7605\n",
      "  Client 50 (User 50) local loss: 0.7814\n",
      "  Client 51 (User 51) local loss: 0.6811\n",
      "  Client 52 (User 52) local loss: 0.6588\n",
      "  Client 53 (User 53) local loss: 0.8098\n",
      "  Client 54 (User 54) local loss: 0.6705\n",
      "  Client 55 (User 55) local loss: 0.7051\n",
      "  Client 56 (User 56) local loss: 0.6767\n",
      "  Client 57 (User 57) local loss: 0.6362\n",
      "  Client 58 (User 58) local loss: 0.6655\n",
      "  Client 59 (User 59) local loss: 0.6928\n",
      "  Client 60 (User 60) local loss: 0.7821\n",
      "  Client 61 (User 61) local loss: 0.7711\n",
      "  Client 62 (User 62) local loss: 0.7535\n",
      "  Client 63 (User 63) local loss: 0.6409\n",
      "  Client 64 (User 64) local loss: 0.6308\n",
      "  Client 65 (User 65) local loss: 0.7544\n",
      "  Client 66 (User 66) local loss: 0.7295\n",
      "  Client 67 (User 67) local loss: 0.6438\n",
      "  Client 68 (User 68) local loss: 0.7268\n",
      "  Client 69 (User 69) local loss: 0.6715\n",
      "  Client 70 (User 70) local loss: 0.8045\n",
      "  Client 71 (User 71) local loss: 0.6943\n",
      "  Client 72 (User 72) local loss: 0.6479\n",
      "  Client 73 (User 73) local loss: 0.7477\n",
      "  Client 74 (User 74) local loss: 0.6629\n",
      "  Client 75 (User 75) local loss: 0.6797\n",
      "  Client 76 (User 76) local loss: 0.6875\n",
      "  Client 77 (User 77) local loss: 0.6190\n",
      "  Client 78 (User 78) local loss: 0.6735\n",
      "  Client 79 (User 79) local loss: 0.6307\n",
      "  Client 80 (User 80) local loss: 0.6228\n",
      "  Client 81 (User 81) local loss: 0.6622\n",
      "  Client 82 (User 82) local loss: 0.6281\n",
      "  Client 83 (User 83) local loss: 0.7277\n",
      "  Client 84 (User 84) local loss: 0.6753\n",
      "  Client 85 (User 85) local loss: 0.6302\n",
      "  Client 86 (User 86) local loss: 0.6305\n",
      "  Client 87 (User 87) local loss: 0.7367\n",
      "  Client 88 (User 88) local loss: 0.6810\n",
      "  Client 89 (User 89) local loss: 0.7450\n",
      "  Client 90 (User 90) local loss: 0.7101\n",
      "  Client 91 (User 91) local loss: 0.7206\n",
      "  Client 92 (User 92) local loss: 0.7010\n",
      "  Client 93 (User 93) local loss: 0.7497\n",
      "  Client 94 (User 94) local loss: 0.6964\n",
      "  Client 95 (User 95) local loss: 0.6527\n",
      "  Client 96 (User 96) local loss: 0.6510\n",
      "  Client 97 (User 97) local loss: 0.7080\n",
      "  Client 98 (User 98) local loss: 0.6709\n",
      "  Client 99 (User 99) local loss: 0.6960\n",
      "Round 2 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 3/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7006\n",
      "  Client 1 (User 1) local loss: 0.6497\n",
      "  Client 2 (User 2) local loss: 0.6351\n",
      "  Client 3 (User 3) local loss: 0.6969\n",
      "  Client 4 (User 4) local loss: 0.7285\n",
      "  Client 5 (User 5) local loss: 0.7523\n",
      "  Client 6 (User 6) local loss: 0.7399\n",
      "  Client 7 (User 7) local loss: 0.7338\n",
      "  Client 8 (User 8) local loss: 0.6956\n",
      "  Client 9 (User 9) local loss: 0.7400\n",
      "  Client 10 (User 10) local loss: 0.7683\n",
      "  Client 11 (User 11) local loss: 0.6643\n",
      "  Client 12 (User 12) local loss: 0.6557\n",
      "  Client 13 (User 13) local loss: 0.6873\n",
      "  Client 14 (User 14) local loss: 0.7775\n",
      "  Client 15 (User 15) local loss: 0.7791\n",
      "  Client 16 (User 16) local loss: 0.6733\n",
      "  Client 17 (User 17) local loss: 0.6479\n",
      "  Client 18 (User 18) local loss: 0.6639\n",
      "  Client 19 (User 19) local loss: 0.6902\n",
      "  Client 20 (User 20) local loss: 0.6869\n",
      "  Client 21 (User 21) local loss: 0.7468\n",
      "  Client 22 (User 22) local loss: 0.6397\n",
      "  Client 23 (User 23) local loss: 0.7461\n",
      "  Client 24 (User 24) local loss: 0.6388\n",
      "  Client 25 (User 25) local loss: 0.6412\n",
      "  Client 26 (User 26) local loss: 0.6529\n",
      "  Client 27 (User 27) local loss: 0.6403\n",
      "  Client 28 (User 28) local loss: 0.5748\n",
      "  Client 29 (User 29) local loss: 0.7055\n",
      "  Client 30 (User 30) local loss: 0.6766\n",
      "  Client 31 (User 31) local loss: 0.6286\n",
      "  Client 32 (User 32) local loss: 0.6837\n",
      "  Client 33 (User 33) local loss: 0.7080\n",
      "  Client 34 (User 34) local loss: 0.6668\n",
      "  Client 35 (User 35) local loss: 0.7607\n",
      "  Client 36 (User 36) local loss: 0.7179\n",
      "  Client 37 (User 37) local loss: 0.6221\n",
      "  Client 38 (User 38) local loss: 0.6861\n",
      "  Client 39 (User 39) local loss: 0.6695\n",
      "  Client 40 (User 40) local loss: 0.7527\n",
      "  Client 41 (User 41) local loss: 0.7568\n",
      "  Client 42 (User 42) local loss: 0.6203\n",
      "  Client 43 (User 43) local loss: 0.6821\n",
      "  Client 44 (User 44) local loss: 0.7970\n",
      "  Client 45 (User 45) local loss: 0.6850\n",
      "  Client 46 (User 46) local loss: 0.7337\n",
      "  Client 47 (User 47) local loss: 0.7147\n",
      "  Client 48 (User 48) local loss: 0.7328\n",
      "  Client 49 (User 49) local loss: 0.7521\n",
      "  Client 50 (User 50) local loss: 0.7743\n",
      "  Client 51 (User 51) local loss: 0.6755\n",
      "  Client 52 (User 52) local loss: 0.6486\n",
      "  Client 53 (User 53) local loss: 0.7973\n",
      "  Client 54 (User 54) local loss: 0.6729\n",
      "  Client 55 (User 55) local loss: 0.6992\n",
      "  Client 56 (User 56) local loss: 0.6547\n",
      "  Client 57 (User 57) local loss: 0.6308\n",
      "  Client 58 (User 58) local loss: 0.6646\n",
      "  Client 59 (User 59) local loss: 0.6884\n",
      "  Client 60 (User 60) local loss: 0.7694\n",
      "  Client 61 (User 61) local loss: 0.7686\n",
      "  Client 62 (User 62) local loss: 0.7497\n",
      "  Client 63 (User 63) local loss: 0.6256\n",
      "  Client 64 (User 64) local loss: 0.6171\n",
      "  Client 65 (User 65) local loss: 0.7494\n",
      "  Client 66 (User 66) local loss: 0.7204\n",
      "  Client 67 (User 67) local loss: 0.6456\n",
      "  Client 68 (User 68) local loss: 0.7161\n",
      "  Client 69 (User 69) local loss: 0.6615\n",
      "  Client 70 (User 70) local loss: 0.8039\n",
      "  Client 71 (User 71) local loss: 0.6899\n",
      "  Client 72 (User 72) local loss: 0.6349\n",
      "  Client 73 (User 73) local loss: 0.7536\n",
      "  Client 74 (User 74) local loss: 0.6580\n",
      "  Client 75 (User 75) local loss: 0.6744\n",
      "  Client 76 (User 76) local loss: 0.6871\n",
      "  Client 77 (User 77) local loss: 0.6075\n",
      "  Client 78 (User 78) local loss: 0.6697\n",
      "  Client 79 (User 79) local loss: 0.6114\n",
      "  Client 80 (User 80) local loss: 0.6161\n",
      "  Client 81 (User 81) local loss: 0.6624\n",
      "  Client 82 (User 82) local loss: 0.6313\n",
      "  Client 83 (User 83) local loss: 0.7226\n",
      "  Client 84 (User 84) local loss: 0.6675\n",
      "  Client 85 (User 85) local loss: 0.6239\n",
      "  Client 86 (User 86) local loss: 0.6322\n",
      "  Client 87 (User 87) local loss: 0.7184\n",
      "  Client 88 (User 88) local loss: 0.6761\n",
      "  Client 89 (User 89) local loss: 0.7341\n",
      "  Client 90 (User 90) local loss: 0.7103\n",
      "  Client 91 (User 91) local loss: 0.7133\n",
      "  Client 92 (User 92) local loss: 0.6965\n",
      "  Client 93 (User 93) local loss: 0.7547\n",
      "  Client 94 (User 94) local loss: 0.6790\n",
      "  Client 95 (User 95) local loss: 0.6480\n",
      "  Client 96 (User 96) local loss: 0.6405\n",
      "  Client 97 (User 97) local loss: 0.7035\n",
      "  Client 98 (User 98) local loss: 0.6638\n",
      "  Client 99 (User 99) local loss: 0.6933\n",
      "Round 3 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 4/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6959\n",
      "  Client 1 (User 1) local loss: 0.6493\n",
      "  Client 2 (User 2) local loss: 0.6266\n",
      "  Client 3 (User 3) local loss: 0.6949\n",
      "  Client 4 (User 4) local loss: 0.7200\n",
      "  Client 5 (User 5) local loss: 0.7497\n",
      "  Client 6 (User 6) local loss: 0.7187\n",
      "  Client 7 (User 7) local loss: 0.7267\n",
      "  Client 8 (User 8) local loss: 0.6876\n",
      "  Client 9 (User 9) local loss: 0.7334\n",
      "  Client 10 (User 10) local loss: 0.7656\n",
      "  Client 11 (User 11) local loss: 0.6510\n",
      "  Client 12 (User 12) local loss: 0.6619\n",
      "  Client 13 (User 13) local loss: 0.6813\n",
      "  Client 14 (User 14) local loss: 0.7735\n",
      "  Client 15 (User 15) local loss: 0.7734\n",
      "  Client 16 (User 16) local loss: 0.6656\n",
      "  Client 17 (User 17) local loss: 0.6412\n",
      "  Client 18 (User 18) local loss: 0.6528\n",
      "  Client 19 (User 19) local loss: 0.6882\n",
      "  Client 20 (User 20) local loss: 0.6864\n",
      "  Client 21 (User 21) local loss: 0.7458\n",
      "  Client 22 (User 22) local loss: 0.6498\n",
      "  Client 23 (User 23) local loss: 0.7481\n",
      "  Client 24 (User 24) local loss: 0.6399\n",
      "  Client 25 (User 25) local loss: 0.6333\n",
      "  Client 26 (User 26) local loss: 0.6545\n",
      "  Client 27 (User 27) local loss: 0.6399\n",
      "  Client 28 (User 28) local loss: 0.5646\n",
      "  Client 29 (User 29) local loss: 0.6968\n",
      "  Client 30 (User 30) local loss: 0.6679\n",
      "  Client 31 (User 31) local loss: 0.6213\n",
      "  Client 32 (User 32) local loss: 0.6759\n",
      "  Client 33 (User 33) local loss: 0.7059\n",
      "  Client 34 (User 34) local loss: 0.6645\n",
      "  Client 35 (User 35) local loss: 0.7487\n",
      "  Client 36 (User 36) local loss: 0.7136\n",
      "  Client 37 (User 37) local loss: 0.6126\n",
      "  Client 38 (User 38) local loss: 0.6807\n",
      "  Client 39 (User 39) local loss: 0.6679\n",
      "  Client 40 (User 40) local loss: 0.7401\n",
      "  Client 41 (User 41) local loss: 0.7482\n",
      "  Client 42 (User 42) local loss: 0.6085\n",
      "  Client 43 (User 43) local loss: 0.6690\n",
      "  Client 44 (User 44) local loss: 0.7919\n",
      "  Client 45 (User 45) local loss: 0.6805\n",
      "  Client 46 (User 46) local loss: 0.7375\n",
      "  Client 47 (User 47) local loss: 0.7043\n",
      "  Client 48 (User 48) local loss: 0.7216\n",
      "  Client 49 (User 49) local loss: 0.7510\n",
      "  Client 50 (User 50) local loss: 0.7720\n",
      "  Client 51 (User 51) local loss: 0.6713\n",
      "  Client 52 (User 52) local loss: 0.6411\n",
      "  Client 53 (User 53) local loss: 0.7908\n",
      "  Client 54 (User 54) local loss: 0.6673\n",
      "  Client 55 (User 55) local loss: 0.6951\n",
      "  Client 56 (User 56) local loss: 0.6582\n",
      "  Client 57 (User 57) local loss: 0.6362\n",
      "  Client 58 (User 58) local loss: 0.6519\n",
      "  Client 59 (User 59) local loss: 0.6849\n",
      "  Client 60 (User 60) local loss: 0.7589\n",
      "  Client 61 (User 61) local loss: 0.7626\n",
      "  Client 62 (User 62) local loss: 0.7400\n",
      "  Client 63 (User 63) local loss: 0.6186\n",
      "  Client 64 (User 64) local loss: 0.6076\n",
      "  Client 65 (User 65) local loss: 0.7393\n",
      "  Client 66 (User 66) local loss: 0.7169\n",
      "  Client 67 (User 67) local loss: 0.6503\n",
      "  Client 68 (User 68) local loss: 0.7043\n",
      "  Client 69 (User 69) local loss: 0.6535\n",
      "  Client 70 (User 70) local loss: 0.7915\n",
      "  Client 71 (User 71) local loss: 0.6844\n",
      "  Client 72 (User 72) local loss: 0.6456\n",
      "  Client 73 (User 73) local loss: 0.7430\n",
      "  Client 74 (User 74) local loss: 0.6557\n",
      "  Client 75 (User 75) local loss: 0.6596\n",
      "  Client 76 (User 76) local loss: 0.6820\n",
      "  Client 77 (User 77) local loss: 0.5953\n",
      "  Client 78 (User 78) local loss: 0.6630\n",
      "  Client 79 (User 79) local loss: 0.6256\n",
      "  Client 80 (User 80) local loss: 0.6121\n",
      "  Client 81 (User 81) local loss: 0.6548\n",
      "  Client 82 (User 82) local loss: 0.6207\n",
      "  Client 83 (User 83) local loss: 0.7158\n",
      "  Client 84 (User 84) local loss: 0.6603\n",
      "  Client 85 (User 85) local loss: 0.6165\n",
      "  Client 86 (User 86) local loss: 0.6353\n",
      "  Client 87 (User 87) local loss: 0.6998\n",
      "  Client 88 (User 88) local loss: 0.6755\n",
      "  Client 89 (User 89) local loss: 0.7254\n",
      "  Client 90 (User 90) local loss: 0.7083\n",
      "  Client 91 (User 91) local loss: 0.7021\n",
      "  Client 92 (User 92) local loss: 0.6899\n",
      "  Client 93 (User 93) local loss: 0.7380\n",
      "  Client 94 (User 94) local loss: 0.6883\n",
      "  Client 95 (User 95) local loss: 0.6527\n",
      "  Client 96 (User 96) local loss: 0.6435\n",
      "  Client 97 (User 97) local loss: 0.6910\n",
      "  Client 98 (User 98) local loss: 0.6633\n",
      "  Client 99 (User 99) local loss: 0.6914\n",
      "Round 4 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 5/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6955\n",
      "  Client 1 (User 1) local loss: 0.6514\n",
      "  Client 2 (User 2) local loss: 0.6232\n",
      "  Client 3 (User 3) local loss: 0.6922\n",
      "  Client 4 (User 4) local loss: 0.7113\n",
      "  Client 5 (User 5) local loss: 0.7450\n",
      "  Client 6 (User 6) local loss: 0.7083\n",
      "  Client 7 (User 7) local loss: 0.7355\n",
      "  Client 8 (User 8) local loss: 0.6824\n",
      "  Client 9 (User 9) local loss: 0.7286\n",
      "  Client 10 (User 10) local loss: 0.7478\n",
      "  Client 11 (User 11) local loss: 0.6400\n",
      "  Client 12 (User 12) local loss: 0.6579\n",
      "  Client 13 (User 13) local loss: 0.6748\n",
      "  Client 14 (User 14) local loss: 0.7653\n",
      "  Client 15 (User 15) local loss: 0.7846\n",
      "  Client 16 (User 16) local loss: 0.6689\n",
      "  Client 17 (User 17) local loss: 0.6371\n",
      "  Client 18 (User 18) local loss: 0.6643\n",
      "  Client 19 (User 19) local loss: 0.6820\n",
      "  Client 20 (User 20) local loss: 0.6820\n",
      "  Client 21 (User 21) local loss: 0.7297\n",
      "  Client 22 (User 22) local loss: 0.6438\n",
      "  Client 23 (User 23) local loss: 0.7465\n",
      "  Client 24 (User 24) local loss: 0.6296\n",
      "  Client 25 (User 25) local loss: 0.6226\n",
      "  Client 26 (User 26) local loss: 0.6535\n",
      "  Client 27 (User 27) local loss: 0.6425\n",
      "  Client 28 (User 28) local loss: 0.5681\n",
      "  Client 29 (User 29) local loss: 0.6862\n",
      "  Client 30 (User 30) local loss: 0.6651\n",
      "  Client 31 (User 31) local loss: 0.6297\n",
      "  Client 32 (User 32) local loss: 0.6670\n",
      "  Client 33 (User 33) local loss: 0.6987\n",
      "  Client 34 (User 34) local loss: 0.6555\n",
      "  Client 35 (User 35) local loss: 0.7366\n",
      "  Client 36 (User 36) local loss: 0.7036\n",
      "  Client 37 (User 37) local loss: 0.6172\n",
      "  Client 38 (User 38) local loss: 0.6629\n",
      "  Client 39 (User 39) local loss: 0.6599\n",
      "  Client 40 (User 40) local loss: 0.7340\n",
      "  Client 41 (User 41) local loss: 0.7356\n",
      "  Client 42 (User 42) local loss: 0.6101\n",
      "  Client 43 (User 43) local loss: 0.6610\n",
      "  Client 44 (User 44) local loss: 0.7863\n",
      "  Client 45 (User 45) local loss: 0.6740\n",
      "  Client 46 (User 46) local loss: 0.7393\n",
      "  Client 47 (User 47) local loss: 0.6921\n",
      "  Client 48 (User 48) local loss: 0.7232\n",
      "  Client 49 (User 49) local loss: 0.7446\n",
      "  Client 50 (User 50) local loss: 0.7574\n",
      "  Client 51 (User 51) local loss: 0.6686\n",
      "  Client 52 (User 52) local loss: 0.6289\n",
      "  Client 53 (User 53) local loss: 0.7676\n",
      "  Client 54 (User 54) local loss: 0.6737\n",
      "  Client 55 (User 55) local loss: 0.6901\n",
      "  Client 56 (User 56) local loss: 0.6555\n",
      "  Client 57 (User 57) local loss: 0.6201\n",
      "  Client 58 (User 58) local loss: 0.6512\n",
      "  Client 59 (User 59) local loss: 0.6840\n",
      "  Client 60 (User 60) local loss: 0.7441\n",
      "  Client 61 (User 61) local loss: 0.7703\n",
      "  Client 62 (User 62) local loss: 0.7301\n",
      "  Client 63 (User 63) local loss: 0.6145\n",
      "  Client 64 (User 64) local loss: 0.5904\n",
      "  Client 65 (User 65) local loss: 0.7322\n",
      "  Client 66 (User 66) local loss: 0.7145\n",
      "  Client 67 (User 67) local loss: 0.6524\n",
      "  Client 68 (User 68) local loss: 0.6893\n",
      "  Client 69 (User 69) local loss: 0.6481\n",
      "  Client 70 (User 70) local loss: 0.7976\n",
      "  Client 71 (User 71) local loss: 0.6787\n",
      "  Client 72 (User 72) local loss: 0.6549\n",
      "  Client 73 (User 73) local loss: 0.7392\n",
      "  Client 74 (User 74) local loss: 0.6531\n",
      "  Client 75 (User 75) local loss: 0.6371\n",
      "  Client 76 (User 76) local loss: 0.6803\n",
      "  Client 77 (User 77) local loss: 0.6031\n",
      "  Client 78 (User 78) local loss: 0.6568\n",
      "  Client 79 (User 79) local loss: 0.6053\n",
      "  Client 80 (User 80) local loss: 0.6019\n",
      "  Client 81 (User 81) local loss: 0.6382\n",
      "  Client 82 (User 82) local loss: 0.6196\n",
      "  Client 83 (User 83) local loss: 0.7112\n",
      "  Client 84 (User 84) local loss: 0.6544\n",
      "  Client 85 (User 85) local loss: 0.5991\n",
      "  Client 86 (User 86) local loss: 0.6297\n",
      "  Client 87 (User 87) local loss: 0.6700\n",
      "  Client 88 (User 88) local loss: 0.6637\n",
      "  Client 89 (User 89) local loss: 0.7245\n",
      "  Client 90 (User 90) local loss: 0.6992\n",
      "  Client 91 (User 91) local loss: 0.6915\n",
      "  Client 92 (User 92) local loss: 0.6796\n",
      "  Client 93 (User 93) local loss: 0.7380\n",
      "  Client 94 (User 94) local loss: 0.6787\n",
      "  Client 95 (User 95) local loss: 0.6425\n",
      "  Client 96 (User 96) local loss: 0.6295\n",
      "  Client 97 (User 97) local loss: 0.6779\n",
      "  Client 98 (User 98) local loss: 0.6615\n",
      "  Client 99 (User 99) local loss: 0.6881\n",
      "Round 5 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 6/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6924\n",
      "  Client 1 (User 1) local loss: 0.6277\n",
      "  Client 2 (User 2) local loss: 0.6038\n",
      "  Client 3 (User 3) local loss: 0.6912\n",
      "  Client 4 (User 4) local loss: 0.7010\n",
      "  Client 5 (User 5) local loss: 0.7411\n",
      "  Client 6 (User 6) local loss: 0.6848\n",
      "  Client 7 (User 7) local loss: 0.7360\n",
      "  Client 8 (User 8) local loss: 0.6724\n",
      "  Client 9 (User 9) local loss: 0.7224\n",
      "  Client 10 (User 10) local loss: 0.7350\n",
      "  Client 11 (User 11) local loss: 0.6450\n",
      "  Client 12 (User 12) local loss: 0.6462\n",
      "  Client 13 (User 13) local loss: 0.6719\n",
      "  Client 14 (User 14) local loss: 0.7575\n",
      "  Client 15 (User 15) local loss: 0.7786\n",
      "  Client 16 (User 16) local loss: 0.6657\n",
      "  Client 17 (User 17) local loss: 0.6153\n",
      "  Client 18 (User 18) local loss: 0.6560\n",
      "  Client 19 (User 19) local loss: 0.6803\n",
      "  Client 20 (User 20) local loss: 0.6781\n",
      "  Client 21 (User 21) local loss: 0.7325\n",
      "  Client 22 (User 22) local loss: 0.6304\n",
      "  Client 23 (User 23) local loss: 0.7501\n",
      "  Client 24 (User 24) local loss: 0.6300\n",
      "  Client 25 (User 25) local loss: 0.6231\n",
      "  Client 26 (User 26) local loss: 0.6546\n",
      "  Client 27 (User 27) local loss: 0.6352\n",
      "  Client 28 (User 28) local loss: 0.5531\n",
      "  Client 29 (User 29) local loss: 0.6792\n",
      "  Client 30 (User 30) local loss: 0.6587\n",
      "  Client 31 (User 31) local loss: 0.6178\n",
      "  Client 32 (User 32) local loss: 0.6524\n",
      "  Client 33 (User 33) local loss: 0.6926\n",
      "  Client 34 (User 34) local loss: 0.6490\n",
      "  Client 35 (User 35) local loss: 0.7191\n",
      "  Client 36 (User 36) local loss: 0.6939\n",
      "  Client 37 (User 37) local loss: 0.6121\n",
      "  Client 38 (User 38) local loss: 0.6569\n",
      "  Client 39 (User 39) local loss: 0.6664\n",
      "  Client 40 (User 40) local loss: 0.7202\n",
      "  Client 41 (User 41) local loss: 0.7277\n",
      "  Client 42 (User 42) local loss: 0.6131\n",
      "  Client 43 (User 43) local loss: 0.6420\n",
      "  Client 44 (User 44) local loss: 0.7845\n",
      "  Client 45 (User 45) local loss: 0.6714\n",
      "  Client 46 (User 46) local loss: 0.7339\n",
      "  Client 47 (User 47) local loss: 0.6777\n",
      "  Client 48 (User 48) local loss: 0.7231\n",
      "  Client 49 (User 49) local loss: 0.7367\n",
      "  Client 50 (User 50) local loss: 0.7558\n",
      "  Client 51 (User 51) local loss: 0.6646\n",
      "  Client 52 (User 52) local loss: 0.6159\n",
      "  Client 53 (User 53) local loss: 0.7489\n",
      "  Client 54 (User 54) local loss: 0.6627\n",
      "  Client 55 (User 55) local loss: 0.6848\n",
      "  Client 56 (User 56) local loss: 0.6599\n",
      "  Client 57 (User 57) local loss: 0.6160\n",
      "  Client 58 (User 58) local loss: 0.6416\n",
      "  Client 59 (User 59) local loss: 0.6824\n",
      "  Client 60 (User 60) local loss: 0.7212\n",
      "  Client 61 (User 61) local loss: 0.7625\n",
      "  Client 62 (User 62) local loss: 0.7168\n",
      "  Client 63 (User 63) local loss: 0.6126\n",
      "  Client 64 (User 64) local loss: 0.5820\n",
      "  Client 65 (User 65) local loss: 0.7088\n",
      "  Client 66 (User 66) local loss: 0.7082\n",
      "  Client 67 (User 67) local loss: 0.6443\n",
      "  Client 68 (User 68) local loss: 0.6684\n",
      "  Client 69 (User 69) local loss: 0.6306\n",
      "  Client 70 (User 70) local loss: 0.7951\n",
      "  Client 71 (User 71) local loss: 0.6719\n",
      "  Client 72 (User 72) local loss: 0.6481\n",
      "  Client 73 (User 73) local loss: 0.7440\n",
      "  Client 74 (User 74) local loss: 0.6411\n",
      "  Client 75 (User 75) local loss: 0.6098\n",
      "  Client 76 (User 76) local loss: 0.6815\n",
      "  Client 77 (User 77) local loss: 0.5805\n",
      "  Client 78 (User 78) local loss: 0.6604\n",
      "  Client 79 (User 79) local loss: 0.6076\n",
      "  Client 80 (User 80) local loss: 0.5837\n",
      "  Client 81 (User 81) local loss: 0.6338\n",
      "  Client 82 (User 82) local loss: 0.5997\n",
      "  Client 83 (User 83) local loss: 0.7049\n",
      "  Client 84 (User 84) local loss: 0.6445\n",
      "  Client 85 (User 85) local loss: 0.6042\n",
      "  Client 86 (User 86) local loss: 0.6237\n",
      "  Client 87 (User 87) local loss: 0.6370\n",
      "  Client 88 (User 88) local loss: 0.6630\n",
      "  Client 89 (User 89) local loss: 0.7100\n",
      "  Client 90 (User 90) local loss: 0.6943\n",
      "  Client 91 (User 91) local loss: 0.6786\n",
      "  Client 92 (User 92) local loss: 0.6754\n",
      "  Client 93 (User 93) local loss: 0.7289\n",
      "  Client 94 (User 94) local loss: 0.6784\n",
      "  Client 95 (User 95) local loss: 0.6444\n",
      "  Client 96 (User 96) local loss: 0.6212\n",
      "  Client 97 (User 97) local loss: 0.6554\n",
      "  Client 98 (User 98) local loss: 0.6539\n",
      "  Client 99 (User 99) local loss: 0.6866\n",
      "Round 6 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 7/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6907\n",
      "  Client 1 (User 1) local loss: 0.6384\n",
      "  Client 2 (User 2) local loss: 0.5966\n",
      "  Client 3 (User 3) local loss: 0.6893\n",
      "  Client 4 (User 4) local loss: 0.6974\n",
      "  Client 5 (User 5) local loss: 0.7297\n",
      "  Client 6 (User 6) local loss: 0.6633\n",
      "  Client 7 (User 7) local loss: 0.7256\n",
      "  Client 8 (User 8) local loss: 0.6629\n",
      "  Client 9 (User 9) local loss: 0.7186\n",
      "  Client 10 (User 10) local loss: 0.7110\n",
      "  Client 11 (User 11) local loss: 0.6246\n",
      "  Client 12 (User 12) local loss: 0.6502\n",
      "  Client 13 (User 13) local loss: 0.6627\n",
      "  Client 14 (User 14) local loss: 0.7383\n",
      "  Client 15 (User 15) local loss: 0.7683\n",
      "  Client 16 (User 16) local loss: 0.6687\n",
      "  Client 17 (User 17) local loss: 0.6100\n",
      "  Client 18 (User 18) local loss: 0.6535\n",
      "  Client 19 (User 19) local loss: 0.6796\n",
      "  Client 20 (User 20) local loss: 0.6788\n",
      "  Client 21 (User 21) local loss: 0.7220\n",
      "  Client 22 (User 22) local loss: 0.6355\n",
      "  Client 23 (User 23) local loss: 0.7408\n",
      "  Client 24 (User 24) local loss: 0.6169\n",
      "  Client 25 (User 25) local loss: 0.6007\n",
      "  Client 26 (User 26) local loss: 0.6450\n",
      "  Client 27 (User 27) local loss: 0.6218\n",
      "  Client 28 (User 28) local loss: 0.5279\n",
      "  Client 29 (User 29) local loss: 0.6692\n",
      "  Client 30 (User 30) local loss: 0.6567\n",
      "  Client 31 (User 31) local loss: 0.6246\n",
      "  Client 32 (User 32) local loss: 0.6362\n",
      "  Client 33 (User 33) local loss: 0.6840\n",
      "  Client 34 (User 34) local loss: 0.6372\n",
      "  Client 35 (User 35) local loss: 0.6970\n",
      "  Client 36 (User 36) local loss: 0.6866\n",
      "  Client 37 (User 37) local loss: 0.6047\n",
      "  Client 38 (User 38) local loss: 0.6275\n",
      "  Client 39 (User 39) local loss: 0.6584\n",
      "  Client 40 (User 40) local loss: 0.7069\n",
      "  Client 41 (User 41) local loss: 0.7159\n",
      "  Client 42 (User 42) local loss: 0.5972\n",
      "  Client 43 (User 43) local loss: 0.6253\n",
      "  Client 44 (User 44) local loss: 0.7766\n",
      "  Client 45 (User 45) local loss: 0.6598\n",
      "  Client 46 (User 46) local loss: 0.7254\n",
      "  Client 47 (User 47) local loss: 0.6579\n",
      "  Client 48 (User 48) local loss: 0.7276\n",
      "  Client 49 (User 49) local loss: 0.7297\n",
      "  Client 50 (User 50) local loss: 0.7459\n",
      "  Client 51 (User 51) local loss: 0.6670\n",
      "  Client 52 (User 52) local loss: 0.6054\n",
      "  Client 53 (User 53) local loss: 0.7211\n",
      "  Client 54 (User 54) local loss: 0.6642\n",
      "  Client 55 (User 55) local loss: 0.6789\n",
      "  Client 56 (User 56) local loss: 0.6611\n",
      "  Client 57 (User 57) local loss: 0.6159\n",
      "  Client 58 (User 58) local loss: 0.6334\n",
      "  Client 59 (User 59) local loss: 0.6772\n",
      "  Client 60 (User 60) local loss: 0.6987\n",
      "  Client 61 (User 61) local loss: 0.7606\n",
      "  Client 62 (User 62) local loss: 0.7030\n",
      "  Client 63 (User 63) local loss: 0.6124\n",
      "  Client 64 (User 64) local loss: 0.5643\n",
      "  Client 65 (User 65) local loss: 0.6961\n",
      "  Client 66 (User 66) local loss: 0.7002\n",
      "  Client 67 (User 67) local loss: 0.6342\n",
      "  Client 68 (User 68) local loss: 0.6522\n",
      "  Client 69 (User 69) local loss: 0.6275\n",
      "  Client 70 (User 70) local loss: 0.7842\n",
      "  Client 71 (User 71) local loss: 0.6559\n",
      "  Client 72 (User 72) local loss: 0.6543\n",
      "  Client 73 (User 73) local loss: 0.7281\n",
      "  Client 74 (User 74) local loss: 0.6468\n",
      "  Client 75 (User 75) local loss: 0.5880\n",
      "  Client 76 (User 76) local loss: 0.6769\n",
      "  Client 77 (User 77) local loss: 0.5879\n",
      "  Client 78 (User 78) local loss: 0.6618\n",
      "  Client 79 (User 79) local loss: 0.5981\n",
      "  Client 80 (User 80) local loss: 0.5819\n",
      "  Client 81 (User 81) local loss: 0.6287\n",
      "  Client 82 (User 82) local loss: 0.5957\n",
      "  Client 83 (User 83) local loss: 0.7007\n",
      "  Client 84 (User 84) local loss: 0.6421\n",
      "  Client 85 (User 85) local loss: 0.5791\n",
      "  Client 86 (User 86) local loss: 0.6214\n",
      "  Client 87 (User 87) local loss: 0.5916\n",
      "  Client 88 (User 88) local loss: 0.6609\n",
      "  Client 89 (User 89) local loss: 0.6984\n",
      "  Client 90 (User 90) local loss: 0.6842\n",
      "  Client 91 (User 91) local loss: 0.6654\n",
      "  Client 92 (User 92) local loss: 0.6733\n",
      "  Client 93 (User 93) local loss: 0.7256\n",
      "  Client 94 (User 94) local loss: 0.6773\n",
      "  Client 95 (User 95) local loss: 0.6393\n",
      "  Client 96 (User 96) local loss: 0.6276\n",
      "  Client 97 (User 97) local loss: 0.6327\n",
      "  Client 98 (User 98) local loss: 0.6585\n",
      "  Client 99 (User 99) local loss: 0.6830\n",
      "Round 7 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 8/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6891\n",
      "  Client 1 (User 1) local loss: 0.6275\n",
      "  Client 2 (User 2) local loss: 0.5820\n",
      "  Client 3 (User 3) local loss: 0.6886\n",
      "  Client 4 (User 4) local loss: 0.6851\n",
      "  Client 5 (User 5) local loss: 0.7174\n",
      "  Client 6 (User 6) local loss: 0.6341\n",
      "  Client 7 (User 7) local loss: 0.7195\n",
      "  Client 8 (User 8) local loss: 0.6530\n",
      "  Client 9 (User 9) local loss: 0.7157\n",
      "  Client 10 (User 10) local loss: 0.6850\n",
      "  Client 11 (User 11) local loss: 0.6330\n",
      "  Client 12 (User 12) local loss: 0.6450\n",
      "  Client 13 (User 13) local loss: 0.6633\n",
      "  Client 14 (User 14) local loss: 0.7160\n",
      "  Client 15 (User 15) local loss: 0.7689\n",
      "  Client 16 (User 16) local loss: 0.6561\n",
      "  Client 17 (User 17) local loss: 0.5878\n",
      "  Client 18 (User 18) local loss: 0.6498\n",
      "  Client 19 (User 19) local loss: 0.6782\n",
      "  Client 20 (User 20) local loss: 0.6627\n",
      "  Client 21 (User 21) local loss: 0.7172\n",
      "  Client 22 (User 22) local loss: 0.6276\n",
      "  Client 23 (User 23) local loss: 0.7331\n",
      "  Client 24 (User 24) local loss: 0.6163\n",
      "  Client 25 (User 25) local loss: 0.5872\n",
      "  Client 26 (User 26) local loss: 0.6417\n",
      "  Client 27 (User 27) local loss: 0.6218\n",
      "  Client 28 (User 28) local loss: 0.5266\n",
      "  Client 29 (User 29) local loss: 0.6599\n",
      "  Client 30 (User 30) local loss: 0.6490\n",
      "  Client 31 (User 31) local loss: 0.6109\n",
      "  Client 32 (User 32) local loss: 0.6290\n",
      "  Client 33 (User 33) local loss: 0.6739\n",
      "  Client 34 (User 34) local loss: 0.6172\n",
      "  Client 35 (User 35) local loss: 0.6648\n",
      "  Client 36 (User 36) local loss: 0.6760\n",
      "  Client 37 (User 37) local loss: 0.6052\n",
      "  Client 38 (User 38) local loss: 0.6498\n",
      "  Client 39 (User 39) local loss: 0.6450\n",
      "  Client 40 (User 40) local loss: 0.6830\n",
      "  Client 41 (User 41) local loss: 0.6988\n",
      "  Client 42 (User 42) local loss: 0.5887\n",
      "  Client 43 (User 43) local loss: 0.6046\n",
      "  Client 44 (User 44) local loss: 0.7801\n",
      "  Client 45 (User 45) local loss: 0.6620\n",
      "  Client 46 (User 46) local loss: 0.7283\n",
      "  Client 47 (User 47) local loss: 0.6390\n",
      "  Client 48 (User 48) local loss: 0.7167\n",
      "  Client 49 (User 49) local loss: 0.7145\n",
      "  Client 50 (User 50) local loss: 0.7376\n",
      "  Client 51 (User 51) local loss: 0.6611\n",
      "  Client 52 (User 52) local loss: 0.5979\n",
      "  Client 53 (User 53) local loss: 0.6832\n",
      "  Client 54 (User 54) local loss: 0.6646\n",
      "  Client 55 (User 55) local loss: 0.6727\n",
      "  Client 56 (User 56) local loss: 0.6611\n",
      "  Client 57 (User 57) local loss: 0.6061\n",
      "  Client 58 (User 58) local loss: 0.6259\n",
      "  Client 59 (User 59) local loss: 0.6778\n",
      "  Client 60 (User 60) local loss: 0.6711\n",
      "  Client 61 (User 61) local loss: 0.7594\n",
      "  Client 62 (User 62) local loss: 0.6773\n",
      "  Client 63 (User 63) local loss: 0.5945\n",
      "  Client 64 (User 64) local loss: 0.5550\n",
      "  Client 65 (User 65) local loss: 0.6716\n",
      "  Client 66 (User 66) local loss: 0.6874\n",
      "  Client 67 (User 67) local loss: 0.6319\n",
      "  Client 68 (User 68) local loss: 0.6170\n",
      "  Client 69 (User 69) local loss: 0.6238\n",
      "  Client 70 (User 70) local loss: 0.7739\n",
      "  Client 71 (User 71) local loss: 0.6507\n",
      "  Client 72 (User 72) local loss: 0.6417\n",
      "  Client 73 (User 73) local loss: 0.7247\n",
      "  Client 74 (User 74) local loss: 0.6366\n",
      "  Client 75 (User 75) local loss: 0.5502\n",
      "  Client 76 (User 76) local loss: 0.6746\n",
      "  Client 77 (User 77) local loss: 0.5897\n",
      "  Client 78 (User 78) local loss: 0.6501\n",
      "  Client 79 (User 79) local loss: 0.5790\n",
      "  Client 80 (User 80) local loss: 0.5896\n",
      "  Client 81 (User 81) local loss: 0.6221\n",
      "  Client 82 (User 82) local loss: 0.5960\n",
      "  Client 83 (User 83) local loss: 0.6935\n",
      "  Client 84 (User 84) local loss: 0.6146\n",
      "  Client 85 (User 85) local loss: 0.5561\n",
      "  Client 86 (User 86) local loss: 0.6219\n",
      "  Client 87 (User 87) local loss: 0.5443\n",
      "  Client 88 (User 88) local loss: 0.6570\n",
      "  Client 89 (User 89) local loss: 0.6810\n",
      "  Client 90 (User 90) local loss: 0.6760\n",
      "  Client 91 (User 91) local loss: 0.6444\n",
      "  Client 92 (User 92) local loss: 0.6591\n",
      "  Client 93 (User 93) local loss: 0.7178\n",
      "  Client 94 (User 94) local loss: 0.6883\n",
      "  Client 95 (User 95) local loss: 0.6322\n",
      "  Client 96 (User 96) local loss: 0.6054\n",
      "  Client 97 (User 97) local loss: 0.6028\n",
      "  Client 98 (User 98) local loss: 0.6538\n",
      "  Client 99 (User 99) local loss: 0.6804\n",
      "Round 8 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 9/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6883\n",
      "  Client 1 (User 1) local loss: 0.6199\n",
      "  Client 2 (User 2) local loss: 0.5741\n",
      "  Client 3 (User 3) local loss: 0.6859\n",
      "  Client 4 (User 4) local loss: 0.6799\n",
      "  Client 5 (User 5) local loss: 0.7070\n",
      "  Client 6 (User 6) local loss: 0.6136\n",
      "  Client 7 (User 7) local loss: 0.7153\n",
      "  Client 8 (User 8) local loss: 0.6464\n",
      "  Client 9 (User 9) local loss: 0.7137\n",
      "  Client 10 (User 10) local loss: 0.6514\n",
      "  Client 11 (User 11) local loss: 0.6204\n",
      "  Client 12 (User 12) local loss: 0.6451\n",
      "  Client 13 (User 13) local loss: 0.6498\n",
      "  Client 14 (User 14) local loss: 0.6854\n",
      "  Client 15 (User 15) local loss: 0.7594\n",
      "  Client 16 (User 16) local loss: 0.6527\n",
      "  Client 17 (User 17) local loss: 0.5759\n",
      "  Client 18 (User 18) local loss: 0.6449\n",
      "  Client 19 (User 19) local loss: 0.6686\n",
      "  Client 20 (User 20) local loss: 0.6739\n",
      "  Client 21 (User 21) local loss: 0.7051\n",
      "  Client 22 (User 22) local loss: 0.6255\n",
      "  Client 23 (User 23) local loss: 0.7351\n",
      "  Client 24 (User 24) local loss: 0.6125\n",
      "  Client 25 (User 25) local loss: 0.5881\n",
      "  Client 26 (User 26) local loss: 0.6296\n",
      "  Client 27 (User 27) local loss: 0.6211\n",
      "  Client 28 (User 28) local loss: 0.5321\n",
      "  Client 29 (User 29) local loss: 0.6285\n",
      "  Client 30 (User 30) local loss: 0.6321\n",
      "  Client 31 (User 31) local loss: 0.5960\n",
      "  Client 32 (User 32) local loss: 0.5904\n",
      "  Client 33 (User 33) local loss: 0.6549\n",
      "  Client 34 (User 34) local loss: 0.6007\n",
      "  Client 35 (User 35) local loss: 0.6380\n",
      "  Client 36 (User 36) local loss: 0.6479\n",
      "  Client 37 (User 37) local loss: 0.6167\n",
      "  Client 38 (User 38) local loss: 0.6432\n",
      "  Client 39 (User 39) local loss: 0.6441\n",
      "  Client 40 (User 40) local loss: 0.6455\n",
      "  Client 41 (User 41) local loss: 0.6748\n",
      "  Client 42 (User 42) local loss: 0.5569\n",
      "  Client 43 (User 43) local loss: 0.5909\n",
      "  Client 44 (User 44) local loss: 0.7575\n",
      "  Client 45 (User 45) local loss: 0.6465\n",
      "  Client 46 (User 46) local loss: 0.7122\n",
      "  Client 47 (User 47) local loss: 0.6124\n",
      "  Client 48 (User 48) local loss: 0.7207\n",
      "  Client 49 (User 49) local loss: 0.6929\n",
      "  Client 50 (User 50) local loss: 0.7274\n",
      "  Client 51 (User 51) local loss: 0.6619\n",
      "  Client 52 (User 52) local loss: 0.5775\n",
      "  Client 53 (User 53) local loss: 0.6441\n",
      "  Client 54 (User 54) local loss: 0.6588\n",
      "  Client 55 (User 55) local loss: 0.6595\n",
      "  Client 56 (User 56) local loss: 0.6486\n",
      "  Client 57 (User 57) local loss: 0.5974\n",
      "  Client 58 (User 58) local loss: 0.6330\n",
      "  Client 59 (User 59) local loss: 0.6746\n",
      "  Client 60 (User 60) local loss: 0.6422\n",
      "  Client 61 (User 61) local loss: 0.7576\n",
      "  Client 62 (User 62) local loss: 0.6596\n",
      "  Client 63 (User 63) local loss: 0.5902\n",
      "  Client 64 (User 64) local loss: 0.5215\n",
      "  Client 65 (User 65) local loss: 0.6395\n",
      "  Client 66 (User 66) local loss: 0.6708\n",
      "  Client 67 (User 67) local loss: 0.6433\n",
      "  Client 68 (User 68) local loss: 0.5907\n",
      "  Client 69 (User 69) local loss: 0.6122\n",
      "  Client 70 (User 70) local loss: 0.7674\n",
      "  Client 71 (User 71) local loss: 0.6325\n",
      "  Client 72 (User 72) local loss: 0.6431\n",
      "  Client 73 (User 73) local loss: 0.7227\n",
      "  Client 74 (User 74) local loss: 0.6443\n",
      "  Client 75 (User 75) local loss: 0.5335\n",
      "  Client 76 (User 76) local loss: 0.6714\n",
      "  Client 77 (User 77) local loss: 0.5738\n",
      "  Client 78 (User 78) local loss: 0.6573\n",
      "  Client 79 (User 79) local loss: 0.5706\n",
      "  Client 80 (User 80) local loss: 0.5787\n",
      "  Client 81 (User 81) local loss: 0.6164\n",
      "  Client 82 (User 82) local loss: 0.5822\n",
      "  Client 83 (User 83) local loss: 0.6871\n",
      "  Client 84 (User 84) local loss: 0.6179\n",
      "  Client 85 (User 85) local loss: 0.5579\n",
      "  Client 86 (User 86) local loss: 0.6007\n",
      "  Client 87 (User 87) local loss: 0.5241\n",
      "  Client 88 (User 88) local loss: 0.6543\n",
      "  Client 89 (User 89) local loss: 0.6616\n",
      "  Client 90 (User 90) local loss: 0.6552\n",
      "  Client 91 (User 91) local loss: 0.6150\n",
      "  Client 92 (User 92) local loss: 0.6531\n",
      "  Client 93 (User 93) local loss: 0.7098\n",
      "  Client 94 (User 94) local loss: 0.6665\n",
      "  Client 95 (User 95) local loss: 0.6315\n",
      "  Client 96 (User 96) local loss: 0.6142\n",
      "  Client 97 (User 97) local loss: 0.5652\n",
      "  Client 98 (User 98) local loss: 0.6545\n",
      "  Client 99 (User 99) local loss: 0.6762\n",
      "Round 9 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 10/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6871\n",
      "  Client 1 (User 1) local loss: 0.6161\n",
      "  Client 2 (User 2) local loss: 0.5568\n",
      "  Client 3 (User 3) local loss: 0.6846\n",
      "  Client 4 (User 4) local loss: 0.6765\n",
      "  Client 5 (User 5) local loss: 0.6905\n",
      "  Client 6 (User 6) local loss: 0.5543\n",
      "  Client 7 (User 7) local loss: 0.7173\n",
      "  Client 8 (User 8) local loss: 0.6246\n",
      "  Client 9 (User 9) local loss: 0.7062\n",
      "  Client 10 (User 10) local loss: 0.6203\n",
      "  Client 11 (User 11) local loss: 0.6204\n",
      "  Client 12 (User 12) local loss: 0.6334\n",
      "  Client 13 (User 13) local loss: 0.6379\n",
      "  Client 14 (User 14) local loss: 0.6576\n",
      "  Client 15 (User 15) local loss: 0.7462\n",
      "  Client 16 (User 16) local loss: 0.6586\n",
      "  Client 17 (User 17) local loss: 0.5576\n",
      "  Client 18 (User 18) local loss: 0.6435\n",
      "  Client 19 (User 19) local loss: 0.6678\n",
      "  Client 20 (User 20) local loss: 0.6713\n",
      "  Client 21 (User 21) local loss: 0.7232\n",
      "  Client 22 (User 22) local loss: 0.6187\n",
      "  Client 23 (User 23) local loss: 0.7327\n",
      "  Client 24 (User 24) local loss: 0.6138\n",
      "  Client 25 (User 25) local loss: 0.5729\n",
      "  Client 26 (User 26) local loss: 0.6411\n",
      "  Client 27 (User 27) local loss: 0.6170\n",
      "  Client 28 (User 28) local loss: 0.5068\n",
      "  Client 29 (User 29) local loss: 0.6168\n",
      "  Client 30 (User 30) local loss: 0.6299\n",
      "  Client 31 (User 31) local loss: 0.5812\n",
      "  Client 32 (User 32) local loss: 0.5501\n",
      "  Client 33 (User 33) local loss: 0.6550\n",
      "  Client 34 (User 34) local loss: 0.5668\n",
      "  Client 35 (User 35) local loss: 0.5799\n",
      "  Client 36 (User 36) local loss: 0.6508\n",
      "  Client 37 (User 37) local loss: 0.6014\n",
      "  Client 38 (User 38) local loss: 0.6441\n",
      "  Client 39 (User 39) local loss: 0.6434\n",
      "  Client 40 (User 40) local loss: 0.6250\n",
      "  Client 41 (User 41) local loss: 0.6355\n",
      "  Client 42 (User 42) local loss: 0.5610\n",
      "  Client 43 (User 43) local loss: 0.5516\n",
      "  Client 44 (User 44) local loss: 0.7572\n",
      "  Client 45 (User 45) local loss: 0.6423\n",
      "  Client 46 (User 46) local loss: 0.6947\n",
      "  Client 47 (User 47) local loss: 0.5850\n",
      "  Client 48 (User 48) local loss: 0.7158\n",
      "  Client 49 (User 49) local loss: 0.6727\n",
      "  Client 50 (User 50) local loss: 0.7168\n",
      "  Client 51 (User 51) local loss: 0.6491\n",
      "  Client 52 (User 52) local loss: 0.5460\n",
      "  Client 53 (User 53) local loss: 0.5903\n",
      "  Client 54 (User 54) local loss: 0.6581\n",
      "  Client 55 (User 55) local loss: 0.6561\n",
      "  Client 56 (User 56) local loss: 0.6554\n",
      "  Client 57 (User 57) local loss: 0.5961\n",
      "  Client 58 (User 58) local loss: 0.5904\n",
      "  Client 59 (User 59) local loss: 0.6738\n",
      "  Client 60 (User 60) local loss: 0.5985\n",
      "  Client 61 (User 61) local loss: 0.7675\n",
      "  Client 62 (User 62) local loss: 0.6264\n",
      "  Client 63 (User 63) local loss: 0.5728\n",
      "  Client 64 (User 64) local loss: 0.5127\n",
      "  Client 65 (User 65) local loss: 0.6361\n",
      "  Client 66 (User 66) local loss: 0.6611\n",
      "  Client 67 (User 67) local loss: 0.6301\n",
      "  Client 68 (User 68) local loss: 0.5602\n",
      "  Client 69 (User 69) local loss: 0.5809\n",
      "  Client 70 (User 70) local loss: 0.7825\n",
      "  Client 71 (User 71) local loss: 0.6117\n",
      "  Client 72 (User 72) local loss: 0.6530\n",
      "  Client 73 (User 73) local loss: 0.7162\n",
      "  Client 74 (User 74) local loss: 0.6316\n",
      "  Client 75 (User 75) local loss: 0.5636\n",
      "  Client 76 (User 76) local loss: 0.6677\n",
      "  Client 77 (User 77) local loss: 0.5835\n",
      "  Client 78 (User 78) local loss: 0.6532\n",
      "  Client 79 (User 79) local loss: 0.5464\n",
      "  Client 80 (User 80) local loss: 0.5581\n",
      "  Client 81 (User 81) local loss: 0.6050\n",
      "  Client 82 (User 82) local loss: 0.6347\n",
      "  Client 83 (User 83) local loss: 0.6736\n",
      "  Client 84 (User 84) local loss: 0.5848\n",
      "  Client 85 (User 85) local loss: 0.5413\n",
      "  Client 86 (User 86) local loss: 0.5991\n",
      "  Client 87 (User 87) local loss: 0.4205\n",
      "  Client 88 (User 88) local loss: 0.6440\n",
      "  Client 89 (User 89) local loss: 0.6357\n",
      "  Client 90 (User 90) local loss: 0.6458\n",
      "  Client 91 (User 91) local loss: 0.5870\n",
      "  Client 92 (User 92) local loss: 0.6363\n",
      "  Client 93 (User 93) local loss: 0.6973\n",
      "  Client 94 (User 94) local loss: 0.6814\n",
      "  Client 95 (User 95) local loss: 0.6240\n",
      "  Client 96 (User 96) local loss: 0.5910\n",
      "  Client 97 (User 97) local loss: 0.5508\n",
      "  Client 98 (User 98) local loss: 0.6596\n",
      "  Client 99 (User 99) local loss: 0.6702\n",
      "Round 10 completed. Global item embeddings updated.\n",
      "Federated training completed.\n"
     ]
    }
   ],
   "source": [
    "# モデルのハイパーパラメータ\n",
    "item_embedding_dim = 32\n",
    "joint_embedding_output_dim = 32\n",
    "\n",
    "# サーバーのインスタンス化\n",
    "server = Server(num_users, num_items, item_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "# 各クライアントのモデルを辞書で保持\n",
    "client_models = {}\n",
    "client_optimizers = {}\n",
    "for client_id in range(num_clients):\n",
    "    client_models[client_id] = ClientModel(\n",
    "        num_items,\n",
    "        item_embedding_dim,\n",
    "        plm_model,\n",
    "        plm_embedding_dim,\n",
    "        joint_embedding_output_dim\n",
    "    )\n",
    "    # NOTE:\n",
    "    # クライアントごとに最適化するパラメータを設定\n",
    "    # ここでは、user_joint_embedding_linear, local_item_embedding, prediction_layer が対象\n",
    "    # 単純にoptim.Adam(params = client_models[client_id].parameters(), lr=0.001)とすると、\n",
    "    # PLMも学習可能パラメータとなってしまうので、\n",
    "    # PLMのパラメータを除外したパラメータのみを取得してから、設定する.\n",
    "    trainable_params = [\n",
    "        p for name, p in client_models[client_id].named_parameters()\n",
    "        if not name.startswith('plm_model.')\n",
    "    ]\n",
    "\n",
    "    client_optimizers[client_id] = optim.Adam(\n",
    "        params=trainable_params,\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "# 学習ループ (フェデレーテッド学習ラウンド)\n",
    "num_communication_rounds = 10\n",
    "local_epochs = 1\n",
    "\n",
    "for round_num in range(num_communication_rounds):\n",
    "    print(f\"\\n--- Communication Round {round_num + 1}/{num_communication_rounds} ---\")\n",
    "\n",
    "    # サーバーからグローバルアイテム埋め込みをクライアントに配布 [cite: 63]\n",
    "    for client_id in range(num_clients):\n",
    "        client_models[client_id].local_item_embedding.weight.data.copy_(server.global_item_embedding.weight.data)\n",
    "\n",
    "    user_linear_weights_for_graph = {} # {user_id: user_joint_embedding_linear.weight.data (d1, d2) Tensor}\n",
    "    user_local_item_weights_to_server = {} # {user_id: local_item_embedding.weight.data (Tensor)}\n",
    "\n",
    "    # クライアントのローカル学習 [cite: 60]\n",
    "    for client_id in range(num_clients):\n",
    "        model = client_models[client_id]\n",
    "        optimizer = client_optimizers[client_id]\n",
    "        dataloader = client_datasets[client_id]\n",
    "\n",
    "        model.train()\n",
    "        local_loss = 0\n",
    "\n",
    "        current_user_id = client_user_map[client_id] \n",
    "\n",
    "        if len(dataloader.dataset) == 0:\n",
    "            print(f\"  Client {client_id} (User {current_user_id}) has no interactions, skipping local training.\")\n",
    "            # 訓練されなかったクライアントのために、現在のモデルの重み（グローバル初期化時と同じ）をアップロード\n",
    "            user_linear_weights_for_graph[current_user_id] = model.user_joint_embedding_linear.weight.data.clone().flatten()\n",
    "            user_local_item_weights_to_server[current_user_id] = model.local_item_embedding.weight.data.clone()\n",
    "            continue\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            # Transformer Blockがないため、 historical_item_sequences は DataLoader から取得しない\n",
    "            for user_ids_batch, item_ids_batch, labels_batch in dataloader:\n",
    "                assert torch.all(user_ids_batch == current_user_id) \n",
    "                current_user_texts = [user_texts[uid.item()] for uid in user_ids_batch]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # historical_item_sequences_batch を渡さない\n",
    "                predictions, user_joint_embedding_linear_weight, local_item_embedding_weight = model(\n",
    "                    user_ids_batch, item_ids_batch, current_user_texts\n",
    "                )\n",
    "\n",
    "                # 損失計算 (L_1のみ) [cite: 90, 91]\n",
    "                loss = nn.BCELoss()(predictions.squeeze(), labels_batch)\n",
    "\n",
    "                # 正則化項の追加 (論文の式(11)と(12)) [cite: 92, 93, 95]\n",
    "                # ここではe_globalはサーバーのglobal_item_embedding.weight.data\n",
    "                # e_i^- はlocal_item_embedding_weightからネガティブサンプリングされたアイテム埋め込み\n",
    "                # 論文では「Mean((e_global - e_i^-)^2)」 [cite: 93]\n",
    "                # 正確な e_i^- のサンプリングはデータセットからのネガティブサンプリングロジックが必要だが、ここでは簡略化\n",
    "                lambda_reg = 0.01 # ハイパーパラメータ [cite: 96, 101]\n",
    "\n",
    "                # global_item_embeddingとlocal_item_embeddingのL2距離を正則化項とする\n",
    "                # (ネガティブサンプリングは省略)\n",
    "                regularization_term = torch.mean(\n",
    "                    (local_item_embedding_weight - server.global_item_embedding.weight.data)**2\n",
    "                )\n",
    "\n",
    "                loss = loss + lambda_reg * regularization_term\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                local_loss += loss.item()\n",
    "\n",
    "        # クライアントがサーバーにアップロードするパラメータを収集 [cite: 61]\n",
    "        user_linear_weights_for_graph[current_user_id] = user_joint_embedding_linear_weight.data.clone()\n",
    "        user_local_item_weights_to_server[current_user_id] = local_item_embedding_weight.data.clone()\n",
    "\n",
    "        print(f\"  Client {client_id} (User {current_user_id}) local loss: {local_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # サーバーでの処理\n",
    "    # 論文のステップ「Graph Aggregation: The server constructs user relation graphs from text embeddings and aggregates parameters through graph convolution.」 [cite: 62]\n",
    "    # ユーザー関係グラフの構築 [cite: 103]\n",
    "    user_graph_adj, sorted_user_ids_for_graph = server.build_user_relationship_graph(\n",
    "        user_linear_weights_for_graph\n",
    "    )\n",
    "    \n",
    "    # アイテム埋め込みの集約 [cite: 109, 110]\n",
    "    server.aggregate_item_embeddings(\n",
    "        user_local_item_weights_to_server, \n",
    "        user_graph_adj, \n",
    "        sorted_user_ids_for_graph\n",
    "    )\n",
    "\n",
    "    print(f\"Round {round_num + 1} completed. Global item embeddings updated.\")\n",
    "\n",
    "print(\"Federated training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f25956c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a7714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-UD7q69fU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
