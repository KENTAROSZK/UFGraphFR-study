{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a757f5de",
   "metadata": {},
   "source": [
    "003に対して以下を追加.\n",
    "\n",
    "- 損失関数への正則化項の追加: 論文の式(12)にある、グローバルアイテム埋め込みとユーザー固有のネガティブサンプリングアイテム埋め込み間の正則化項 \n",
    "mathcalR(e_global,e_i −) を損失関数に含めます 。これにより、ローカルモデルがグローバルな知識から逸脱しすぎないように制約します\n",
    "- ユーザー特徴抽出 MLP の導入: ユーザー特徴のより高次な表現を抽出するために、User Feature Refinement MLP を導入します "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069f54a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kentaro.suzuki/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embedding dimension: 384\n",
      "Number of users: 100\n",
      "Number of items: 50\n",
      "Total interactions: 5000\n",
      "Number of clients (1 client per user): 100\n",
      "\n",
      "--- Communication Round 1/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7809\n",
      "  Client 1 (User 1) local loss: 0.8102\n",
      "  Client 2 (User 2) local loss: 0.8282\n",
      "  Client 3 (User 3) local loss: 0.8680\n",
      "  Client 4 (User 4) local loss: 0.7229\n",
      "  Client 5 (User 5) local loss: 0.7638\n",
      "  Client 6 (User 6) local loss: 0.8415\n",
      "  Client 7 (User 7) local loss: 0.8793\n",
      "  Client 8 (User 8) local loss: 0.8238\n",
      "  Client 9 (User 9) local loss: 0.8440\n",
      "  Client 10 (User 10) local loss: 0.8488\n",
      "  Client 11 (User 11) local loss: 0.8297\n",
      "  Client 12 (User 12) local loss: 0.8003\n",
      "  Client 13 (User 13) local loss: 0.8460\n",
      "  Client 14 (User 14) local loss: 0.7989\n",
      "  Client 15 (User 15) local loss: 0.8371\n",
      "  Client 16 (User 16) local loss: 0.8409\n",
      "  Client 17 (User 17) local loss: 0.7642\n",
      "  Client 18 (User 18) local loss: 0.8680\n",
      "  Client 19 (User 19) local loss: 0.8733\n",
      "  Client 20 (User 20) local loss: 0.8292\n",
      "  Client 21 (User 21) local loss: 0.8111\n",
      "  Client 22 (User 22) local loss: 0.8350\n",
      "  Client 23 (User 23) local loss: 0.8479\n",
      "  Client 24 (User 24) local loss: 0.8396\n",
      "  Client 25 (User 25) local loss: 0.8465\n",
      "  Client 26 (User 26) local loss: 0.8209\n",
      "  Client 27 (User 27) local loss: 0.8772\n",
      "  Client 28 (User 28) local loss: 0.8658\n",
      "  Client 29 (User 29) local loss: 0.8283\n",
      "  Client 30 (User 30) local loss: 0.8388\n",
      "  Client 31 (User 31) local loss: 0.8617\n",
      "  Client 32 (User 32) local loss: 0.8251\n",
      "  Client 33 (User 33) local loss: 0.8181\n",
      "  Client 34 (User 34) local loss: 0.8512\n",
      "  Client 35 (User 35) local loss: 0.8457\n",
      "  Client 36 (User 36) local loss: 0.8550\n",
      "  Client 37 (User 37) local loss: 0.7594\n",
      "  Client 38 (User 38) local loss: 0.7992\n",
      "  Client 39 (User 39) local loss: 0.7959\n",
      "  Client 40 (User 40) local loss: 0.7678\n",
      "  Client 41 (User 41) local loss: 0.8116\n",
      "  Client 42 (User 42) local loss: 0.8027\n",
      "  Client 43 (User 43) local loss: 0.8093\n",
      "  Client 44 (User 44) local loss: 0.8158\n",
      "  Client 45 (User 45) local loss: 0.8283\n",
      "  Client 46 (User 46) local loss: 0.7984\n",
      "  Client 47 (User 47) local loss: 0.8522\n",
      "  Client 48 (User 48) local loss: 0.8307\n",
      "  Client 49 (User 49) local loss: 0.7628\n",
      "  Client 50 (User 50) local loss: 0.7578\n",
      "  Client 51 (User 51) local loss: 0.9015\n",
      "  Client 52 (User 52) local loss: 0.8393\n",
      "  Client 53 (User 53) local loss: 0.8805\n",
      "  Client 54 (User 54) local loss: 0.7568\n",
      "  Client 55 (User 55) local loss: 0.8044\n",
      "  Client 56 (User 56) local loss: 0.8484\n",
      "  Client 57 (User 57) local loss: 0.7677\n",
      "  Client 58 (User 58) local loss: 0.8739\n",
      "  Client 59 (User 59) local loss: 0.8239\n",
      "  Client 60 (User 60) local loss: 0.8567\n",
      "  Client 61 (User 61) local loss: 0.8603\n",
      "  Client 62 (User 62) local loss: 0.9408\n",
      "  Client 63 (User 63) local loss: 0.8078\n",
      "  Client 64 (User 64) local loss: 0.8194\n",
      "  Client 65 (User 65) local loss: 0.8688\n",
      "  Client 66 (User 66) local loss: 0.7758\n",
      "  Client 67 (User 67) local loss: 0.7987\n",
      "  Client 68 (User 68) local loss: 0.8459\n",
      "  Client 69 (User 69) local loss: 0.8325\n",
      "  Client 70 (User 70) local loss: 0.8571\n",
      "  Client 71 (User 71) local loss: 0.7741\n",
      "  Client 72 (User 72) local loss: 0.8269\n",
      "  Client 73 (User 73) local loss: 0.8329\n",
      "  Client 74 (User 74) local loss: 0.8136\n",
      "  Client 75 (User 75) local loss: 0.8180\n",
      "  Client 76 (User 76) local loss: 0.8402\n",
      "  Client 77 (User 77) local loss: 0.8165\n",
      "  Client 78 (User 78) local loss: 0.7849\n",
      "  Client 79 (User 79) local loss: 0.7972\n",
      "  Client 80 (User 80) local loss: 0.8357\n",
      "  Client 81 (User 81) local loss: 0.8466\n",
      "  Client 82 (User 82) local loss: 0.8475\n",
      "  Client 83 (User 83) local loss: 0.7835\n",
      "  Client 84 (User 84) local loss: 0.7908\n",
      "  Client 85 (User 85) local loss: 0.7841\n",
      "  Client 86 (User 86) local loss: 0.8107\n",
      "  Client 87 (User 87) local loss: 0.8008\n",
      "  Client 88 (User 88) local loss: 0.8076\n",
      "  Client 89 (User 89) local loss: 0.7619\n",
      "  Client 90 (User 90) local loss: 0.8525\n",
      "  Client 91 (User 91) local loss: 0.7610\n",
      "  Client 92 (User 92) local loss: 0.8891\n",
      "  Client 93 (User 93) local loss: 0.8005\n",
      "  Client 94 (User 94) local loss: 0.8635\n",
      "  Client 95 (User 95) local loss: 0.8014\n",
      "  Client 96 (User 96) local loss: 0.8158\n",
      "  Client 97 (User 97) local loss: 0.8099\n",
      "  Client 98 (User 98) local loss: 0.8135\n",
      "  Client 99 (User 99) local loss: 0.8986\n",
      "Round 1 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 2/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7947\n",
      "  Client 1 (User 1) local loss: 0.8149\n",
      "  Client 2 (User 2) local loss: 0.8504\n",
      "  Client 3 (User 3) local loss: 0.8661\n",
      "  Client 4 (User 4) local loss: 0.7224\n",
      "  Client 5 (User 5) local loss: 0.7617\n",
      "  Client 6 (User 6) local loss: 0.8505\n",
      "  Client 7 (User 7) local loss: 0.8588\n",
      "  Client 8 (User 8) local loss: 0.8270\n",
      "  Client 9 (User 9) local loss: 0.8312\n",
      "  Client 10 (User 10) local loss: 0.8571\n",
      "  Client 11 (User 11) local loss: 0.8337\n",
      "  Client 12 (User 12) local loss: 0.7974\n",
      "  Client 13 (User 13) local loss: 0.8708\n",
      "  Client 14 (User 14) local loss: 0.7914\n",
      "  Client 15 (User 15) local loss: 0.8224\n",
      "  Client 16 (User 16) local loss: 0.8330\n",
      "  Client 17 (User 17) local loss: 0.7734\n",
      "  Client 18 (User 18) local loss: 0.8467\n",
      "  Client 19 (User 19) local loss: 0.8712\n",
      "  Client 20 (User 20) local loss: 0.8334\n",
      "  Client 21 (User 21) local loss: 0.7924\n",
      "  Client 22 (User 22) local loss: 0.8159\n",
      "  Client 23 (User 23) local loss: 0.8439\n",
      "  Client 24 (User 24) local loss: 0.8574\n",
      "  Client 25 (User 25) local loss: 0.8656\n",
      "  Client 26 (User 26) local loss: 0.8132\n",
      "  Client 27 (User 27) local loss: 0.8686\n",
      "  Client 28 (User 28) local loss: 0.8631\n",
      "  Client 29 (User 29) local loss: 0.8252\n",
      "  Client 30 (User 30) local loss: 0.8312\n",
      "  Client 31 (User 31) local loss: 0.8397\n",
      "  Client 32 (User 32) local loss: 0.8091\n",
      "  Client 33 (User 33) local loss: 0.8319\n",
      "  Client 34 (User 34) local loss: 0.8386\n",
      "  Client 35 (User 35) local loss: 0.8289\n",
      "  Client 36 (User 36) local loss: 0.8474\n",
      "  Client 37 (User 37) local loss: 0.7439\n",
      "  Client 38 (User 38) local loss: 0.8077\n",
      "  Client 39 (User 39) local loss: 0.7626\n",
      "  Client 40 (User 40) local loss: 0.7381\n",
      "  Client 41 (User 41) local loss: 0.8103\n",
      "  Client 42 (User 42) local loss: 0.7949\n",
      "  Client 43 (User 43) local loss: 0.8076\n",
      "  Client 44 (User 44) local loss: 0.8035\n",
      "  Client 45 (User 45) local loss: 0.8396\n",
      "  Client 46 (User 46) local loss: 0.7865\n",
      "  Client 47 (User 47) local loss: 0.8607\n",
      "  Client 48 (User 48) local loss: 0.8389\n",
      "  Client 49 (User 49) local loss: 0.7615\n",
      "  Client 50 (User 50) local loss: 0.7507\n",
      "  Client 51 (User 51) local loss: 0.8852\n",
      "  Client 52 (User 52) local loss: 0.8209\n",
      "  Client 53 (User 53) local loss: 0.8773\n",
      "  Client 54 (User 54) local loss: 0.7821\n",
      "  Client 55 (User 55) local loss: 0.8035\n",
      "  Client 56 (User 56) local loss: 0.8392\n",
      "  Client 57 (User 57) local loss: 0.7796\n",
      "  Client 58 (User 58) local loss: 0.8573\n",
      "  Client 59 (User 59) local loss: 0.8453\n",
      "  Client 60 (User 60) local loss: 0.8379\n",
      "  Client 61 (User 61) local loss: 0.8641\n",
      "  Client 62 (User 62) local loss: 0.9433\n",
      "  Client 63 (User 63) local loss: 0.8046\n",
      "  Client 64 (User 64) local loss: 0.8065\n",
      "  Client 65 (User 65) local loss: 0.8594\n",
      "  Client 66 (User 66) local loss: 0.7690\n",
      "  Client 67 (User 67) local loss: 0.7754\n",
      "  Client 68 (User 68) local loss: 0.8501\n",
      "  Client 69 (User 69) local loss: 0.8183\n",
      "  Client 70 (User 70) local loss: 0.8368\n",
      "  Client 71 (User 71) local loss: 0.7795\n",
      "  Client 72 (User 72) local loss: 0.8533\n",
      "  Client 73 (User 73) local loss: 0.8419\n",
      "  Client 74 (User 74) local loss: 0.8002\n",
      "  Client 75 (User 75) local loss: 0.7967\n",
      "  Client 76 (User 76) local loss: 0.8511\n",
      "  Client 77 (User 77) local loss: 0.8098\n",
      "  Client 78 (User 78) local loss: 0.7641\n",
      "  Client 79 (User 79) local loss: 0.8226\n",
      "  Client 80 (User 80) local loss: 0.8328\n",
      "  Client 81 (User 81) local loss: 0.8524\n",
      "  Client 82 (User 82) local loss: 0.8460\n",
      "  Client 83 (User 83) local loss: 0.7904\n",
      "  Client 84 (User 84) local loss: 0.8002\n",
      "  Client 85 (User 85) local loss: 0.7653\n",
      "  Client 86 (User 86) local loss: 0.8148\n",
      "  Client 87 (User 87) local loss: 0.7873\n",
      "  Client 88 (User 88) local loss: 0.8059\n",
      "  Client 89 (User 89) local loss: 0.7608\n",
      "  Client 90 (User 90) local loss: 0.8440\n",
      "  Client 91 (User 91) local loss: 0.7910\n",
      "  Client 92 (User 92) local loss: 0.9145\n",
      "  Client 93 (User 93) local loss: 0.8097\n",
      "  Client 94 (User 94) local loss: 0.8552\n",
      "  Client 95 (User 95) local loss: 0.7849\n",
      "  Client 96 (User 96) local loss: 0.8149\n",
      "  Client 97 (User 97) local loss: 0.8085\n",
      "  Client 98 (User 98) local loss: 0.8191\n",
      "  Client 99 (User 99) local loss: 0.8847\n",
      "Round 2 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 3/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7931\n",
      "  Client 1 (User 1) local loss: 0.7758\n",
      "  Client 2 (User 2) local loss: 0.8357\n",
      "  Client 3 (User 3) local loss: 0.8570\n",
      "  Client 4 (User 4) local loss: 0.7155\n",
      "  Client 5 (User 5) local loss: 0.7583\n",
      "  Client 6 (User 6) local loss: 0.8377\n",
      "  Client 7 (User 7) local loss: 0.8612\n",
      "  Client 8 (User 8) local loss: 0.8016\n",
      "  Client 9 (User 9) local loss: 0.8288\n",
      "  Client 10 (User 10) local loss: 0.8540\n",
      "  Client 11 (User 11) local loss: 0.8307\n",
      "  Client 12 (User 12) local loss: 0.7806\n",
      "  Client 13 (User 13) local loss: 0.8685\n",
      "  Client 14 (User 14) local loss: 0.7905\n",
      "  Client 15 (User 15) local loss: 0.8248\n",
      "  Client 16 (User 16) local loss: 0.8368\n",
      "  Client 17 (User 17) local loss: 0.7985\n",
      "  Client 18 (User 18) local loss: 0.8374\n",
      "  Client 19 (User 19) local loss: 0.8768\n",
      "  Client 20 (User 20) local loss: 0.8198\n",
      "  Client 21 (User 21) local loss: 0.7859\n",
      "  Client 22 (User 22) local loss: 0.8081\n",
      "  Client 23 (User 23) local loss: 0.8292\n",
      "  Client 24 (User 24) local loss: 0.8425\n",
      "  Client 25 (User 25) local loss: 0.8443\n",
      "  Client 26 (User 26) local loss: 0.8252\n",
      "  Client 27 (User 27) local loss: 0.8657\n",
      "  Client 28 (User 28) local loss: 0.8818\n",
      "  Client 29 (User 29) local loss: 0.8353\n",
      "  Client 30 (User 30) local loss: 0.8080\n",
      "  Client 31 (User 31) local loss: 0.8452\n",
      "  Client 32 (User 32) local loss: 0.8269\n",
      "  Client 33 (User 33) local loss: 0.8288\n",
      "  Client 34 (User 34) local loss: 0.8367\n",
      "  Client 35 (User 35) local loss: 0.8275\n",
      "  Client 36 (User 36) local loss: 0.8760\n",
      "  Client 37 (User 37) local loss: 0.7421\n",
      "  Client 38 (User 38) local loss: 0.8109\n",
      "  Client 39 (User 39) local loss: 0.7612\n",
      "  Client 40 (User 40) local loss: 0.7578\n",
      "  Client 41 (User 41) local loss: 0.8039\n",
      "  Client 42 (User 42) local loss: 0.7987\n",
      "  Client 43 (User 43) local loss: 0.8128\n",
      "  Client 44 (User 44) local loss: 0.8019\n",
      "  Client 45 (User 45) local loss: 0.8086\n",
      "  Client 46 (User 46) local loss: 0.7801\n",
      "  Client 47 (User 47) local loss: 0.8759\n",
      "  Client 48 (User 48) local loss: 0.8411\n",
      "  Client 49 (User 49) local loss: 0.7656\n",
      "  Client 50 (User 50) local loss: 0.7484\n",
      "  Client 51 (User 51) local loss: 0.8819\n",
      "  Client 52 (User 52) local loss: 0.8139\n",
      "  Client 53 (User 53) local loss: 0.8684\n",
      "  Client 54 (User 54) local loss: 0.7697\n",
      "  Client 55 (User 55) local loss: 0.8230\n",
      "  Client 56 (User 56) local loss: 0.8506\n",
      "  Client 57 (User 57) local loss: 0.7660\n",
      "  Client 58 (User 58) local loss: 0.8739\n",
      "  Client 59 (User 59) local loss: 0.8064\n",
      "  Client 60 (User 60) local loss: 0.8517\n",
      "  Client 61 (User 61) local loss: 0.8554\n",
      "  Client 62 (User 62) local loss: 0.9252\n",
      "  Client 63 (User 63) local loss: 0.8171\n",
      "  Client 64 (User 64) local loss: 0.7989\n",
      "  Client 65 (User 65) local loss: 0.8680\n",
      "  Client 66 (User 66) local loss: 0.7628\n",
      "  Client 67 (User 67) local loss: 0.7847\n",
      "  Client 68 (User 68) local loss: 0.8284\n",
      "  Client 69 (User 69) local loss: 0.8245\n",
      "  Client 70 (User 70) local loss: 0.8407\n",
      "  Client 71 (User 71) local loss: 0.7850\n",
      "  Client 72 (User 72) local loss: 0.8563\n",
      "  Client 73 (User 73) local loss: 0.8485\n",
      "  Client 74 (User 74) local loss: 0.8085\n",
      "  Client 75 (User 75) local loss: 0.8078\n",
      "  Client 76 (User 76) local loss: 0.8373\n",
      "  Client 77 (User 77) local loss: 0.8243\n",
      "  Client 78 (User 78) local loss: 0.7941\n",
      "  Client 79 (User 79) local loss: 0.7875\n",
      "  Client 80 (User 80) local loss: 0.8290\n",
      "  Client 81 (User 81) local loss: 0.8379\n",
      "  Client 82 (User 82) local loss: 0.8233\n",
      "  Client 83 (User 83) local loss: 0.7934\n",
      "  Client 84 (User 84) local loss: 0.7764\n",
      "  Client 85 (User 85) local loss: 0.7701\n",
      "  Client 86 (User 86) local loss: 0.8124\n",
      "  Client 87 (User 87) local loss: 0.7899\n",
      "  Client 88 (User 88) local loss: 0.7923\n",
      "  Client 89 (User 89) local loss: 0.7647\n",
      "  Client 90 (User 90) local loss: 0.8415\n",
      "  Client 91 (User 91) local loss: 0.7833\n",
      "  Client 92 (User 92) local loss: 0.9054\n",
      "  Client 93 (User 93) local loss: 0.8242\n",
      "  Client 94 (User 94) local loss: 0.8642\n",
      "  Client 95 (User 95) local loss: 0.7776\n",
      "  Client 96 (User 96) local loss: 0.8134\n",
      "  Client 97 (User 97) local loss: 0.8159\n",
      "  Client 98 (User 98) local loss: 0.8180\n",
      "  Client 99 (User 99) local loss: 0.8836\n",
      "Round 3 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 4/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7755\n",
      "  Client 1 (User 1) local loss: 0.7940\n",
      "  Client 2 (User 2) local loss: 0.8328\n",
      "  Client 3 (User 3) local loss: 0.8608\n",
      "  Client 4 (User 4) local loss: 0.7377\n",
      "  Client 5 (User 5) local loss: 0.7509\n",
      "  Client 6 (User 6) local loss: 0.8461\n",
      "  Client 7 (User 7) local loss: 0.8573\n",
      "  Client 8 (User 8) local loss: 0.8160\n",
      "  Client 9 (User 9) local loss: 0.8262\n",
      "  Client 10 (User 10) local loss: 0.8349\n",
      "  Client 11 (User 11) local loss: 0.8340\n",
      "  Client 12 (User 12) local loss: 0.7772\n",
      "  Client 13 (User 13) local loss: 0.8597\n",
      "  Client 14 (User 14) local loss: 0.7768\n",
      "  Client 15 (User 15) local loss: 0.8111\n",
      "  Client 16 (User 16) local loss: 0.8277\n",
      "  Client 17 (User 17) local loss: 0.7796\n",
      "  Client 18 (User 18) local loss: 0.8438\n",
      "  Client 19 (User 19) local loss: 0.8748\n",
      "  Client 20 (User 20) local loss: 0.8127\n",
      "  Client 21 (User 21) local loss: 0.8180\n",
      "  Client 22 (User 22) local loss: 0.8236\n",
      "  Client 23 (User 23) local loss: 0.8385\n",
      "  Client 24 (User 24) local loss: 0.8336\n",
      "  Client 25 (User 25) local loss: 0.8363\n",
      "  Client 26 (User 26) local loss: 0.8376\n",
      "  Client 27 (User 27) local loss: 0.8628\n",
      "  Client 28 (User 28) local loss: 0.8393\n",
      "  Client 29 (User 29) local loss: 0.8224\n",
      "  Client 30 (User 30) local loss: 0.8335\n",
      "  Client 31 (User 31) local loss: 0.8372\n",
      "  Client 32 (User 32) local loss: 0.8304\n",
      "  Client 33 (User 33) local loss: 0.8148\n",
      "  Client 34 (User 34) local loss: 0.8183\n",
      "  Client 35 (User 35) local loss: 0.8324\n",
      "  Client 36 (User 36) local loss: 0.8616\n",
      "  Client 37 (User 37) local loss: 0.7606\n",
      "  Client 38 (User 38) local loss: 0.8046\n",
      "  Client 39 (User 39) local loss: 0.7829\n",
      "  Client 40 (User 40) local loss: 0.7703\n",
      "  Client 41 (User 41) local loss: 0.8122\n",
      "  Client 42 (User 42) local loss: 0.7923\n",
      "  Client 43 (User 43) local loss: 0.8172\n",
      "  Client 44 (User 44) local loss: 0.7999\n",
      "  Client 45 (User 45) local loss: 0.8391\n",
      "  Client 46 (User 46) local loss: 0.7839\n",
      "  Client 47 (User 47) local loss: 0.8545\n",
      "  Client 48 (User 48) local loss: 0.8478\n",
      "  Client 49 (User 49) local loss: 0.7419\n",
      "  Client 50 (User 50) local loss: 0.7466\n",
      "  Client 51 (User 51) local loss: 0.8535\n",
      "  Client 52 (User 52) local loss: 0.8055\n",
      "  Client 53 (User 53) local loss: 0.8822\n",
      "  Client 54 (User 54) local loss: 0.7664\n",
      "  Client 55 (User 55) local loss: 0.8075\n",
      "  Client 56 (User 56) local loss: 0.8557\n",
      "  Client 57 (User 57) local loss: 0.7774\n",
      "  Client 58 (User 58) local loss: 0.8641\n",
      "  Client 59 (User 59) local loss: 0.8259\n",
      "  Client 60 (User 60) local loss: 0.8602\n",
      "  Client 61 (User 61) local loss: 0.8648\n",
      "  Client 62 (User 62) local loss: 0.9204\n",
      "  Client 63 (User 63) local loss: 0.8103\n",
      "  Client 64 (User 64) local loss: 0.8115\n",
      "  Client 65 (User 65) local loss: 0.8691\n",
      "  Client 66 (User 66) local loss: 0.7658\n",
      "  Client 67 (User 67) local loss: 0.7838\n",
      "  Client 68 (User 68) local loss: 0.8321\n",
      "  Client 69 (User 69) local loss: 0.8036\n",
      "  Client 70 (User 70) local loss: 0.8505\n",
      "  Client 71 (User 71) local loss: 0.7721\n",
      "  Client 72 (User 72) local loss: 0.8318\n",
      "  Client 73 (User 73) local loss: 0.8519\n",
      "  Client 74 (User 74) local loss: 0.7944\n",
      "  Client 75 (User 75) local loss: 0.7879\n",
      "  Client 76 (User 76) local loss: 0.8345\n",
      "  Client 77 (User 77) local loss: 0.8009\n",
      "  Client 78 (User 78) local loss: 0.7855\n",
      "  Client 79 (User 79) local loss: 0.8076\n",
      "  Client 80 (User 80) local loss: 0.8207\n",
      "  Client 81 (User 81) local loss: 0.8439\n",
      "  Client 82 (User 82) local loss: 0.8221\n",
      "  Client 83 (User 83) local loss: 0.7855\n",
      "  Client 84 (User 84) local loss: 0.7968\n",
      "  Client 85 (User 85) local loss: 0.7802\n",
      "  Client 86 (User 86) local loss: 0.7888\n",
      "  Client 87 (User 87) local loss: 0.7779\n",
      "  Client 88 (User 88) local loss: 0.7978\n",
      "  Client 89 (User 89) local loss: 0.7544\n",
      "  Client 90 (User 90) local loss: 0.8266\n",
      "  Client 91 (User 91) local loss: 0.7826\n",
      "  Client 92 (User 92) local loss: 0.8949\n",
      "  Client 93 (User 93) local loss: 0.8009\n",
      "  Client 94 (User 94) local loss: 0.8443\n",
      "  Client 95 (User 95) local loss: 0.7815\n",
      "  Client 96 (User 96) local loss: 0.8120\n",
      "  Client 97 (User 97) local loss: 0.7978\n",
      "  Client 98 (User 98) local loss: 0.8165\n",
      "  Client 99 (User 99) local loss: 0.8816\n",
      "Round 4 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 5/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7693\n",
      "  Client 1 (User 1) local loss: 0.7990\n",
      "  Client 2 (User 2) local loss: 0.8245\n",
      "  Client 3 (User 3) local loss: 0.8631\n",
      "  Client 4 (User 4) local loss: 0.7374\n",
      "  Client 5 (User 5) local loss: 0.7511\n",
      "  Client 6 (User 6) local loss: 0.8331\n",
      "  Client 7 (User 7) local loss: 0.8474\n",
      "  Client 8 (User 8) local loss: 0.8242\n",
      "  Client 9 (User 9) local loss: 0.8139\n",
      "  Client 10 (User 10) local loss: 0.8310\n",
      "  Client 11 (User 11) local loss: 0.8289\n",
      "  Client 12 (User 12) local loss: 0.7789\n",
      "  Client 13 (User 13) local loss: 0.8511\n",
      "  Client 14 (User 14) local loss: 0.7816\n",
      "  Client 15 (User 15) local loss: 0.8241\n",
      "  Client 16 (User 16) local loss: 0.8251\n",
      "  Client 17 (User 17) local loss: 0.7671\n",
      "  Client 18 (User 18) local loss: 0.8326\n",
      "  Client 19 (User 19) local loss: 0.8591\n",
      "  Client 20 (User 20) local loss: 0.8228\n",
      "  Client 21 (User 21) local loss: 0.7891\n",
      "  Client 22 (User 22) local loss: 0.8092\n",
      "  Client 23 (User 23) local loss: 0.8321\n",
      "  Client 24 (User 24) local loss: 0.8369\n",
      "  Client 25 (User 25) local loss: 0.8350\n",
      "  Client 26 (User 26) local loss: 0.8233\n",
      "  Client 27 (User 27) local loss: 0.8528\n",
      "  Client 28 (User 28) local loss: 0.8451\n",
      "  Client 29 (User 29) local loss: 0.8072\n",
      "  Client 30 (User 30) local loss: 0.8052\n",
      "  Client 31 (User 31) local loss: 0.8495\n",
      "  Client 32 (User 32) local loss: 0.8090\n",
      "  Client 33 (User 33) local loss: 0.8008\n",
      "  Client 34 (User 34) local loss: 0.8304\n",
      "  Client 35 (User 35) local loss: 0.8364\n",
      "  Client 36 (User 36) local loss: 0.8657\n",
      "  Client 37 (User 37) local loss: 0.7519\n",
      "  Client 38 (User 38) local loss: 0.8023\n",
      "  Client 39 (User 39) local loss: 0.7837\n",
      "  Client 40 (User 40) local loss: 0.7758\n",
      "  Client 41 (User 41) local loss: 0.8099\n",
      "  Client 42 (User 42) local loss: 0.8003\n",
      "  Client 43 (User 43) local loss: 0.8228\n",
      "  Client 44 (User 44) local loss: 0.8036\n",
      "  Client 45 (User 45) local loss: 0.8089\n",
      "  Client 46 (User 46) local loss: 0.7872\n",
      "  Client 47 (User 47) local loss: 0.8538\n",
      "  Client 48 (User 48) local loss: 0.8213\n",
      "  Client 49 (User 49) local loss: 0.7575\n",
      "  Client 50 (User 50) local loss: 0.7429\n",
      "  Client 51 (User 51) local loss: 0.8570\n",
      "  Client 52 (User 52) local loss: 0.8143\n",
      "  Client 53 (User 53) local loss: 0.8573\n",
      "  Client 54 (User 54) local loss: 0.7739\n",
      "  Client 55 (User 55) local loss: 0.7993\n",
      "  Client 56 (User 56) local loss: 0.8332\n",
      "  Client 57 (User 57) local loss: 0.7892\n",
      "  Client 58 (User 58) local loss: 0.8655\n",
      "  Client 59 (User 59) local loss: 0.8213\n",
      "  Client 60 (User 60) local loss: 0.8314\n",
      "  Client 61 (User 61) local loss: 0.8775\n",
      "  Client 62 (User 62) local loss: 0.9147\n",
      "  Client 63 (User 63) local loss: 0.7963\n",
      "  Client 64 (User 64) local loss: 0.8090\n",
      "  Client 65 (User 65) local loss: 0.8349\n",
      "  Client 66 (User 66) local loss: 0.7591\n",
      "  Client 67 (User 67) local loss: 0.8080\n",
      "  Client 68 (User 68) local loss: 0.8411\n",
      "  Client 69 (User 69) local loss: 0.8157\n",
      "  Client 70 (User 70) local loss: 0.8542\n",
      "  Client 71 (User 71) local loss: 0.7773\n",
      "  Client 72 (User 72) local loss: 0.8450\n",
      "  Client 73 (User 73) local loss: 0.8377\n",
      "  Client 74 (User 74) local loss: 0.8016\n",
      "  Client 75 (User 75) local loss: 0.7799\n",
      "  Client 76 (User 76) local loss: 0.8373\n",
      "  Client 77 (User 77) local loss: 0.8041\n",
      "  Client 78 (User 78) local loss: 0.7892\n",
      "  Client 79 (User 79) local loss: 0.7897\n",
      "  Client 80 (User 80) local loss: 0.8161\n",
      "  Client 81 (User 81) local loss: 0.8626\n",
      "  Client 82 (User 82) local loss: 0.8421\n",
      "  Client 83 (User 83) local loss: 0.7869\n",
      "  Client 84 (User 84) local loss: 0.7884\n",
      "  Client 85 (User 85) local loss: 0.7853\n",
      "  Client 86 (User 86) local loss: 0.8078\n",
      "  Client 87 (User 87) local loss: 0.7759\n",
      "  Client 88 (User 88) local loss: 0.8099\n",
      "  Client 89 (User 89) local loss: 0.7488\n",
      "  Client 90 (User 90) local loss: 0.8172\n",
      "  Client 91 (User 91) local loss: 0.7699\n",
      "  Client 92 (User 92) local loss: 0.8990\n",
      "  Client 93 (User 93) local loss: 0.8151\n",
      "  Client 94 (User 94) local loss: 0.8412\n",
      "  Client 95 (User 95) local loss: 0.7801\n",
      "  Client 96 (User 96) local loss: 0.8201\n",
      "  Client 97 (User 97) local loss: 0.7948\n",
      "  Client 98 (User 98) local loss: 0.8284\n",
      "  Client 99 (User 99) local loss: 0.8733\n",
      "Round 5 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 6/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7851\n",
      "  Client 1 (User 1) local loss: 0.8040\n",
      "  Client 2 (User 2) local loss: 0.8213\n",
      "  Client 3 (User 3) local loss: 0.8528\n",
      "  Client 4 (User 4) local loss: 0.7194\n",
      "  Client 5 (User 5) local loss: 0.7424\n",
      "  Client 6 (User 6) local loss: 0.8395\n",
      "  Client 7 (User 7) local loss: 0.8421\n",
      "  Client 8 (User 8) local loss: 0.8035\n",
      "  Client 9 (User 9) local loss: 0.8274\n",
      "  Client 10 (User 10) local loss: 0.8320\n",
      "  Client 11 (User 11) local loss: 0.8363\n",
      "  Client 12 (User 12) local loss: 0.7793\n",
      "  Client 13 (User 13) local loss: 0.8480\n",
      "  Client 14 (User 14) local loss: 0.7801\n",
      "  Client 15 (User 15) local loss: 0.8215\n",
      "  Client 16 (User 16) local loss: 0.8096\n",
      "  Client 17 (User 17) local loss: 0.7602\n",
      "  Client 18 (User 18) local loss: 0.8417\n",
      "  Client 19 (User 19) local loss: 0.8839\n",
      "  Client 20 (User 20) local loss: 0.8201\n",
      "  Client 21 (User 21) local loss: 0.8040\n",
      "  Client 22 (User 22) local loss: 0.7997\n",
      "  Client 23 (User 23) local loss: 0.8304\n",
      "  Client 24 (User 24) local loss: 0.8347\n",
      "  Client 25 (User 25) local loss: 0.8325\n",
      "  Client 26 (User 26) local loss: 0.8210\n",
      "  Client 27 (User 27) local loss: 0.8492\n",
      "  Client 28 (User 28) local loss: 0.8650\n",
      "  Client 29 (User 29) local loss: 0.8157\n",
      "  Client 30 (User 30) local loss: 0.8196\n",
      "  Client 31 (User 31) local loss: 0.8549\n",
      "  Client 32 (User 32) local loss: 0.8258\n",
      "  Client 33 (User 33) local loss: 0.8116\n",
      "  Client 34 (User 34) local loss: 0.8238\n",
      "  Client 35 (User 35) local loss: 0.8550\n",
      "  Client 36 (User 36) local loss: 0.8628\n",
      "  Client 37 (User 37) local loss: 0.7375\n",
      "  Client 38 (User 38) local loss: 0.8088\n",
      "  Client 39 (User 39) local loss: 0.7666\n",
      "  Client 40 (User 40) local loss: 0.7483\n",
      "  Client 41 (User 41) local loss: 0.8125\n",
      "  Client 42 (User 42) local loss: 0.7978\n",
      "  Client 43 (User 43) local loss: 0.8076\n",
      "  Client 44 (User 44) local loss: 0.8073\n",
      "  Client 45 (User 45) local loss: 0.8102\n",
      "  Client 46 (User 46) local loss: 0.7952\n",
      "  Client 47 (User 47) local loss: 0.8617\n",
      "  Client 48 (User 48) local loss: 0.8202\n",
      "  Client 49 (User 49) local loss: 0.7496\n",
      "  Client 50 (User 50) local loss: 0.7311\n",
      "  Client 51 (User 51) local loss: 0.8600\n",
      "  Client 52 (User 52) local loss: 0.8155\n",
      "  Client 53 (User 53) local loss: 0.8655\n",
      "  Client 54 (User 54) local loss: 0.7751\n",
      "  Client 55 (User 55) local loss: 0.7962\n",
      "  Client 56 (User 56) local loss: 0.8380\n",
      "  Client 57 (User 57) local loss: 0.7811\n",
      "  Client 58 (User 58) local loss: 0.8529\n",
      "  Client 59 (User 59) local loss: 0.8287\n",
      "  Client 60 (User 60) local loss: 0.8428\n",
      "  Client 61 (User 61) local loss: 0.8606\n",
      "  Client 62 (User 62) local loss: 0.9132\n",
      "  Client 63 (User 63) local loss: 0.7913\n",
      "  Client 64 (User 64) local loss: 0.8015\n",
      "  Client 65 (User 65) local loss: 0.8410\n",
      "  Client 66 (User 66) local loss: 0.7711\n",
      "  Client 67 (User 67) local loss: 0.7861\n",
      "  Client 68 (User 68) local loss: 0.8228\n",
      "  Client 69 (User 69) local loss: 0.8085\n",
      "  Client 70 (User 70) local loss: 0.8411\n",
      "  Client 71 (User 71) local loss: 0.7637\n",
      "  Client 72 (User 72) local loss: 0.8364\n",
      "  Client 73 (User 73) local loss: 0.8272\n",
      "  Client 74 (User 74) local loss: 0.7964\n",
      "  Client 75 (User 75) local loss: 0.7900\n",
      "  Client 76 (User 76) local loss: 0.8387\n",
      "  Client 77 (User 77) local loss: 0.8062\n",
      "  Client 78 (User 78) local loss: 0.7749\n",
      "  Client 79 (User 79) local loss: 0.7882\n",
      "  Client 80 (User 80) local loss: 0.8219\n",
      "  Client 81 (User 81) local loss: 0.8476\n",
      "  Client 82 (User 82) local loss: 0.8413\n",
      "  Client 83 (User 83) local loss: 0.7921\n",
      "  Client 84 (User 84) local loss: 0.7906\n",
      "  Client 85 (User 85) local loss: 0.7790\n",
      "  Client 86 (User 86) local loss: 0.7991\n",
      "  Client 87 (User 87) local loss: 0.7839\n",
      "  Client 88 (User 88) local loss: 0.7770\n",
      "  Client 89 (User 89) local loss: 0.7657\n",
      "  Client 90 (User 90) local loss: 0.8306\n",
      "  Client 91 (User 91) local loss: 0.7991\n",
      "  Client 92 (User 92) local loss: 0.9078\n",
      "  Client 93 (User 93) local loss: 0.8032\n",
      "  Client 94 (User 94) local loss: 0.8536\n",
      "  Client 95 (User 95) local loss: 0.7907\n",
      "  Client 96 (User 96) local loss: 0.8128\n",
      "  Client 97 (User 97) local loss: 0.8071\n",
      "  Client 98 (User 98) local loss: 0.8334\n",
      "  Client 99 (User 99) local loss: 0.8765\n",
      "Round 6 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 7/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7847\n",
      "  Client 1 (User 1) local loss: 0.8021\n",
      "  Client 2 (User 2) local loss: 0.8239\n",
      "  Client 3 (User 3) local loss: 0.8537\n",
      "  Client 4 (User 4) local loss: 0.7303\n",
      "  Client 5 (User 5) local loss: 0.7210\n",
      "  Client 6 (User 6) local loss: 0.8205\n",
      "  Client 7 (User 7) local loss: 0.8459\n",
      "  Client 8 (User 8) local loss: 0.8081\n",
      "  Client 9 (User 9) local loss: 0.8255\n",
      "  Client 10 (User 10) local loss: 0.8319\n",
      "  Client 11 (User 11) local loss: 0.8181\n",
      "  Client 12 (User 12) local loss: 0.7681\n",
      "  Client 13 (User 13) local loss: 0.8387\n",
      "  Client 14 (User 14) local loss: 0.7946\n",
      "  Client 15 (User 15) local loss: 0.8133\n",
      "  Client 16 (User 16) local loss: 0.8217\n",
      "  Client 17 (User 17) local loss: 0.7753\n",
      "  Client 18 (User 18) local loss: 0.8147\n",
      "  Client 19 (User 19) local loss: 0.8479\n",
      "  Client 20 (User 20) local loss: 0.8004\n",
      "  Client 21 (User 21) local loss: 0.8074\n",
      "  Client 22 (User 22) local loss: 0.8002\n",
      "  Client 23 (User 23) local loss: 0.8152\n",
      "  Client 24 (User 24) local loss: 0.8249\n",
      "  Client 25 (User 25) local loss: 0.8237\n",
      "  Client 26 (User 26) local loss: 0.8198\n",
      "  Client 27 (User 27) local loss: 0.8491\n",
      "  Client 28 (User 28) local loss: 0.8642\n",
      "  Client 29 (User 29) local loss: 0.8092\n",
      "  Client 30 (User 30) local loss: 0.8224\n",
      "  Client 31 (User 31) local loss: 0.8531\n",
      "  Client 32 (User 32) local loss: 0.8005\n",
      "  Client 33 (User 33) local loss: 0.8099\n",
      "  Client 34 (User 34) local loss: 0.8141\n",
      "  Client 35 (User 35) local loss: 0.8331\n",
      "  Client 36 (User 36) local loss: 0.8547\n",
      "  Client 37 (User 37) local loss: 0.7417\n",
      "  Client 38 (User 38) local loss: 0.8088\n",
      "  Client 39 (User 39) local loss: 0.7486\n",
      "  Client 40 (User 40) local loss: 0.7732\n",
      "  Client 41 (User 41) local loss: 0.8010\n",
      "  Client 42 (User 42) local loss: 0.7891\n",
      "  Client 43 (User 43) local loss: 0.8251\n",
      "  Client 44 (User 44) local loss: 0.7945\n",
      "  Client 45 (User 45) local loss: 0.8032\n",
      "  Client 46 (User 46) local loss: 0.7835\n",
      "  Client 47 (User 47) local loss: 0.8299\n",
      "  Client 48 (User 48) local loss: 0.8166\n",
      "  Client 49 (User 49) local loss: 0.7428\n",
      "  Client 50 (User 50) local loss: 0.7328\n",
      "  Client 51 (User 51) local loss: 0.8690\n",
      "  Client 52 (User 52) local loss: 0.8005\n",
      "  Client 53 (User 53) local loss: 0.8678\n",
      "  Client 54 (User 54) local loss: 0.7686\n",
      "  Client 55 (User 55) local loss: 0.7751\n",
      "  Client 56 (User 56) local loss: 0.8362\n",
      "  Client 57 (User 57) local loss: 0.7917\n",
      "  Client 58 (User 58) local loss: 0.8489\n",
      "  Client 59 (User 59) local loss: 0.8204\n",
      "  Client 60 (User 60) local loss: 0.8330\n",
      "  Client 61 (User 61) local loss: 0.8517\n",
      "  Client 62 (User 62) local loss: 0.9047\n",
      "  Client 63 (User 63) local loss: 0.7920\n",
      "  Client 64 (User 64) local loss: 0.7988\n",
      "  Client 65 (User 65) local loss: 0.8509\n",
      "  Client 66 (User 66) local loss: 0.7627\n",
      "  Client 67 (User 67) local loss: 0.7995\n",
      "  Client 68 (User 68) local loss: 0.8322\n",
      "  Client 69 (User 69) local loss: 0.8190\n",
      "  Client 70 (User 70) local loss: 0.8389\n",
      "  Client 71 (User 71) local loss: 0.7807\n",
      "  Client 72 (User 72) local loss: 0.8318\n",
      "  Client 73 (User 73) local loss: 0.8235\n",
      "  Client 74 (User 74) local loss: 0.7770\n",
      "  Client 75 (User 75) local loss: 0.7993\n",
      "  Client 76 (User 76) local loss: 0.8270\n",
      "  Client 77 (User 77) local loss: 0.8033\n",
      "  Client 78 (User 78) local loss: 0.7773\n",
      "  Client 79 (User 79) local loss: 0.7976\n",
      "  Client 80 (User 80) local loss: 0.8149\n",
      "  Client 81 (User 81) local loss: 0.8453\n",
      "  Client 82 (User 82) local loss: 0.8265\n",
      "  Client 83 (User 83) local loss: 0.7784\n",
      "  Client 84 (User 84) local loss: 0.7957\n",
      "  Client 85 (User 85) local loss: 0.7897\n",
      "  Client 86 (User 86) local loss: 0.8038\n",
      "  Client 87 (User 87) local loss: 0.7690\n",
      "  Client 88 (User 88) local loss: 0.7887\n",
      "  Client 89 (User 89) local loss: 0.7463\n",
      "  Client 90 (User 90) local loss: 0.8290\n",
      "  Client 91 (User 91) local loss: 0.7866\n",
      "  Client 92 (User 92) local loss: 0.8836\n",
      "  Client 93 (User 93) local loss: 0.8068\n",
      "  Client 94 (User 94) local loss: 0.8429\n",
      "  Client 95 (User 95) local loss: 0.7710\n",
      "  Client 96 (User 96) local loss: 0.8053\n",
      "  Client 97 (User 97) local loss: 0.7956\n",
      "  Client 98 (User 98) local loss: 0.7997\n",
      "  Client 99 (User 99) local loss: 0.8729\n",
      "Round 7 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 8/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7751\n",
      "  Client 1 (User 1) local loss: 0.7813\n",
      "  Client 2 (User 2) local loss: 0.8134\n",
      "  Client 3 (User 3) local loss: 0.8426\n",
      "  Client 4 (User 4) local loss: 0.7236\n",
      "  Client 5 (User 5) local loss: 0.7313\n",
      "  Client 6 (User 6) local loss: 0.8280\n",
      "  Client 7 (User 7) local loss: 0.8365\n",
      "  Client 8 (User 8) local loss: 0.8017\n",
      "  Client 9 (User 9) local loss: 0.8170\n",
      "  Client 10 (User 10) local loss: 0.8195\n",
      "  Client 11 (User 11) local loss: 0.7980\n",
      "  Client 12 (User 12) local loss: 0.7687\n",
      "  Client 13 (User 13) local loss: 0.8346\n",
      "  Client 14 (User 14) local loss: 0.7705\n",
      "  Client 15 (User 15) local loss: 0.8107\n",
      "  Client 16 (User 16) local loss: 0.8292\n",
      "  Client 17 (User 17) local loss: 0.7555\n",
      "  Client 18 (User 18) local loss: 0.7989\n",
      "  Client 19 (User 19) local loss: 0.8719\n",
      "  Client 20 (User 20) local loss: 0.8257\n",
      "  Client 21 (User 21) local loss: 0.7890\n",
      "  Client 22 (User 22) local loss: 0.8058\n",
      "  Client 23 (User 23) local loss: 0.8132\n",
      "  Client 24 (User 24) local loss: 0.8208\n",
      "  Client 25 (User 25) local loss: 0.8316\n",
      "  Client 26 (User 26) local loss: 0.8096\n",
      "  Client 27 (User 27) local loss: 0.8464\n",
      "  Client 28 (User 28) local loss: 0.8767\n",
      "  Client 29 (User 29) local loss: 0.7991\n",
      "  Client 30 (User 30) local loss: 0.8139\n",
      "  Client 31 (User 31) local loss: 0.8435\n",
      "  Client 32 (User 32) local loss: 0.8059\n",
      "  Client 33 (User 33) local loss: 0.8036\n",
      "  Client 34 (User 34) local loss: 0.7996\n",
      "  Client 35 (User 35) local loss: 0.8254\n",
      "  Client 36 (User 36) local loss: 0.8463\n",
      "  Client 37 (User 37) local loss: 0.7398\n",
      "  Client 38 (User 38) local loss: 0.7951\n",
      "  Client 39 (User 39) local loss: 0.7448\n",
      "  Client 40 (User 40) local loss: 0.7523\n",
      "  Client 41 (User 41) local loss: 0.7841\n",
      "  Client 42 (User 42) local loss: 0.7808\n",
      "  Client 43 (User 43) local loss: 0.8161\n",
      "  Client 44 (User 44) local loss: 0.7859\n",
      "  Client 45 (User 45) local loss: 0.7967\n",
      "  Client 46 (User 46) local loss: 0.7705\n",
      "  Client 47 (User 47) local loss: 0.8265\n",
      "  Client 48 (User 48) local loss: 0.8081\n",
      "  Client 49 (User 49) local loss: 0.7363\n",
      "  Client 50 (User 50) local loss: 0.7245\n",
      "  Client 51 (User 51) local loss: 0.8602\n",
      "  Client 52 (User 52) local loss: 0.8043\n",
      "  Client 53 (User 53) local loss: 0.8598\n",
      "  Client 54 (User 54) local loss: 0.7621\n",
      "  Client 55 (User 55) local loss: 0.7847\n",
      "  Client 56 (User 56) local loss: 0.8466\n",
      "  Client 57 (User 57) local loss: 0.7772\n",
      "  Client 58 (User 58) local loss: 0.8277\n",
      "  Client 59 (User 59) local loss: 0.8010\n",
      "  Client 60 (User 60) local loss: 0.8329\n",
      "  Client 61 (User 61) local loss: 0.8408\n",
      "  Client 62 (User 62) local loss: 0.8856\n",
      "  Client 63 (User 63) local loss: 0.7826\n",
      "  Client 64 (User 64) local loss: 0.7915\n",
      "  Client 65 (User 65) local loss: 0.8400\n",
      "  Client 66 (User 66) local loss: 0.7535\n",
      "  Client 67 (User 67) local loss: 0.7920\n",
      "  Client 68 (User 68) local loss: 0.8052\n",
      "  Client 69 (User 69) local loss: 0.7851\n",
      "  Client 70 (User 70) local loss: 0.8311\n",
      "  Client 71 (User 71) local loss: 0.7723\n",
      "  Client 72 (User 72) local loss: 0.8309\n",
      "  Client 73 (User 73) local loss: 0.8263\n",
      "  Client 74 (User 74) local loss: 0.7657\n",
      "  Client 75 (User 75) local loss: 0.7858\n",
      "  Client 76 (User 76) local loss: 0.8220\n",
      "  Client 77 (User 77) local loss: 0.7930\n",
      "  Client 78 (User 78) local loss: 0.7792\n",
      "  Client 79 (User 79) local loss: 0.7913\n",
      "  Client 80 (User 80) local loss: 0.8168\n",
      "  Client 81 (User 81) local loss: 0.8420\n",
      "  Client 82 (User 82) local loss: 0.8327\n",
      "  Client 83 (User 83) local loss: 0.7701\n",
      "  Client 84 (User 84) local loss: 0.7711\n",
      "  Client 85 (User 85) local loss: 0.7669\n",
      "  Client 86 (User 86) local loss: 0.7876\n",
      "  Client 87 (User 87) local loss: 0.7707\n",
      "  Client 88 (User 88) local loss: 0.8002\n",
      "  Client 89 (User 89) local loss: 0.7483\n",
      "  Client 90 (User 90) local loss: 0.8158\n",
      "  Client 91 (User 91) local loss: 0.7802\n",
      "  Client 92 (User 92) local loss: 0.9027\n",
      "  Client 93 (User 93) local loss: 0.7952\n",
      "  Client 94 (User 94) local loss: 0.8407\n",
      "  Client 95 (User 95) local loss: 0.8123\n",
      "  Client 96 (User 96) local loss: 0.8053\n",
      "  Client 97 (User 97) local loss: 0.7852\n",
      "  Client 98 (User 98) local loss: 0.8158\n",
      "  Client 99 (User 99) local loss: 0.8678\n",
      "Round 8 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 9/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7485\n",
      "  Client 1 (User 1) local loss: 0.7955\n",
      "  Client 2 (User 2) local loss: 0.8047\n",
      "  Client 3 (User 3) local loss: 0.8311\n",
      "  Client 4 (User 4) local loss: 0.7228\n",
      "  Client 5 (User 5) local loss: 0.7215\n",
      "  Client 6 (User 6) local loss: 0.8064\n",
      "  Client 7 (User 7) local loss: 0.8265\n",
      "  Client 8 (User 8) local loss: 0.7787\n",
      "  Client 9 (User 9) local loss: 0.8270\n",
      "  Client 10 (User 10) local loss: 0.8095\n",
      "  Client 11 (User 11) local loss: 0.7880\n",
      "  Client 12 (User 12) local loss: 0.7507\n",
      "  Client 13 (User 13) local loss: 0.8223\n",
      "  Client 14 (User 14) local loss: 0.7768\n",
      "  Client 15 (User 15) local loss: 0.7982\n",
      "  Client 16 (User 16) local loss: 0.8087\n",
      "  Client 17 (User 17) local loss: 0.7522\n",
      "  Client 18 (User 18) local loss: 0.7846\n",
      "  Client 19 (User 19) local loss: 0.8563\n",
      "  Client 20 (User 20) local loss: 0.8046\n",
      "  Client 21 (User 21) local loss: 0.7915\n",
      "  Client 22 (User 22) local loss: 0.7951\n",
      "  Client 23 (User 23) local loss: 0.7846\n",
      "  Client 24 (User 24) local loss: 0.8365\n",
      "  Client 25 (User 25) local loss: 0.8245\n",
      "  Client 26 (User 26) local loss: 0.8167\n",
      "  Client 27 (User 27) local loss: 0.8368\n",
      "  Client 28 (User 28) local loss: 0.8762\n",
      "  Client 29 (User 29) local loss: 0.7836\n",
      "  Client 30 (User 30) local loss: 0.8155\n",
      "  Client 31 (User 31) local loss: 0.8220\n",
      "  Client 32 (User 32) local loss: 0.8201\n",
      "  Client 33 (User 33) local loss: 0.7880\n",
      "  Client 34 (User 34) local loss: 0.7744\n",
      "  Client 35 (User 35) local loss: 0.8241\n",
      "  Client 36 (User 36) local loss: 0.8595\n",
      "  Client 37 (User 37) local loss: 0.7486\n",
      "  Client 38 (User 38) local loss: 0.7861\n",
      "  Client 39 (User 39) local loss: 0.7210\n",
      "  Client 40 (User 40) local loss: 0.7761\n",
      "  Client 41 (User 41) local loss: 0.7851\n",
      "  Client 42 (User 42) local loss: 0.7752\n",
      "  Client 43 (User 43) local loss: 0.8004\n",
      "  Client 44 (User 44) local loss: 0.7942\n",
      "  Client 45 (User 45) local loss: 0.7752\n",
      "  Client 46 (User 46) local loss: 0.7669\n",
      "  Client 47 (User 47) local loss: 0.8090\n",
      "  Client 48 (User 48) local loss: 0.7926\n",
      "  Client 49 (User 49) local loss: 0.7525\n",
      "  Client 50 (User 50) local loss: 0.7168\n",
      "  Client 51 (User 51) local loss: 0.8392\n",
      "  Client 52 (User 52) local loss: 0.7877\n",
      "  Client 53 (User 53) local loss: 0.8552\n",
      "  Client 54 (User 54) local loss: 0.7498\n",
      "  Client 55 (User 55) local loss: 0.7743\n",
      "  Client 56 (User 56) local loss: 0.8301\n",
      "  Client 57 (User 57) local loss: 0.7803\n",
      "  Client 58 (User 58) local loss: 0.8211\n",
      "  Client 59 (User 59) local loss: 0.7945\n",
      "  Client 60 (User 60) local loss: 0.8169\n",
      "  Client 61 (User 61) local loss: 0.8207\n",
      "  Client 62 (User 62) local loss: 0.8759\n",
      "  Client 63 (User 63) local loss: 0.7667\n",
      "  Client 64 (User 64) local loss: 0.7976\n",
      "  Client 65 (User 65) local loss: 0.8221\n",
      "  Client 66 (User 66) local loss: 0.7509\n",
      "  Client 67 (User 67) local loss: 0.7796\n",
      "  Client 68 (User 68) local loss: 0.7920\n",
      "  Client 69 (User 69) local loss: 0.8050\n",
      "  Client 70 (User 70) local loss: 0.8291\n",
      "  Client 71 (User 71) local loss: 0.7755\n",
      "  Client 72 (User 72) local loss: 0.8232\n",
      "  Client 73 (User 73) local loss: 0.8157\n",
      "  Client 74 (User 74) local loss: 0.7614\n",
      "  Client 75 (User 75) local loss: 0.8001\n",
      "  Client 76 (User 76) local loss: 0.8113\n",
      "  Client 77 (User 77) local loss: 0.7901\n",
      "  Client 78 (User 78) local loss: 0.7736\n",
      "  Client 79 (User 79) local loss: 0.7901\n",
      "  Client 80 (User 80) local loss: 0.7939\n",
      "  Client 81 (User 81) local loss: 0.8417\n",
      "  Client 82 (User 82) local loss: 0.8387\n",
      "  Client 83 (User 83) local loss: 0.7589\n",
      "  Client 84 (User 84) local loss: 0.7643\n",
      "  Client 85 (User 85) local loss: 0.7660\n",
      "  Client 86 (User 86) local loss: 0.7824\n",
      "  Client 87 (User 87) local loss: 0.7558\n",
      "  Client 88 (User 88) local loss: 0.7921\n",
      "  Client 89 (User 89) local loss: 0.7403\n",
      "  Client 90 (User 90) local loss: 0.8015\n",
      "  Client 91 (User 91) local loss: 0.7741\n",
      "  Client 92 (User 92) local loss: 0.8754\n",
      "  Client 93 (User 93) local loss: 0.7931\n",
      "  Client 94 (User 94) local loss: 0.8217\n",
      "  Client 95 (User 95) local loss: 0.7748\n",
      "  Client 96 (User 96) local loss: 0.7959\n",
      "  Client 97 (User 97) local loss: 0.7621\n",
      "  Client 98 (User 98) local loss: 0.8191\n",
      "  Client 99 (User 99) local loss: 0.8561\n",
      "Round 9 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 10/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7567\n",
      "  Client 1 (User 1) local loss: 0.7742\n",
      "  Client 2 (User 2) local loss: 0.7938\n",
      "  Client 3 (User 3) local loss: 0.8309\n",
      "  Client 4 (User 4) local loss: 0.7374\n",
      "  Client 5 (User 5) local loss: 0.7100\n",
      "  Client 6 (User 6) local loss: 0.8010\n",
      "  Client 7 (User 7) local loss: 0.8020\n",
      "  Client 8 (User 8) local loss: 0.7794\n",
      "  Client 9 (User 9) local loss: 0.8063\n",
      "  Client 10 (User 10) local loss: 0.7970\n",
      "  Client 11 (User 11) local loss: 0.7728\n",
      "  Client 12 (User 12) local loss: 0.7382\n",
      "  Client 13 (User 13) local loss: 0.8362\n",
      "  Client 14 (User 14) local loss: 0.7633\n",
      "  Client 15 (User 15) local loss: 0.7996\n",
      "  Client 16 (User 16) local loss: 0.7839\n",
      "  Client 17 (User 17) local loss: 0.7405\n",
      "  Client 18 (User 18) local loss: 0.7697\n",
      "  Client 19 (User 19) local loss: 0.8593\n",
      "  Client 20 (User 20) local loss: 0.8139\n",
      "  Client 21 (User 21) local loss: 0.7872\n",
      "  Client 22 (User 22) local loss: 0.7681\n",
      "  Client 23 (User 23) local loss: 0.7713\n",
      "  Client 24 (User 24) local loss: 0.8130\n",
      "  Client 25 (User 25) local loss: 0.8140\n",
      "  Client 26 (User 26) local loss: 0.7986\n",
      "  Client 27 (User 27) local loss: 0.8057\n",
      "  Client 28 (User 28) local loss: 0.8687\n",
      "  Client 29 (User 29) local loss: 0.7690\n",
      "  Client 30 (User 30) local loss: 0.8142\n",
      "  Client 31 (User 31) local loss: 0.8419\n",
      "  Client 32 (User 32) local loss: 0.8014\n",
      "  Client 33 (User 33) local loss: 0.7675\n",
      "  Client 34 (User 34) local loss: 0.7609\n",
      "  Client 35 (User 35) local loss: 0.8161\n",
      "  Client 36 (User 36) local loss: 0.8537\n",
      "  Client 37 (User 37) local loss: 0.7386\n",
      "  Client 38 (User 38) local loss: 0.7656\n",
      "  Client 39 (User 39) local loss: 0.7169\n",
      "  Client 40 (User 40) local loss: 0.7417\n",
      "  Client 41 (User 41) local loss: 0.7956\n",
      "  Client 42 (User 42) local loss: 0.7717\n",
      "  Client 43 (User 43) local loss: 0.7969\n",
      "  Client 44 (User 44) local loss: 0.7802\n",
      "  Client 45 (User 45) local loss: 0.7661\n",
      "  Client 46 (User 46) local loss: 0.7688\n",
      "  Client 47 (User 47) local loss: 0.7837\n",
      "  Client 48 (User 48) local loss: 0.7697\n",
      "  Client 49 (User 49) local loss: 0.7391\n",
      "  Client 50 (User 50) local loss: 0.7189\n",
      "  Client 51 (User 51) local loss: 0.8529\n",
      "  Client 52 (User 52) local loss: 0.7894\n",
      "  Client 53 (User 53) local loss: 0.8398\n",
      "  Client 54 (User 54) local loss: 0.7462\n",
      "  Client 55 (User 55) local loss: 0.7700\n",
      "  Client 56 (User 56) local loss: 0.8183\n",
      "  Client 57 (User 57) local loss: 0.7656\n",
      "  Client 58 (User 58) local loss: 0.7821\n",
      "  Client 59 (User 59) local loss: 0.7597\n",
      "  Client 60 (User 60) local loss: 0.8130\n",
      "  Client 61 (User 61) local loss: 0.8019\n",
      "  Client 62 (User 62) local loss: 0.8483\n",
      "  Client 63 (User 63) local loss: 0.7543\n",
      "  Client 64 (User 64) local loss: 0.7930\n",
      "  Client 65 (User 65) local loss: 0.8113\n",
      "  Client 66 (User 66) local loss: 0.7477\n",
      "  Client 67 (User 67) local loss: 0.7854\n",
      "  Client 68 (User 68) local loss: 0.7750\n",
      "  Client 69 (User 69) local loss: 0.7932\n",
      "  Client 70 (User 70) local loss: 0.8216\n",
      "  Client 71 (User 71) local loss: 0.7441\n",
      "  Client 72 (User 72) local loss: 0.8015\n",
      "  Client 73 (User 73) local loss: 0.7862\n",
      "  Client 74 (User 74) local loss: 0.7605\n",
      "  Client 75 (User 75) local loss: 0.7917\n",
      "  Client 76 (User 76) local loss: 0.7950\n",
      "  Client 77 (User 77) local loss: 0.7823\n",
      "  Client 78 (User 78) local loss: 0.7724\n",
      "  Client 79 (User 79) local loss: 0.7994\n",
      "  Client 80 (User 80) local loss: 0.7830\n",
      "  Client 81 (User 81) local loss: 0.8337\n",
      "  Client 82 (User 82) local loss: 0.8242\n",
      "  Client 83 (User 83) local loss: 0.7463\n",
      "  Client 84 (User 84) local loss: 0.7654\n",
      "  Client 85 (User 85) local loss: 0.7765\n",
      "  Client 86 (User 86) local loss: 0.7758\n",
      "  Client 87 (User 87) local loss: 0.7656\n",
      "  Client 88 (User 88) local loss: 0.7956\n",
      "  Client 89 (User 89) local loss: 0.7516\n",
      "  Client 90 (User 90) local loss: 0.7886\n",
      "  Client 91 (User 91) local loss: 0.7739\n",
      "  Client 92 (User 92) local loss: 0.8657\n",
      "  Client 93 (User 93) local loss: 0.7950\n",
      "  Client 94 (User 94) local loss: 0.8135\n",
      "  Client 95 (User 95) local loss: 0.7782\n",
      "  Client 96 (User 96) local loss: 0.7887\n",
      "  Client 97 (User 97) local loss: 0.7558\n",
      "  Client 98 (User 98) local loss: 0.8016\n",
      "  Client 99 (User 99) local loss: 0.8476\n",
      "Round 10 completed. Global item embeddings updated.\n",
      "Federated training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 軽量 LLM 埋め込みモデルのロード (変更なし)\n",
    "plm_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "plm_tokenizer = AutoTokenizer.from_pretrained(plm_model_name)\n",
    "plm_model = AutoModel.from_pretrained(plm_model_name)\n",
    "\n",
    "# PLMは学習済みモデルのため、勾配計算を無効化\n",
    "for param in plm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "plm_embedding_dim = plm_model.config.hidden_size\n",
    "print(f\"PLM embedding dimension: {plm_embedding_dim}\")\n",
    "\n",
    "\n",
    "class ClientModel(nn.Module):\n",
    "    def __init__(self, num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.plm_model = plm_model\n",
    "        \n",
    "        # Joint Embedding Layer (module parameter θ_user) [cite: 64]\n",
    "        # 論文の式(3) e_u = h(v_u) = v_u W_d1xd + b [cite: 78]\n",
    "        self.user_joint_embedding_linear = nn.Linear(plm_embedding_dim, joint_embedding_output_dim)\n",
    "        \n",
    "        # Item Embedding Layer (module parameter θ_item) [cite: 64]\n",
    "        self.local_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        # User Feature Refinement MLP (module parameter θ_umlp) [cite: 66]\n",
    "        # 論文のImplementation Detailsで「user's mlp layer uses a two-layer mlp layer with a 32-64-32 architecture」とある [cite: 169]\n",
    "        self.user_mlp = nn.Sequential(\n",
    "            nn.Linear(joint_embedding_output_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32) # 出力次元はユーザー埋め込み次元と同じ32に設定 [cite: 169]\n",
    "        )\n",
    "\n",
    "        # Predictive Scoring Function (module parameter θ_score) [cite: 67]\n",
    "        # 論文のImplementation Detailsで「32->16->8->1」のスキーマを持つMLPを使用とある [cite: 168]\n",
    "        self.prediction_mlp = nn.Sequential(\n",
    "            nn.Linear(item_embedding_dim + joint_embedding_output_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    # Transformer Block は削除されたため、historical_item_sequences は不要\n",
    "    def forward(self, user_ids, item_ids, user_texts_batch): \n",
    "        # ユーザーのテキスト特徴をPLMで埋め込み\n",
    "        encoded_input = plm_tokenizer(user_texts_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        plm_output = self.plm_model(**encoded_input).last_hidden_state[:, 0, :] # [CLS]トークンの埋め込みを使用\n",
    "\n",
    "        # Joint Embedding Layer: テキスト埋め込みからユーザー特徴ベクトルを生成\n",
    "        user_raw_embedding = self.user_joint_embedding_linear(plm_output)\n",
    "        \n",
    "        # User Feature Refinement MLP: ユーザー特徴の高次表現を抽出 [cite: 66]\n",
    "        user_embedding = self.user_mlp(user_raw_embedding) # (batch_size, joint_embedding_output_dim)\n",
    "\n",
    "        # アイテム埋め込み\n",
    "        item_embedding = self.local_item_embedding(item_ids) # (batch_size, item_embedding_dim)\n",
    "\n",
    "        # 予測層への入力は、User MLPの出力（ユーザー特徴）とターゲットアイテムの埋め込みを結合 [cite: 67]\n",
    "        combined_features = torch.cat((user_embedding, item_embedding), dim=1)\n",
    "        logits = self.prediction_mlp(combined_features)\n",
    "        predictions = torch.sigmoid(logits)\n",
    "\n",
    "        # グラフ構築とアイテム集約のために、user_joint_embedding_linear.weight と local_item_embedding.weight を返す\n",
    "        # 論文の「Parameter Uploading: Clients transmit user joint embedding weights and local item embeddings to the server.」 [cite: 61]\n",
    "        return predictions, self.user_joint_embedding_linear.weight, self.local_item_embedding.weight\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, num_users, num_items, item_embedding_dim, joint_embedding_output_dim):\n",
    "        self.global_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        self.joint_embedding_output_dim = joint_embedding_output_dim\n",
    "    \n",
    "    def build_user_relationship_graph(self, user_linear_weights_map):\n",
    "        \"\"\"\n",
    "        各ユーザーのuser_joint_embedding_linear.weightからユーザー関係グラフを構築します。\n",
    "        論文の式 (15) に基づいています。 [cite: 106]\n",
    "        \n",
    "        Args:\n",
    "            user_linear_weights_map (dict): {user_id: user_joint_embedding_linear.weight.data (flattened)}\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: ユーザーグラフの隣接行列 (NumPy配列)\n",
    "            list: グラフのノード順に対応するユーザーIDのリスト\n",
    "        \"\"\"\n",
    "        sorted_user_ids = sorted(user_linear_weights_map.keys())\n",
    "        if not sorted_user_ids:\n",
    "            return np.zeros((0, 0)), []\n",
    "\n",
    "        # 各ユーザーの線形層の重みベクトルを収集\n",
    "        # 論文の「w_i = vec(W_i)」に相当 [cite: 105]\n",
    "        user_weight_vectors = np.array([\n",
    "            user_linear_weights_map[u_id].cpu().numpy() for u_id in sorted_user_ids\n",
    "        ])\n",
    "\n",
    "        # コサイン類似度で類似度行列を計算 (S_ij) [cite: 106]\n",
    "        similarity_matrix = cosine_similarity(user_weight_vectors)\n",
    "\n",
    "        # ここでは簡単のため、完全な類似度グラフを使用 (S' に相当) [cite: 108]\n",
    "        # 論文の「take the top-N in the highest similarity list」 は、後のステップで実装可能 [cite: 108]\n",
    "        user_graph_adj = similarity_matrix \n",
    "        \n",
    "        return user_graph_adj, sorted_user_ids\n",
    "\n",
    "    def aggregate_item_embeddings(self, user_local_item_weights, user_graph_adj, sorted_user_ids):\n",
    "        \"\"\"\n",
    "        ユーザー関係グラフに基づいて、アイテム埋め込みをグローバルに集約します。\n",
    "        論文の式 (16) と (17) に基づいています。 [cite: 111, 114]\n",
    "        \n",
    "        Args:\n",
    "            user_local_item_weights (dict): {user_id: local_item_embedding.weight.data (Tensor)}\n",
    "            user_graph_adj (np.ndarray): ユーザーグラフの隣接行列\n",
    "            sorted_user_ids (list): user_graph_adj のノード順に対応するユーザーIDのリスト\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: 更新されたグローバルアイテム埋め込みの重み\n",
    "        \"\"\"\n",
    "        if not user_local_item_weights:\n",
    "            return self.global_item_embedding.weight.data\n",
    "\n",
    "        # グラフの順序に合わせて各ユーザーのアイテム埋め込みを行列Aとしてまとめる\n",
    "        # A は (num_users, num_items, item_embedding_dim)\n",
    "        # 論文の「A is the round item embedding matrix, the I-th row represents the item embedding obtained from user i」に相当 [cite: 111]\n",
    "        item_embedding_matrix_A = torch.stack([\n",
    "            user_local_item_weights[u_id] for u_id in sorted_user_ids\n",
    "        ]) # (num_users, num_items, item_embedding_dim)\n",
    "\n",
    "        # グラフの正規化 (S'')\n",
    "        row_sums_graph = np.sum(user_graph_adj, axis=1, keepdims=True)\n",
    "        row_sums_graph[row_sums_graph == 0] = 1 \n",
    "        normalized_user_graph_adj = user_graph_adj / row_sums_graph\n",
    "        \n",
    "        normalized_user_graph_adj_tensor = torch.tensor(normalized_user_graph_adj, dtype=torch.float32)\n",
    "\n",
    "        # グラフ畳み込み (R = S'' A) [cite: 111]\n",
    "        # R は (num_users, num_items, item_embedding_dim) となる\n",
    "        # MatMul: (num_users, num_users) x (num_users, num_items, item_embedding_dim)\n",
    "        # Einstein Summation Convention: 'ij, jkd -> ikd'\n",
    "        R_tensor = torch.einsum('ij, jkd -> ikd', normalized_user_graph_adj_tensor, item_embedding_matrix_A)\n",
    "\n",
    "        # グローバルアイテム埋め込みの更新 (θ_global = DR) [cite: 113, 114]\n",
    "        # ここではDを全ユーザーの単純平均と解釈 (Rの0次元目を平均)\n",
    "        new_global_item_embedding_weight = R_tensor.mean(dim=0) # (num_items, item_embedding_dim)\n",
    "\n",
    "        # サーバーのグローバルアイテム埋め込みを直接更新\n",
    "        self.global_item_embedding.weight.data.copy_(new_global_item_embedding_weight)\n",
    "        \n",
    "        return self.global_item_embedding.weight.data\n",
    "\n",
    "\n",
    "# データセットの準備とクライアントへの分割 (1クライアント1ユーザー)\n",
    "num_users = 100\n",
    "num_items = 50\n",
    "num_clients = num_users # 1クライアント1ユーザー\n",
    "\n",
    "user_texts = {i: f\"This user likes movies about {i % 5} and enjoys {i % 3}.\" for i in range(num_users)}\n",
    "\n",
    "interactions_list = []\n",
    "# ユーザーのインタラクション履歴はTransformer Blockがないため不要ですが、\n",
    "# ダミーデータの整合性のために残します。\n",
    "user_interaction_history = defaultdict(list) \n",
    "\n",
    "for u_id in range(num_users):\n",
    "    for i_id in range(num_items):\n",
    "        if np.random.rand() > 0.7:\n",
    "            interactions_list.append([u_id, i_id, 1])\n",
    "            user_interaction_history[u_id].append(i_id) \n",
    "        else:\n",
    "            interactions_list.append([u_id, i_id, 0])\n",
    "\n",
    "interactions = torch.tensor(interactions_list, dtype=torch.float32)\n",
    "\n",
    "client_user_map = {} # {client_id: user_id}\n",
    "client_datasets = {}\n",
    "for u_id in range(num_users):\n",
    "    client_id = u_id \n",
    "    client_user_map[client_id] = u_id \n",
    "    \n",
    "    client_interactions_indices = [i for i, (u, _, _) in enumerate(interactions_list) if u == u_id]\n",
    "    \n",
    "    if not client_interactions_indices:\n",
    "        print(f\"Warning: User {u_id} has no interactions. Client {client_id} will have an empty dataset.\")\n",
    "        # ダミーデータセットを作成してエラーを回避\n",
    "        client_subset = TensorDataset(\n",
    "            torch.empty(0, dtype=torch.long), \n",
    "            torch.empty(0, dtype=torch.long), \n",
    "            torch.empty(0, dtype=torch.float32)\n",
    "        )\n",
    "    else:\n",
    "        # Transformer Blockがないため、 historical_item_sequences は DataLoader に含めない\n",
    "        user_interaction_data_for_client = []\n",
    "        for idx in client_interactions_indices:\n",
    "            u_id_data, i_id_data, label_data = interactions_list[idx]\n",
    "            user_interaction_data_for_client.append((u_id_data, i_id_data, label_data))\n",
    "\n",
    "        users_tensor = torch.tensor([d[0] for d in user_interaction_data_for_client], dtype=torch.long)\n",
    "        items_tensor = torch.tensor([d[1] for d in user_interaction_data_for_client], dtype=torch.long)\n",
    "        labels_tensor = torch.tensor([d[2] for d in user_interaction_data_for_client], dtype=torch.float32)\n",
    "\n",
    "        client_subset = TensorDataset(users_tensor, items_tensor, labels_tensor)\n",
    "    \n",
    "    client_datasets[client_id] = DataLoader(client_subset, batch_size=min(32, max(1, len(client_subset))), shuffle=True)\n",
    "\n",
    "print(f\"Number of users: {num_users}\")\n",
    "print(f\"Number of items: {num_items}\")\n",
    "print(f\"Total interactions: {len(interactions)}\")\n",
    "print(f\"Number of clients (1 client per user): {num_clients}\")\n",
    "\n",
    "\n",
    "# モデルのハイパーパラメータ\n",
    "item_embedding_dim = 32\n",
    "joint_embedding_output_dim = 32 \n",
    "\n",
    "# サーバーのインスタンス化\n",
    "server = Server(num_users, num_items, item_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "# 各クライアントのモデルを辞書で保持\n",
    "client_models = {}\n",
    "client_optimizers = {}\n",
    "for client_id in range(num_clients):\n",
    "    client_models[client_id] = ClientModel(\n",
    "        num_items,\n",
    "        item_embedding_dim,\n",
    "        plm_model,\n",
    "        plm_embedding_dim,\n",
    "        joint_embedding_output_dim\n",
    "    )\n",
    "    # NOTE:\n",
    "    # クライアントごとに最適化するパラメータを設定\n",
    "    # ここでは、user_joint_embedding_linear, local_item_embedding, prediction_layer が対象\n",
    "    # 単純にoptim.Adam(params = client_models[client_id].parameters(), lr=0.001)とすると、\n",
    "    # PLMも学習可能パラメータとなってしまうので、\n",
    "    # PLMのパラメータを除外したパラメータのみを取得してから、設定する.\n",
    "    trainable_params = [\n",
    "        p for name, p in client_models[client_id].named_parameters()\n",
    "        if not name.startswith('plm_model.')\n",
    "    ]\n",
    "\n",
    "    client_optimizers[client_id] = optim.Adam(\n",
    "        params=trainable_params,\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "# 学習ループ (フェデレーテッド学習ラウンド)\n",
    "num_communication_rounds = 10\n",
    "local_epochs = 1\n",
    "\n",
    "for round_num in range(num_communication_rounds):\n",
    "    print(f\"\\n--- Communication Round {round_num + 1}/{num_communication_rounds} ---\")\n",
    "    \n",
    "    # サーバーからグローバルアイテム埋め込みをクライアントに配布 [cite: 63]\n",
    "    for client_id in range(num_clients):\n",
    "        client_models[client_id].local_item_embedding.weight.data.copy_(server.global_item_embedding.weight.data)\n",
    "\n",
    "    user_linear_weights_for_graph = {} \n",
    "    user_local_item_weights_to_server = {} \n",
    "    \n",
    "    # クライアントのローカル学習 [cite: 60]\n",
    "    for client_id in range(num_clients):\n",
    "        model = client_models[client_id]\n",
    "        optimizer = client_optimizers[client_id]\n",
    "        dataloader = client_datasets[client_id]\n",
    "        \n",
    "        model.train()\n",
    "        local_loss = 0\n",
    "        \n",
    "        current_user_id = client_user_map[client_id] \n",
    "        \n",
    "        if len(dataloader.dataset) == 0:\n",
    "            print(f\"  Client {client_id} (User {current_user_id}) has no interactions, skipping local training.\")\n",
    "            # 訓練されなかったクライアントのために、現在のモデルの重み（グローバル初期化時と同じ）をアップロード\n",
    "            user_linear_weights_for_graph[current_user_id] = model.user_joint_embedding_linear.weight.data.clone().flatten()\n",
    "            user_local_item_weights_to_server[current_user_id] = model.local_item_embedding.weight.data.clone()\n",
    "            continue\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            # Transformer Blockがないため、 historical_item_sequences は DataLoader から取得しない\n",
    "            for user_ids_batch, item_ids_batch, labels_batch in dataloader:\n",
    "                assert torch.all(user_ids_batch == current_user_id) \n",
    "                current_user_texts = [user_texts[uid.item()] for uid in user_ids_batch]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                # historical_item_sequences_batch を渡さない\n",
    "                predictions, user_joint_embedding_linear_weight, local_item_embedding_weight = model(\n",
    "                    user_ids_batch, item_ids_batch, current_user_texts\n",
    "                )\n",
    "                \n",
    "                # 損失計算 (L_1のみ) [cite: 90, 91]\n",
    "                loss = nn.BCEWithLogitsLoss()(predictions.squeeze(), labels_batch)\n",
    "                \n",
    "                # 正則化項の追加 (論文の式(11)と(12)) [cite: 92, 93, 95]\n",
    "                # ここではe_globalはサーバーのglobal_item_embedding.weight.data\n",
    "                # e_i^- はlocal_item_embedding_weightからネガティブサンプリングされたアイテム埋め込み\n",
    "                # 論文では「Mean((e_global - e_i^-)^2)」 [cite: 93]\n",
    "                # 正確な e_i^- のサンプリングはデータセットからのネガティブサンプリングロジックが必要だが、ここでは簡略化\n",
    "                lambda_reg = 0.01 # ハイパーパラメータ [cite: 96, 101]\n",
    "                \n",
    "                # global_item_embeddingとlocal_item_embeddingのL2距離を正則化項とする\n",
    "                # (ネガティブサンプリングは省略)\n",
    "                regularization_term = torch.mean(\n",
    "                    (local_item_embedding_weight - server.global_item_embedding.weight.data)**2\n",
    "                )\n",
    "                \n",
    "                loss = loss + lambda_reg * regularization_term\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                local_loss += loss.item()\n",
    "\n",
    "        # クライアントがサーバーにアップロードするパラメータを収集 [cite: 61]\n",
    "        user_linear_weights_for_graph[current_user_id] = user_joint_embedding_linear_weight.data.clone().flatten()\n",
    "        user_local_item_weights_to_server[current_user_id] = local_item_embedding_weight.data.clone()\n",
    "\n",
    "        print(f\"  Client {client_id} (User {current_user_id}) local loss: {local_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # サーバーでの処理\n",
    "    # 論文のステップ「Graph Aggregation: The server constructs user relation graphs from text embeddings and aggregates parameters through graph convolution.」 [cite: 62]\n",
    "    # ユーザー関係グラフの構築 [cite: 103]\n",
    "    user_graph_adj, sorted_user_ids_for_graph = server.build_user_relationship_graph(\n",
    "        user_linear_weights_for_graph\n",
    "    )\n",
    "    \n",
    "    # アイテム埋め込みの集約 [cite: 109, 110]\n",
    "    server.aggregate_item_embeddings(\n",
    "        user_local_item_weights_to_server, \n",
    "        user_graph_adj, \n",
    "        sorted_user_ids_for_graph\n",
    "    )\n",
    "\n",
    "    print(f\"Round {round_num + 1} completed. Global item embeddings updated.\")\n",
    "\n",
    "print(\"Federated training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-UD7q69fU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
