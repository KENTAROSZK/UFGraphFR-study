{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497358d2",
   "metadata": {},
   "source": [
    "002は途中まで動かせるが、エラーが起きるので、003で002と同ステップの内容を実施することとした"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89a391",
   "metadata": {},
   "source": [
    "## 1. 必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f31c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850205cc",
   "metadata": {},
   "source": [
    "## 2. データセットの準備とクライアントへの分割 (変更)\n",
    "フェデレーテッド学習をシミュレートするため、ユーザーを複数の「クライアント」に分割します。各クライアントは自身のユーザーIDとインタラクションデータを持つことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7def1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 has users: [0]\n",
      "Client 1 has users: [1]\n",
      "Client 2 has users: [2]\n",
      "Client 3 has users: [3]\n",
      "Client 4 has users: [4]\n",
      "Client 5 has users: [5]\n",
      "Client 6 has users: [6]\n",
      "Client 7 has users: [7]\n",
      "Client 8 has users: [8]\n",
      "Client 9 has users: [9]\n",
      "Client 10 has users: [10]\n",
      "Client 11 has users: [11]\n",
      "Client 12 has users: [12]\n",
      "Client 13 has users: [13]\n",
      "Client 14 has users: [14]\n",
      "Client 15 has users: [15]\n",
      "Client 16 has users: [16]\n",
      "Client 17 has users: [17]\n",
      "Client 18 has users: [18]\n",
      "Client 19 has users: [19]\n",
      "Client 20 has users: [20]\n",
      "Client 21 has users: [21]\n",
      "Client 22 has users: [22]\n",
      "Client 23 has users: [23]\n",
      "Client 24 has users: [24]\n",
      "Client 25 has users: [25]\n",
      "Client 26 has users: [26]\n",
      "Client 27 has users: [27]\n",
      "Client 28 has users: [28]\n",
      "Client 29 has users: [29]\n",
      "Client 30 has users: [30]\n",
      "Client 31 has users: [31]\n",
      "Client 32 has users: [32]\n",
      "Client 33 has users: [33]\n",
      "Client 34 has users: [34]\n",
      "Client 35 has users: [35]\n",
      "Client 36 has users: [36]\n",
      "Client 37 has users: [37]\n",
      "Client 38 has users: [38]\n",
      "Client 39 has users: [39]\n",
      "Client 40 has users: [40]\n",
      "Client 41 has users: [41]\n",
      "Client 42 has users: [42]\n",
      "Client 43 has users: [43]\n",
      "Client 44 has users: [44]\n",
      "Client 45 has users: [45]\n",
      "Client 46 has users: [46]\n",
      "Client 47 has users: [47]\n",
      "Client 48 has users: [48]\n",
      "Client 49 has users: [49]\n",
      "Client 50 has users: [50]\n",
      "Client 51 has users: [51]\n",
      "Client 52 has users: [52]\n",
      "Client 53 has users: [53]\n",
      "Client 54 has users: [54]\n",
      "Client 55 has users: [55]\n",
      "Client 56 has users: [56]\n",
      "Client 57 has users: [57]\n",
      "Client 58 has users: [58]\n",
      "Client 59 has users: [59]\n",
      "Client 60 has users: [60]\n",
      "Client 61 has users: [61]\n",
      "Client 62 has users: [62]\n",
      "Client 63 has users: [63]\n",
      "Client 64 has users: [64]\n",
      "Client 65 has users: [65]\n",
      "Client 66 has users: [66]\n",
      "Client 67 has users: [67]\n",
      "Client 68 has users: [68]\n",
      "Client 69 has users: [69]\n",
      "Client 70 has users: [70]\n",
      "Client 71 has users: [71]\n",
      "Client 72 has users: [72]\n",
      "Client 73 has users: [73]\n",
      "Client 74 has users: [74]\n",
      "Client 75 has users: [75]\n",
      "Client 76 has users: [76]\n",
      "Client 77 has users: [77]\n",
      "Client 78 has users: [78]\n",
      "Client 79 has users: [79]\n",
      "Client 80 has users: [80]\n",
      "Client 81 has users: [81]\n",
      "Client 82 has users: [82]\n",
      "Client 83 has users: [83]\n",
      "Client 84 has users: [84]\n",
      "Client 85 has users: [85]\n",
      "Client 86 has users: [86]\n",
      "Client 87 has users: [87]\n",
      "Client 88 has users: [88]\n",
      "Client 89 has users: [89]\n",
      "Client 90 has users: [90]\n",
      "Client 91 has users: [91]\n",
      "Client 92 has users: [92]\n",
      "Client 93 has users: [93]\n",
      "Client 94 has users: [94]\n",
      "Client 95 has users: [95]\n",
      "Client 96 has users: [96]\n",
      "Client 97 has users: [97]\n",
      "Client 98 has users: [98]\n",
      "Client 99 has users: [99]\n",
      "Client 0 dataset size: 2\n",
      "3\n",
      "torch.Size([32]) torch.Size([32]) torch.Size([32])\n",
      "3\n",
      "torch.Size([18]) torch.Size([18]) torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "num_users = 100\n",
    "num_items = 50\n",
    "num_clients = num_users # NOTE: 普通、1クライアントが複数のユーザを持つことがあるので、ユーザとクライアントを別で定義する.\n",
    "\n",
    "\n",
    "# ユーザーのテキスト特徴 (例: 趣味、自己紹介など)\n",
    "user_texts = {i: f\"This user likes movies about {i % 5} and enjoys {i % 3}.\" for i in range(num_users)}\n",
    "\n",
    "# ユーザーアイテムインタラクション (implicit feedback)\n",
    "interactions_list = []\n",
    "for u_id in range(num_users):\n",
    "    for i_id in range(num_items):\n",
    "        if np.random.rand() > 0.7:  # 約30%の確率でインタラクションあり\n",
    "            interactions_list.append([u_id, i_id, 1])\n",
    "        else:\n",
    "            interactions_list.append([u_id, i_id, 0])\n",
    "\n",
    "interactions = torch.tensor(interactions_list, dtype=torch.float32)\n",
    "\n",
    "# 各クライアントにユーザを割り当てる\n",
    "client_user_map = defaultdict(list)\n",
    "for u_id in range(num_users):\n",
    "    client_id = u_id % num_clients\n",
    "    client_user_map[client_id].append(u_id)\n",
    "\n",
    "# for key, val in client_user_map.items():\n",
    "#     print(f\"Client {key} has users: {val}\")\n",
    "\n",
    "client_datasets = {}\n",
    "for client_id, uids in client_user_map.items():\n",
    "    # 各クライアントのインタラクションデータを抽出\n",
    "    client_interactions_indices = [i for i, (u,_,_) in enumerate(interactions_list) if u in uids]\n",
    "    client_subset = Subset(\n",
    "        TensorDataset(\n",
    "            interactions[:,0].long(),\n",
    "            interactions[:,1].long(),\n",
    "            interactions[:,2].float()\n",
    "        ),\n",
    "        client_interactions_indices\n",
    "    )\n",
    "    client_datasets[client_id] = DataLoader(client_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "# for client_id, dataset in client_datasets.items():\n",
    "#     print(f\"Client {client_id} dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd15d9",
   "metadata": {},
   "source": [
    "## 3. 軽量 LLM 埋め込みモデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc6f06d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face の軽量 LLM 埋め込みモデルのロード\n",
    "plm_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "plm_tokenizer = AutoTokenizer.from_pretrained(plm_model_name)\n",
    "plm_model = AutoModel.from_pretrained(plm_model_name)\n",
    "\n",
    "# PLMは学習済みモデルのため、勾配計算を無効化\n",
    "for param in plm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "plm_embedding_dim = plm_model.config.hidden_size\n",
    "print(f\"PLM embedding dimension: {plm_embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d24697",
   "metadata": {},
   "source": [
    "## 4. モデルの定義 (変更あり: グローバルアイテム埋め込みの追加)\n",
    "各クライアントが持つモデルに加えて、サーバーが管理する「グローバルアイテム埋め込み」を導入します。これは、論文における \n",
    "\n",
    "theta_item に相当します 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e80802f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クライアント側のモデルを定義して、その後サーバ側を定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "962134a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クライアントのモデル\n",
    "class ClientModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items,\n",
    "        item_embedding_dim,\n",
    "        plm_model,\n",
    "        plm_embedding_dim,\n",
    "        joint_embedding_output_dim,\n",
    "    ):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.plm_model = plm_model # NOTE: PLMは全クライアントで同じものを利用する.重みは固定である.\n",
    "\n",
    "        # joint embedding layer\n",
    "        self.user_joint_embedding_linear = nn.Linear(plm_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "        # item embedding layer\n",
    "        self.local_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        # 予測層 (各クライアントのローカルパラメータ)\n",
    "        self.prediction_layer = nn.Linear(joint_embedding_output_dim + item_embedding_dim, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, user_texts_batch):\n",
    "        encoded_input = plm_tokenizer(user_texts_batch, return_tensors='pt', padding=True, truncation=True)\n",
    "        plm_output = self.plm_model(**encoded_input).last_hidden_state[:, 0, :] # [CLS]トークンの埋め込みを使用\n",
    "\n",
    "        # Joint Embedding Layer の線形変換\n",
    "        user_embedding = self.user_joint_embedding_linear(plm_output) # (batch_size, joint_embedding_output_dim)\n",
    "\n",
    "        # ローカルのアイテム埋め込み\n",
    "        item_embedding = self.local_item_embedding(item_ids) # (batch_size, item_embedding_dim)\n",
    "\n",
    "        # ユーザー埋め込みとアイテム埋め込みを結合\n",
    "        combined_features = torch.cat((user_embedding, item_embedding), dim=1)\n",
    "\n",
    "        # 予測\n",
    "        prediction = torch.sigmoid(self.prediction_layer(combined_features))\n",
    "        return prediction, self.user_joint_embedding_linear.weight, item_embedding # 線形層の重みとアイテム埋め込みを返す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# サーバのモデル\n",
    "class Server:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users,\n",
    "        num_items,\n",
    "        item_embedding_dim,\n",
    "        joint_embedding_output_dim,\n",
    "    ):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        self.joint_embedding_output_dim = joint_embedding_output_dim\n",
    "        self.global_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        # # グローバルアイテム埋め込みのパラメータを学習対象とする\n",
    "        # self.optimizer = optim.Adam(self.global_item_embedding.parameters(), lr=0.001)\n",
    "\n",
    "    def build_user_relationship_graph(\n",
    "        self,\n",
    "        client_user_linear_weights,\n",
    "        user_ids_in_client,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ユーザーのジョイント埋め込み層の重み行列からユーザー関係グラフを構築します。\n",
    "        論文の式 (15) に基づいています [cite: 105, 106]。\n",
    "        \"\"\"\n",
    "        all_user_weights = {}\n",
    "\n",
    "        for client_id, weight_matrix in client_user_linear_weights.items():\n",
    "            for i, user_id in enumerate(user_ids_in_client[client_id]):\n",
    "                # 重み行列をベクトル化\n",
    "                all_user_weights[user_id] = weight_matrix[i].flatten().detach().cpu().numpy()\n",
    "\n",
    "        # 全ユーザーの重みベクトルを収集\n",
    "        sorted_user_ids = sorted(all_user_weights.keys())\n",
    "        if not sorted_user_ids: # ユーザーがいない場合\n",
    "            return np.zeros((self.num_users, self.num_users))\n",
    "\n",
    "        user_weight_vectors = np.array([all_user_weights[uid] for uid in sorted_user_ids])\n",
    "\n",
    "        # コサイン類似度で類似度行列を計算\n",
    "        similarity_matrix = cosine_similarity(user_weight_vectors)\n",
    "\n",
    "        # 各ユーザーの上位N個の類似ユーザーを選択してグラフを構築 (ここでは簡単のため、全てのユーザー間の類似度を使用)\n",
    "        # 論文のStep2では「top-N in the highest similarity list」とあるが [cite: 108]、\n",
    "        # ここでは完全な類似度グラフ (隣接行列) を使用。\n",
    "        # 厳密には、ここで閾値を設けるか、上位K個のみを選択して疎なグラフを構築すべき。\n",
    "        # S' に相当 [cite: 108]\n",
    "        user_graph_adj = similarity_matrix\n",
    "\n",
    "        return user_graph_adj, sorted_user_ids\n",
    "\n",
    "    def aggregate_item_embeddings(\n",
    "        self,\n",
    "        client_item_embeddings,\n",
    "        user_graph_adj,\n",
    "        sorted_user_ids,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ユーザー関係グラフに基づいて、アイテム埋め込みをグローバルに集約します。\n",
    "        論文の式 (16) と (17)  に基づいています。\n",
    "\n",
    "        Args:\n",
    "            client_local_item_weights (dict):\n",
    "            user_graph_adj (np.ndarray): ユーザーグラフの隣接行列\n",
    "            sorted_user_ids (list): user_graph_adj のノード順に対応するクライアントIDのリスト\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 更新されたグローバルアイテム埋め込みの重み\n",
    "        \"\"\"\n",
    "        # 各ユーザの現在のアイテム埋め込みを収集する（ユーザID順に並べ替える）\n",
    "        current_item_embeddings_map = {}\n",
    "        for client_id, item_embs in client_item_embeddings.items():\n",
    "            # クライアントが処理したユーザIDと対応するアイテム埋め込み\n",
    "            for u_id, item_emb in item_embs.items():\n",
    "                # 各ユーザーが複数のアイテムとインタラクションする可能性があるため、\n",
    "                # ここでは簡略化のため、各ユーザーのアイテム埋め込みの平均を使用する\n",
    "                # 論文では「the I-th row represents the item embedding obtained from user i」\n",
    "                # とあり、ユーザーiが学習したアイテム埋め込み全体を指す。\n",
    "                # ここでは、そのユーザーが学習したアイテム埋め込みの平均を代表値とする。\n",
    "                current_item_embeddings_map[u_id] = item_emb.mean(dim=0).detach().cpu().numpy()\n",
    "\n",
    "        # グラフの順序に合わせてアイテム埋め込みを行列にまとめる\n",
    "        item_embedding_matrix_A = np.array([current_item_embeddings_map[uid] for uid in sorted_user_ids])\n",
    "\n",
    "        # グラフ畳み込み (LightGCNの簡略版) [cite: 110, 111]\n",
    "        # 論文の式(16): R = S'' A  (S''は正規化された隣接行列)\n",
    "        # ここではS''を正規化された user_graph_adj とする\n",
    "        # 正規化: D^{-1/2} A D^{-1/2} (ただし、ここでは簡易的に行和で正規化)\n",
    "        # 厳密には LightGCN の伝播ルールに従うべきだが、ここでは単純化\n",
    "\n",
    "        # 簡単な正規化\n",
    "        row_sums = user_graph_adj.sum(axis=1, keepdims=True)\n",
    "        row_sums[row_sums == 0] = 1 # ゼロ除算を避ける\n",
    "        normalized_adj = user_graph_adj / row_sums\n",
    "\n",
    "        # グラフ畳み込み\n",
    "        # R が学習後の相関行列\n",
    "        R = np.dot(normalized_adj, item_embedding_matrix_A)\n",
    "\n",
    "        # グローバルアイテム埋め込みの更新 (論文の式(17)に基づく) [cite: 113, 114]\n",
    "        # θ_global = DR  (Dはaggregation時のdegree matrix [cite: 114])\n",
    "        # ここでは、Rの各行（ユーザーiによって学習されたアイテム埋め込み）の平均をとることで、\n",
    "        # グローバルなアイテム埋め込みを導出すると解釈する。\n",
    "        # これは FedAvg に近いシンプルな集約方法。\n",
    "        # 厳密なDは、各ユーザーの貢献度に応じた重み付け行列だが、\n",
    "        # まずは単純平均で実装する。\n",
    "        new_global_item_embedding_np = np.mean(R, axis=0)\n",
    "\n",
    "        # NumPy配列をPyTorchテンソルに変換し、グローバルアイテム埋め込みを更新\n",
    "        new_global_item_embedding_tensor = torch.tensor(new_global_item_embedding_np, dtype=torch.float32)\n",
    "\n",
    "        # サーバーのグローバルアイテム埋め込みを直接更新\n",
    "        self.global_item_embedding.weight.data.copy_(new_global_item_embedding_tensor)\n",
    "        return self.global_item_embedding.weight.data # 更新されたグローバルアイテム埋め込みの重みを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bfca50",
   "metadata": {},
   "source": [
    "## 5. 学習ループの変更 (フェデレーテッド学習のシミュレーション)\n",
    "この学習ループでは、以下のステップをシミュレートします。\n",
    "\n",
    "グローバル配布: サーバーがグローバルアイテム埋め込みを各クライアントに配布します。\n",
    "\n",
    "ローカル学習: 各クライアントは自身のデータを使ってモデルを学習し、ユーザーのジョイント埋め込み層の重みと、ローカルで更新されたアイテム埋め込み（のテンソル）をサーバーにアップロードします。\n",
    "\n",
    "グラフ集約: サーバーはアップロードされたユーザー埋め込み層の重みからユーザー関係グラフを構築し、それに基づいてグローバルアイテム埋め込みを集約・更新します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff104e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Communication Round 1/10 ---\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n"
     ]
    }
   ],
   "source": [
    "item_embedding_dim = 32\n",
    "joint_embedding_output_dim = 64\n",
    "\n",
    "# サーバーのインスタンス化\n",
    "server = Server(num_users, num_items, item_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "# 各クライアントのモデルを辞書で保持\n",
    "client_models = {}\n",
    "client_optimizers = {}\n",
    "for client_id in range(num_clients):\n",
    "    client_models[client_id] = ClientModel(\n",
    "        num_items,\n",
    "        item_embedding_dim,\n",
    "        plm_model,\n",
    "        plm_embedding_dim,\n",
    "        joint_embedding_output_dim\n",
    "    )\n",
    "    # NOTE:\n",
    "    # クライアントごとに最適化するパラメータを設定\n",
    "    # ここでは、user_joint_embedding_linear, local_item_embedding, prediction_layer が対象\n",
    "    # 単純にoptim.Adam(params = client_models[client_id].parameters(), lr=0.001)とすると、\n",
    "    # PLMも学習可能パラメータとなってしまうので、\n",
    "    # PLMのパラメータを除外したパラメータのみを取得してから、設定する.\n",
    "    trainable_params = [\n",
    "        p for name, p in client_models[client_id].named_parameters()\n",
    "        if not name.startswith('plm_model.')\n",
    "    ]\n",
    "\n",
    "    client_optimizers[client_id] = optim.Adam(\n",
    "        params=trainable_params,\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "\n",
    "# 学習ループ (フェデレーテッド学習ラウンド)\n",
    "num_communication_rounds = 10\n",
    "local_epochs = 1 # 各クライアントのローカル学習エポック数\n",
    "\n",
    "\n",
    "for round_num in range(num_communication_rounds):\n",
    "    print(f\"\\n--- Communication Round {round_num + 1}/{num_communication_rounds} ---\")\n",
    "\n",
    "    # サーバーからグローバルアイテム埋め込みをクライアントに配布\n",
    "    # (ClientModelのlocal_item_embeddingをサーバーのglobal_item_embeddingで初期化)\n",
    "    # 論文の「Global Distribution: Updated global project embeddings are broadcast \n",
    "    # to all clients for next-round initialization.」[cite: 63]\n",
    "    for client_id in range(num_clients):\n",
    "        client_models[client_id].local_item_embedding.weight.data.copy_(server.global_item_embedding.weight.data)\n",
    "\n",
    "    client_user_linear_weights_to_server = {} # {client_id: user_linear_weight_matrix_from_client}\n",
    "    client_item_embeddings_to_server = defaultdict(dict) # {client_id: {user_id: item_embeddings_tensor_from_user}}\n",
    "\n",
    "    # クライアントのローカル学習\n",
    "    for client_id in range(num_clients):\n",
    "        model = client_models[client_id]\n",
    "        optimizer = client_optimizers[client_id]\n",
    "        dataloader = client_datasets[client_id]\n",
    "\n",
    "        model.train()\n",
    "        local_loss = 0.0\n",
    "\n",
    "        # 各ユーザがどのクライアントに属しているかを把握\n",
    "        users_in_current_client = client_user_map[client_id]\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            for user_ids_batch, item_ids_batch, labels_batch in dataloader:\n",
    "\n",
    "                # バッチ内のユーザーIDに対応するテキスト特徴を取得\n",
    "                current_user_texts = [user_texts[uid.item()] for uid in user_ids_batch]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                predictions, user_linear_weight, item_embs_batch = model(\n",
    "                    user_ids_batch,\n",
    "                    item_ids_batch,\n",
    "                    current_user_texts\n",
    "                )\n",
    "\n",
    "                # 損失計算 (論文の式(12) L_all = L_1 + lambda * R) [cite: 95]\n",
    "                # ここでは簡略化のためL_1のみを使用。Rはまだ導入していない。\n",
    "                loss = nn.BCELoss()(predictions.squeeze(), labels_batch) # NOTE: ClientModel側の出力ですでにsigmoidを適用しているため、BCELossを使用\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                local_loss += loss.item()\n",
    "\n",
    "                # 各ユーザーの線形層の出力 (埋め込み) を収集\n",
    "                for i, u_id_tensor in enumerate(user_ids_batch):\n",
    "                    u_id = u_id_tensor.item()\n",
    "                    # 各ユーザーの線形層の重み (今回は線形層の出力) をクライアントがサーバーに報告する\n",
    "                    client_user_linear_weights_to_server[client_id].append(user_linear_weight[i].detach().cpu().numpy())\n",
    "\n",
    "                    # 各ユーザーが学習したアイテム埋め込みも収集 (ここではバッチ内の平均)\n",
    "                    # 論文の「item embedding obtained from user i」を模倣\n",
    "                    # ここでは、バッチ内の各ユーザーのアイテム埋め込みの平均として保存\n",
    "                    client_item_embeddings_to_server[client_id][u_id] = item_embs_batch[i].detach().cpu()\n",
    "        print(f\"  Client {client_id} local loss: {local_loss / len(dataloader):.4f}\")\n",
    "\n",
    "        # ユーザーIDとそれに紐づくテキスト埋め込みを統合する\n",
    "        all_user_embedding_outputs = {}\n",
    "        for client_id, user_embs_list in client_user_linear_weights_to_server.items():\n",
    "            # 各クライアントがアップロードする `user_joint_embedding_linear.weight` を格納する\n",
    "            client_linear_weights_for_graph = {\n",
    "                client_id: client_models[client_id].user_joint_embedding_linear.weight.data.clone().flatten()\n",
    "                for client_id in range(num_clients)\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a76b1",
   "metadata": {},
   "source": [
    "とりあえず"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embedding dimension: 384\n",
      "Number of users: 100\n",
      "Number of items: 50\n",
      "Number of interactions: 5000\n",
      "Number of clients: 10\n",
      "\n",
      "--- Communication Round 1/10 ---\n",
      "  Client 0 local loss: 0.6406\n",
      "  Client 1 local loss: 0.6355\n",
      "  Client 2 local loss: 0.6334\n",
      "  Client 3 local loss: 0.6324\n",
      "  Client 4 local loss: 0.6702\n",
      "  Client 5 local loss: 0.6325\n",
      "  Client 6 local loss: 0.6666\n",
      "  Client 7 local loss: 0.6481\n",
      "  Client 8 local loss: 0.6350\n",
      "  Client 9 local loss: 0.6254\n",
      "Round 1 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 2/10 ---\n",
      "  Client 0 local loss: 0.6058\n",
      "  Client 1 local loss: 0.5967\n",
      "  Client 2 local loss: 0.6278\n",
      "  Client 3 local loss: 0.6148\n",
      "  Client 4 local loss: 0.6546\n",
      "  Client 5 local loss: 0.6054\n",
      "  Client 6 local loss: 0.6500\n",
      "  Client 7 local loss: 0.6358\n",
      "  Client 8 local loss: 0.6074\n",
      "  Client 9 local loss: 0.6136\n",
      "Round 2 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 3/10 ---\n",
      "  Client 0 local loss: 0.6023\n",
      "  Client 1 local loss: 0.5866\n",
      "  Client 2 local loss: 0.6215\n",
      "  Client 3 local loss: 0.6145\n",
      "  Client 4 local loss: 0.6637\n",
      "  Client 5 local loss: 0.6051\n",
      "  Client 6 local loss: 0.6413\n",
      "  Client 7 local loss: 0.6315\n",
      "  Client 8 local loss: 0.5944\n",
      "  Client 9 local loss: 0.6080\n",
      "Round 3 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 4/10 ---\n",
      "  Client 0 local loss: 0.6050\n",
      "  Client 1 local loss: 0.5834\n",
      "  Client 2 local loss: 0.6160\n",
      "  Client 3 local loss: 0.6112\n",
      "  Client 4 local loss: 0.6529\n",
      "  Client 5 local loss: 0.6021\n",
      "  Client 6 local loss: 0.6488\n",
      "  Client 7 local loss: 0.6261\n",
      "  Client 8 local loss: 0.5872\n",
      "  Client 9 local loss: 0.6136\n",
      "Round 4 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 5/10 ---\n",
      "  Client 0 local loss: 0.5963\n",
      "  Client 1 local loss: 0.5819\n",
      "  Client 2 local loss: 0.6127\n",
      "  Client 3 local loss: 0.6073\n",
      "  Client 4 local loss: 0.6563\n",
      "  Client 5 local loss: 0.6031\n",
      "  Client 6 local loss: 0.6418\n",
      "  Client 7 local loss: 0.6141\n",
      "  Client 8 local loss: 0.5942\n",
      "  Client 9 local loss: 0.6097\n",
      "Round 5 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 6/10 ---\n",
      "  Client 0 local loss: 0.5978\n",
      "  Client 1 local loss: 0.5761\n",
      "  Client 2 local loss: 0.6228\n",
      "  Client 3 local loss: 0.6083\n",
      "  Client 4 local loss: 0.6488\n",
      "  Client 5 local loss: 0.5950\n",
      "  Client 6 local loss: 0.6346\n",
      "  Client 7 local loss: 0.6124\n",
      "  Client 8 local loss: 0.5931\n",
      "  Client 9 local loss: 0.6099\n",
      "Round 6 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 7/10 ---\n",
      "  Client 0 local loss: 0.5931\n",
      "  Client 1 local loss: 0.5763\n",
      "  Client 2 local loss: 0.6111\n",
      "  Client 3 local loss: 0.6026\n",
      "  Client 4 local loss: 0.6476\n",
      "  Client 5 local loss: 0.5930\n",
      "  Client 6 local loss: 0.6272\n",
      "  Client 7 local loss: 0.6119\n",
      "  Client 8 local loss: 0.5861\n",
      "  Client 9 local loss: 0.6093\n",
      "Round 7 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 8/10 ---\n",
      "  Client 0 local loss: 0.5960\n",
      "  Client 1 local loss: 0.5805\n",
      "  Client 2 local loss: 0.6141\n",
      "  Client 3 local loss: 0.6046\n",
      "  Client 4 local loss: 0.6489\n",
      "  Client 5 local loss: 0.5902\n",
      "  Client 6 local loss: 0.6281\n",
      "  Client 7 local loss: 0.6019\n",
      "  Client 8 local loss: 0.5864\n",
      "  Client 9 local loss: 0.6044\n",
      "Round 8 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 9/10 ---\n",
      "  Client 0 local loss: 0.5880\n",
      "  Client 1 local loss: 0.5696\n",
      "  Client 2 local loss: 0.6067\n",
      "  Client 3 local loss: 0.6026\n",
      "  Client 4 local loss: 0.6498\n",
      "  Client 5 local loss: 0.5862\n",
      "  Client 6 local loss: 0.6205\n",
      "  Client 7 local loss: 0.5981\n",
      "  Client 8 local loss: 0.5787\n",
      "  Client 9 local loss: 0.6025\n",
      "Round 9 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 10/10 ---\n",
      "  Client 0 local loss: 0.5912\n",
      "  Client 1 local loss: 0.5748\n",
      "  Client 2 local loss: 0.6058\n",
      "  Client 3 local loss: 0.5949\n",
      "  Client 4 local loss: 0.6432\n",
      "  Client 5 local loss: 0.5874\n",
      "  Client 6 local loss: 0.6169\n",
      "  Client 7 local loss: 0.6067\n",
      "  Client 8 local loss: 0.5804\n",
      "  Client 9 local loss: 0.5989\n",
      "Round 10 completed. Global item embeddings updated.\n",
      "Federated training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 軽量 LLM 埋め込みモデルのロード (変更なし)\n",
    "plm_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "plm_tokenizer = AutoTokenizer.from_pretrained(plm_model_name)\n",
    "plm_model = AutoModel.from_pretrained(plm_model_name)\n",
    "\n",
    "# PLMは学習済みモデルのため、勾配計算を無効化\n",
    "for param in plm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "plm_embedding_dim = plm_model.config.hidden_size\n",
    "print(f\"PLM embedding dimension: {plm_embedding_dim}\")\n",
    "\n",
    "\n",
    "class ClientModel(nn.Module):\n",
    "    def __init__(self, num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.plm_model = plm_model\n",
    "        \n",
    "        # Joint Embedding Layer の線形変換部分 (ユーザーのローカルパラメータ)\n",
    "        self.user_joint_embedding_linear = nn.Linear(plm_embedding_dim, joint_embedding_output_dim)\n",
    "        \n",
    "        # アイテム埋め込み (各クライアントのローカルパラメータとして初期化される)\n",
    "        self.local_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        # 予測層 (各クライアントのローカルパラメータ)\n",
    "        self.prediction_layer = nn.Linear(joint_embedding_output_dim + item_embedding_dim, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, user_texts_batch):\n",
    "        # ユーザーのテキスト特徴をPLMで埋め込み\n",
    "        encoded_input = plm_tokenizer(user_texts_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        plm_output = self.plm_model(**encoded_input).last_hidden_state[:, 0, :]\n",
    "\n",
    "        # Joint Embedding Layer の線形変換\n",
    "        user_embedding = self.user_joint_embedding_linear(plm_output)\n",
    "\n",
    "        # ローカルのアイテム埋め込み\n",
    "        item_embedding = self.local_item_embedding(item_ids)\n",
    "\n",
    "        # ユーザー埋め込みとアイテム埋め込みを結合\n",
    "        combined_features = torch.cat((user_embedding, item_embedding), dim=1)\n",
    "\n",
    "        # 予測\n",
    "        prediction = torch.sigmoid(self.prediction_layer(combined_features))\n",
    "        return prediction, self.user_joint_embedding_linear.weight, item_embedding # 線形層の重みとアイテム埋め込みを返す\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, num_users, num_items, item_embedding_dim, joint_embedding_output_dim):\n",
    "        # グローバルアイテム埋め込みは、全アイテムの埋め込み行列として管理\n",
    "        self.global_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        self.joint_embedding_output_dim = joint_embedding_output_dim\n",
    "    \n",
    "    def build_user_relationship_graph(self, client_linear_weights_map):\n",
    "        \"\"\"\n",
    "        各クライアントのuser_joint_embedding_linear.weightからユーザー関係グラフを構築します。\n",
    "        論文の式 (15)  に基づいています。\n",
    "        \n",
    "        Args:\n",
    "            client_linear_weights_map (dict): {client_id: user_joint_embedding_linear.weight.data (flattened)}\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: ユーザーグラフの隣接行列 (NumPy配列)\n",
    "            list: グラフのノード順に対応するクライアントIDのリスト\n",
    "        \"\"\"\n",
    "        # クライアントIDをユーザーIDとしてグラフを構築\n",
    "        sorted_client_ids = sorted(client_linear_weights_map.keys())\n",
    "        if not sorted_client_ids:\n",
    "            return np.zeros((0, 0)), []\n",
    "\n",
    "        # クライアントの線形層の重みベクトルを収集\n",
    "        client_weight_vectors = np.array([\n",
    "            client_linear_weights_map[c_id].cpu().numpy() for c_id in sorted_client_ids\n",
    "        ])\n",
    "\n",
    "        # コサイン類似度で類似度行列を計算 (S_ij) \n",
    "        similarity_matrix = cosine_similarity(client_weight_vectors)\n",
    "\n",
    "        # ここでは簡単のため、完全な類似度グラフを使用 (S' に相当) \n",
    "        # 論文の「top-N in the highest similarity list」 は、後のステップで実装可能\n",
    "        user_graph_adj = similarity_matrix \n",
    "        \n",
    "        return user_graph_adj, sorted_client_ids\n",
    "\n",
    "    def aggregate_item_embeddings(self, client_local_item_weights, user_graph_adj, sorted_client_ids):\n",
    "        \"\"\"\n",
    "        ユーザー関係グラフに基づいて、アイテム埋め込みをグローバルに集約します。\n",
    "        論文の式 (16) と (17)  に基づいています。\n",
    "        \n",
    "        Args:\n",
    "            client_local_item_weights (dict): {client_id: local_item_embedding.weight.data (Tensor)}\n",
    "            user_graph_adj (np.ndarray): ユーザーグラフの隣接行列\n",
    "            sorted_client_ids (list): user_graph_adj のノード順に対応するクライアントIDのリスト\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: 更新されたグローバルアイテム埋め込みの重み\n",
    "        \"\"\"\n",
    "        if not client_local_item_weights:\n",
    "            return self.global_item_embedding.weight.data\n",
    "\n",
    "        # グラフの順序に合わせてクライアントのアイテム埋め込みを行列Aとしてまとめる\n",
    "        # A は (num_clients, num_items, item_embedding_dim)\n",
    "        # 論文の「A is the round item embedding matrix, the I-th row represents the item embedding obtained from user i」\n",
    "        # ここでは、「user i」を「client i」と解釈し、各クライアントの全アイテムの埋め込み行列をAの要素とする\n",
    "        client_item_embedding_matrix_A = torch.stack([\n",
    "            client_local_item_weights[c_id] for c_id in sorted_client_ids\n",
    "        ]) # (num_clients, num_items, item_embedding_dim)\n",
    "\n",
    "        # グラフの正規化 (S'') \n",
    "        # 簡単な行和正規化を使用 (LightGCNの対称正規化とは異なるが、開始点として)\n",
    "        row_sums_graph = np.sum(user_graph_adj, axis=1, keepdims=True)\n",
    "        row_sums_graph[row_sums_graph == 0] = 1 # ゼロ除算回避\n",
    "        normalized_user_graph_adj = user_graph_adj / row_sums_graph\n",
    "        \n",
    "        # NumPyをPyTorchテンソルに変換\n",
    "        normalized_user_graph_adj_tensor = torch.tensor(normalized_user_graph_adj, dtype=torch.float32)\n",
    "\n",
    "        # グラフ畳み込み (R = S'' A) \n",
    "        # R は (num_clients, num_items, item_embedding_dim) となる\n",
    "        # MatMul: (num_clients, num_clients) x (num_clients, num_items, item_embedding_dim)\n",
    "        # 結果として、各クライアント（行）が、類似するクライアントのアイテム埋め込みを加重平均したものを得る\n",
    "        # R_tensor = torch.matmul(normalized_user_graph_adj_tensor, client_item_embedding_matrix_A)\n",
    "        R_tensor = torch.einsum('ij, jkd -> ikd', normalized_user_graph_adj_tensor, client_item_embedding_matrix_A)\n",
    "\n",
    "        # グローバルアイテム埋め込みの更新 (θ_global = DR) \n",
    "        # 論文のDはAggregation時のdegree matrixだが、ここではRの平均を取ることで、\n",
    "        # 全体としての共通のアイテム埋め込みを導出すると解釈\n",
    "        new_global_item_embedding_weight = R_tensor.mean(dim=0) # (num_items, item_embedding_dim)\n",
    "\n",
    "        # サーバーのグローバルアイテム埋め込みを直接更新\n",
    "        self.global_item_embedding.weight.data.copy_(new_global_item_embedding_weight)\n",
    "        \n",
    "        # 関数自体は新しい埋め込みの値を返すのではなく、内部状態を更新する\n",
    "        return self.global_item_embedding.weight.data # 更新されたグローバルアイテム埋め込みの重みを返す\n",
    "\n",
    "\n",
    "# データセットの準備とクライアントへの分割 (変更なし)\n",
    "num_users = 100\n",
    "num_items = 50\n",
    "num_clients = 10\n",
    "\n",
    "user_texts = {i: f\"This user likes movies about {i % 5} and enjoys {i % 3}.\" for i in range(num_users)}\n",
    "\n",
    "interactions_list = []\n",
    "for u_id in range(num_users):\n",
    "    for i_id in range(num_items):\n",
    "        if np.random.rand() > 0.7:\n",
    "            interactions_list.append([u_id, i_id, 1])\n",
    "        else:\n",
    "            interactions_list.append([u_id, i_id, 0])\n",
    "\n",
    "interactions = torch.tensor(interactions_list, dtype=torch.float32)\n",
    "\n",
    "client_user_map = defaultdict(list)\n",
    "for u_id in range(num_users):\n",
    "    client_id = u_id % num_clients\n",
    "    client_user_map[client_id].append(u_id)\n",
    "\n",
    "client_datasets = {}\n",
    "for client_id, uids in client_user_map.items():\n",
    "    client_interactions_indices = [i for i, (u, _, _) in enumerate(interactions_list) if u in uids]\n",
    "    client_subset = Subset(TensorDataset(interactions[:, 0].long(), interactions[:, 1].long(), interactions[:, 2]), client_interactions_indices)\n",
    "    client_datasets[client_id] = DataLoader(client_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Number of users: {num_users}\")\n",
    "print(f\"Number of items: {num_items}\")\n",
    "print(f\"Number of interactions: {len(interactions)}\")\n",
    "print(f\"Number of clients: {num_clients}\")\n",
    "\n",
    "\n",
    "# モデルのハイパーパラメータ\n",
    "item_embedding_dim = 32\n",
    "joint_embedding_output_dim = 32 \n",
    "\n",
    "# サーバーのインスタンス化\n",
    "server = Server(num_users, num_items, item_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "# 各クライアントのモデルを辞書で保持\n",
    "client_models = {}\n",
    "client_optimizers = {}\n",
    "for client_id in range(num_clients):\n",
    "    client_models[client_id] = ClientModel(num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim)\n",
    "    client_optimizers[client_id] = optim.Adam(client_models[client_id].parameters(), lr=0.001)\n",
    "\n",
    "# 学習ループ (フェデレーテッド学習ラウンド)\n",
    "num_communication_rounds = 10\n",
    "local_epochs = 1 \n",
    "\n",
    "for round_num in range(num_communication_rounds):\n",
    "    print(f\"\\n--- Communication Round {round_num + 1}/{num_communication_rounds} ---\")\n",
    "    \n",
    "    # サーバーからグローバルアイテム埋め込みをクライアントに配布\n",
    "    for client_id in range(num_clients):\n",
    "        client_models[client_id].local_item_embedding.weight.data.copy_(server.global_item_embedding.weight.data)\n",
    "\n",
    "    client_linear_weights_for_graph = {} # {client_id: user_joint_embedding_linear.weight.data (flattened)}\n",
    "    client_local_item_weights_to_server = {} # {client_id: local_item_embedding.weight.data (Tensor)}\n",
    "    \n",
    "    # クライアントのローカル学習\n",
    "    for client_id in range(num_clients):\n",
    "        model = client_models[client_id]\n",
    "        optimizer = client_optimizers[client_id]\n",
    "        dataloader = client_datasets[client_id]\n",
    "        \n",
    "        model.train()\n",
    "        local_loss = 0\n",
    "        \n",
    "        for epoch in range(local_epochs):\n",
    "            for user_ids_batch, item_ids_batch, labels_batch in dataloader:\n",
    "                current_user_texts = [user_texts[uid.item()] for uid in user_ids_batch]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions, user_linear_weight_matrix, item_embs_batch = model(user_ids_batch, item_ids_batch, current_user_texts)\n",
    "                \n",
    "                # 損失計算 (L_1のみ)\n",
    "                loss = nn.BCELoss()(predictions.squeeze(), labels_batch)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                local_loss += loss.item()\n",
    "\n",
    "        # クライアントがサーバーにアップロードするパラメータを収集\n",
    "        # 各クライアントは自身の user_joint_embedding_linear.weight をベクトル化してアップロード \n",
    "        client_linear_weights_for_graph[client_id] = model.user_joint_embedding_linear.weight.data.clone().flatten()\n",
    "        \n",
    "        # 各クライアントは自身の local_item_embedding.weight もアップロード\n",
    "        client_local_item_weights_to_server[client_id] = model.local_item_embedding.weight.data.clone()\n",
    "\n",
    "        print(f\"  Client {client_id} local loss: {local_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # サーバーでの処理\n",
    "    # ユーザー関係グラフの構築 \n",
    "    user_graph_adj, sorted_client_ids_for_graph = server.build_user_relationship_graph(\n",
    "        client_linear_weights_for_graph\n",
    "    )\n",
    "    \n",
    "    # アイテム埋め込みの集約 \n",
    "    server.aggregate_item_embeddings(\n",
    "        client_local_item_weights_to_server, \n",
    "        user_graph_adj, \n",
    "        sorted_client_ids_for_graph\n",
    "    )\n",
    "\n",
    "    print(f\"Round {round_num + 1} completed. Global item embeddings updated.\")\n",
    "\n",
    "print(\"Federated training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2232d6",
   "metadata": {},
   "source": [
    "1クライアント1ユーザに修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6845044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kentaro.suzuki/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embedding dimension: 384\n",
      "Number of users: 100\n",
      "Number of items: 50\n",
      "Total interactions: 5000\n",
      "Number of clients (1 client per user): 100\n",
      "\n",
      "--- Communication Round 1/10 ---\n",
      "  Client 0 (User 0) local loss: 0.7276\n",
      "  Client 1 (User 1) local loss: 0.7022\n",
      "  Client 2 (User 2) local loss: 0.7561\n",
      "  Client 3 (User 3) local loss: 0.7084\n",
      "  Client 4 (User 4) local loss: 0.7386\n",
      "  Client 5 (User 5) local loss: 0.6692\n",
      "  Client 6 (User 6) local loss: 0.7510\n",
      "  Client 7 (User 7) local loss: 0.7375\n",
      "  Client 8 (User 8) local loss: 0.7595\n",
      "  Client 9 (User 9) local loss: 0.6605\n",
      "  Client 10 (User 10) local loss: 0.6423\n",
      "  Client 11 (User 11) local loss: 0.6982\n",
      "  Client 12 (User 12) local loss: 0.7081\n",
      "  Client 13 (User 13) local loss: 0.7375\n",
      "  Client 14 (User 14) local loss: 0.6891\n",
      "  Client 15 (User 15) local loss: 0.6695\n",
      "  Client 16 (User 16) local loss: 0.7670\n",
      "  Client 17 (User 17) local loss: 0.7243\n",
      "  Client 18 (User 18) local loss: 0.6946\n",
      "  Client 19 (User 19) local loss: 0.7323\n",
      "  Client 20 (User 20) local loss: 0.6963\n",
      "  Client 21 (User 21) local loss: 0.6941\n",
      "  Client 22 (User 22) local loss: 0.7423\n",
      "  Client 23 (User 23) local loss: 0.7185\n",
      "  Client 24 (User 24) local loss: 0.6877\n",
      "  Client 25 (User 25) local loss: 0.6997\n",
      "  Client 26 (User 26) local loss: 0.6523\n",
      "  Client 27 (User 27) local loss: 0.6416\n",
      "  Client 28 (User 28) local loss: 0.7107\n",
      "  Client 29 (User 29) local loss: 0.7045\n",
      "  Client 30 (User 30) local loss: 0.6766\n",
      "  Client 31 (User 31) local loss: 0.7113\n",
      "  Client 32 (User 32) local loss: 0.7128\n",
      "  Client 33 (User 33) local loss: 0.6621\n",
      "  Client 34 (User 34) local loss: 0.6925\n",
      "  Client 35 (User 35) local loss: 0.7176\n",
      "  Client 36 (User 36) local loss: 0.7380\n",
      "  Client 37 (User 37) local loss: 0.7305\n",
      "  Client 38 (User 38) local loss: 0.6827\n",
      "  Client 39 (User 39) local loss: 0.6487\n",
      "  Client 40 (User 40) local loss: 0.7217\n",
      "  Client 41 (User 41) local loss: 0.7129\n",
      "  Client 42 (User 42) local loss: 0.6809\n",
      "  Client 43 (User 43) local loss: 0.6893\n",
      "  Client 44 (User 44) local loss: 0.7371\n",
      "  Client 45 (User 45) local loss: 0.7239\n",
      "  Client 46 (User 46) local loss: 0.7117\n",
      "  Client 47 (User 47) local loss: 0.7398\n",
      "  Client 48 (User 48) local loss: 0.7082\n",
      "  Client 49 (User 49) local loss: 0.6827\n",
      "  Client 50 (User 50) local loss: 0.6793\n",
      "  Client 51 (User 51) local loss: 0.7675\n",
      "  Client 52 (User 52) local loss: 0.6990\n",
      "  Client 53 (User 53) local loss: 0.7544\n",
      "  Client 54 (User 54) local loss: 0.7182\n",
      "  Client 55 (User 55) local loss: 0.7235\n",
      "  Client 56 (User 56) local loss: 0.7380\n",
      "  Client 57 (User 57) local loss: 0.7027\n",
      "  Client 58 (User 58) local loss: 0.6504\n",
      "  Client 59 (User 59) local loss: 0.6437\n",
      "  Client 60 (User 60) local loss: 0.6817\n",
      "  Client 61 (User 61) local loss: 0.7236\n",
      "  Client 62 (User 62) local loss: 0.6536\n",
      "  Client 63 (User 63) local loss: 0.6886\n",
      "  Client 64 (User 64) local loss: 0.7020\n",
      "  Client 65 (User 65) local loss: 0.7341\n",
      "  Client 66 (User 66) local loss: 0.6736\n",
      "  Client 67 (User 67) local loss: 0.6347\n",
      "  Client 68 (User 68) local loss: 0.7229\n",
      "  Client 69 (User 69) local loss: 0.6920\n",
      "  Client 70 (User 70) local loss: 0.6974\n",
      "  Client 71 (User 71) local loss: 0.7235\n",
      "  Client 72 (User 72) local loss: 0.7234\n",
      "  Client 73 (User 73) local loss: 0.6533\n",
      "  Client 74 (User 74) local loss: 0.6962\n",
      "  Client 75 (User 75) local loss: 0.6722\n",
      "  Client 76 (User 76) local loss: 0.6276\n",
      "  Client 77 (User 77) local loss: 0.7060\n",
      "  Client 78 (User 78) local loss: 0.7065\n",
      "  Client 79 (User 79) local loss: 0.7956\n",
      "  Client 80 (User 80) local loss: 0.6866\n",
      "  Client 81 (User 81) local loss: 0.6745\n",
      "  Client 82 (User 82) local loss: 0.6636\n",
      "  Client 83 (User 83) local loss: 0.6557\n",
      "  Client 84 (User 84) local loss: 0.6904\n",
      "  Client 85 (User 85) local loss: 0.7201\n",
      "  Client 86 (User 86) local loss: 0.7177\n",
      "  Client 87 (User 87) local loss: 0.7219\n",
      "  Client 88 (User 88) local loss: 0.6944\n",
      "  Client 89 (User 89) local loss: 0.7057\n",
      "  Client 90 (User 90) local loss: 0.6828\n",
      "  Client 91 (User 91) local loss: 0.7116\n",
      "  Client 92 (User 92) local loss: 0.6614\n",
      "  Client 93 (User 93) local loss: 0.7229\n",
      "  Client 94 (User 94) local loss: 0.6788\n",
      "  Client 95 (User 95) local loss: 0.6887\n",
      "  Client 96 (User 96) local loss: 0.6928\n",
      "  Client 97 (User 97) local loss: 0.6891\n",
      "  Client 98 (User 98) local loss: 0.7758\n",
      "  Client 99 (User 99) local loss: 0.6809\n",
      "Round 1 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 2/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6761\n",
      "  Client 1 (User 1) local loss: 0.7149\n",
      "  Client 2 (User 2) local loss: 0.6918\n",
      "  Client 3 (User 3) local loss: 0.7182\n",
      "  Client 4 (User 4) local loss: 0.6961\n",
      "  Client 5 (User 5) local loss: 0.5798\n",
      "  Client 6 (User 6) local loss: 0.6823\n",
      "  Client 7 (User 7) local loss: 0.6715\n",
      "  Client 8 (User 8) local loss: 0.6556\n",
      "  Client 9 (User 9) local loss: 0.5802\n",
      "  Client 10 (User 10) local loss: 0.6444\n",
      "  Client 11 (User 11) local loss: 0.6520\n",
      "  Client 12 (User 12) local loss: 0.6205\n",
      "  Client 13 (User 13) local loss: 0.6915\n",
      "  Client 14 (User 14) local loss: 0.6458\n",
      "  Client 15 (User 15) local loss: 0.5430\n",
      "  Client 16 (User 16) local loss: 0.6909\n",
      "  Client 17 (User 17) local loss: 0.6077\n",
      "  Client 18 (User 18) local loss: 0.5976\n",
      "  Client 19 (User 19) local loss: 0.6497\n",
      "  Client 20 (User 20) local loss: 0.6736\n",
      "  Client 21 (User 21) local loss: 0.6465\n",
      "  Client 22 (User 22) local loss: 0.6593\n",
      "  Client 23 (User 23) local loss: 0.6870\n",
      "  Client 24 (User 24) local loss: 0.6366\n",
      "  Client 25 (User 25) local loss: 0.6456\n",
      "  Client 26 (User 26) local loss: 0.6310\n",
      "  Client 27 (User 27) local loss: 0.6153\n",
      "  Client 28 (User 28) local loss: 0.6937\n",
      "  Client 29 (User 29) local loss: 0.6907\n",
      "  Client 30 (User 30) local loss: 0.5928\n",
      "  Client 31 (User 31) local loss: 0.6355\n",
      "  Client 32 (User 32) local loss: 0.6379\n",
      "  Client 33 (User 33) local loss: 0.5928\n",
      "  Client 34 (User 34) local loss: 0.6157\n",
      "  Client 35 (User 35) local loss: 0.6402\n",
      "  Client 36 (User 36) local loss: 0.6803\n",
      "  Client 37 (User 37) local loss: 0.6628\n",
      "  Client 38 (User 38) local loss: 0.6345\n",
      "  Client 39 (User 39) local loss: 0.6229\n",
      "  Client 40 (User 40) local loss: 0.6930\n",
      "  Client 41 (User 41) local loss: 0.7016\n",
      "  Client 42 (User 42) local loss: 0.7046\n",
      "  Client 43 (User 43) local loss: 0.6586\n",
      "  Client 44 (User 44) local loss: 0.6960\n",
      "  Client 45 (User 45) local loss: 0.6872\n",
      "  Client 46 (User 46) local loss: 0.6702\n",
      "  Client 47 (User 47) local loss: 0.6572\n",
      "  Client 48 (User 48) local loss: 0.6848\n",
      "  Client 49 (User 49) local loss: 0.6645\n",
      "  Client 50 (User 50) local loss: 0.6595\n",
      "  Client 51 (User 51) local loss: 0.6805\n",
      "  Client 52 (User 52) local loss: 0.6288\n",
      "  Client 53 (User 53) local loss: 0.6519\n",
      "  Client 54 (User 54) local loss: 0.7206\n",
      "  Client 55 (User 55) local loss: 0.6394\n",
      "  Client 56 (User 56) local loss: 0.6848\n",
      "  Client 57 (User 57) local loss: 0.6949\n",
      "  Client 58 (User 58) local loss: 0.6227\n",
      "  Client 59 (User 59) local loss: 0.6384\n",
      "  Client 60 (User 60) local loss: 0.6341\n",
      "  Client 61 (User 61) local loss: 0.6423\n",
      "  Client 62 (User 62) local loss: 0.6842\n",
      "  Client 63 (User 63) local loss: 0.6633\n",
      "  Client 64 (User 64) local loss: 0.6459\n",
      "  Client 65 (User 65) local loss: 0.6916\n",
      "  Client 66 (User 66) local loss: 0.6175\n",
      "  Client 67 (User 67) local loss: 0.6005\n",
      "  Client 68 (User 68) local loss: 0.7196\n",
      "  Client 69 (User 69) local loss: 0.6340\n",
      "  Client 70 (User 70) local loss: 0.6862\n",
      "  Client 71 (User 71) local loss: 0.6730\n",
      "  Client 72 (User 72) local loss: 0.7015\n",
      "  Client 73 (User 73) local loss: 0.6231\n",
      "  Client 74 (User 74) local loss: 0.6097\n",
      "  Client 75 (User 75) local loss: 0.6498\n",
      "  Client 76 (User 76) local loss: 0.6113\n",
      "  Client 77 (User 77) local loss: 0.6906\n",
      "  Client 78 (User 78) local loss: 0.6820\n",
      "  Client 79 (User 79) local loss: 0.7596\n",
      "  Client 80 (User 80) local loss: 0.6330\n",
      "  Client 81 (User 81) local loss: 0.6227\n",
      "  Client 82 (User 82) local loss: 0.6358\n",
      "  Client 83 (User 83) local loss: 0.5771\n",
      "  Client 84 (User 84) local loss: 0.6290\n",
      "  Client 85 (User 85) local loss: 0.6951\n",
      "  Client 86 (User 86) local loss: 0.6471\n",
      "  Client 87 (User 87) local loss: 0.6900\n",
      "  Client 88 (User 88) local loss: 0.6531\n",
      "  Client 89 (User 89) local loss: 0.5830\n",
      "  Client 90 (User 90) local loss: 0.6015\n",
      "  Client 91 (User 91) local loss: 0.6482\n",
      "  Client 92 (User 92) local loss: 0.5938\n",
      "  Client 93 (User 93) local loss: 0.7043\n",
      "  Client 94 (User 94) local loss: 0.6294\n",
      "  Client 95 (User 95) local loss: 0.6677\n",
      "  Client 96 (User 96) local loss: 0.6570\n",
      "  Client 97 (User 97) local loss: 0.5963\n",
      "  Client 98 (User 98) local loss: 0.7026\n",
      "  Client 99 (User 99) local loss: 0.6415\n",
      "Round 2 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 3/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6891\n",
      "  Client 1 (User 1) local loss: 0.7130\n",
      "  Client 2 (User 2) local loss: 0.6893\n",
      "  Client 3 (User 3) local loss: 0.6783\n",
      "  Client 4 (User 4) local loss: 0.6612\n",
      "  Client 5 (User 5) local loss: 0.5718\n",
      "  Client 6 (User 6) local loss: 0.6268\n",
      "  Client 7 (User 7) local loss: 0.6005\n",
      "  Client 8 (User 8) local loss: 0.6023\n",
      "  Client 9 (User 9) local loss: 0.5669\n",
      "  Client 10 (User 10) local loss: 0.5919\n",
      "  Client 11 (User 11) local loss: 0.6754\n",
      "  Client 12 (User 12) local loss: 0.5678\n",
      "  Client 13 (User 13) local loss: 0.6700\n",
      "  Client 14 (User 14) local loss: 0.6012\n",
      "  Client 15 (User 15) local loss: 0.4417\n",
      "  Client 16 (User 16) local loss: 0.6791\n",
      "  Client 17 (User 17) local loss: 0.5726\n",
      "  Client 18 (User 18) local loss: 0.5538\n",
      "  Client 19 (User 19) local loss: 0.5841\n",
      "  Client 20 (User 20) local loss: 0.6846\n",
      "  Client 21 (User 21) local loss: 0.6560\n",
      "  Client 22 (User 22) local loss: 0.6115\n",
      "  Client 23 (User 23) local loss: 0.6811\n",
      "  Client 24 (User 24) local loss: 0.5681\n",
      "  Client 25 (User 25) local loss: 0.6058\n",
      "  Client 26 (User 26) local loss: 0.5966\n",
      "  Client 27 (User 27) local loss: 0.5773\n",
      "  Client 28 (User 28) local loss: 0.6543\n",
      "  Client 29 (User 29) local loss: 0.6861\n",
      "  Client 30 (User 30) local loss: 0.5434\n",
      "  Client 31 (User 31) local loss: 0.5943\n",
      "  Client 32 (User 32) local loss: 0.6283\n",
      "  Client 33 (User 33) local loss: 0.5273\n",
      "  Client 34 (User 34) local loss: 0.6270\n",
      "  Client 35 (User 35) local loss: 0.5819\n",
      "  Client 36 (User 36) local loss: 0.6566\n",
      "  Client 37 (User 37) local loss: 0.6973\n",
      "  Client 38 (User 38) local loss: 0.5704\n",
      "  Client 39 (User 39) local loss: 0.5925\n",
      "  Client 40 (User 40) local loss: 0.6346\n",
      "  Client 41 (User 41) local loss: 0.6427\n",
      "  Client 42 (User 42) local loss: 0.6537\n",
      "  Client 43 (User 43) local loss: 0.6480\n",
      "  Client 44 (User 44) local loss: 0.7012\n",
      "  Client 45 (User 45) local loss: 0.7140\n",
      "  Client 46 (User 46) local loss: 0.6214\n",
      "  Client 47 (User 47) local loss: 0.6284\n",
      "  Client 48 (User 48) local loss: 0.6624\n",
      "  Client 49 (User 49) local loss: 0.6309\n",
      "  Client 50 (User 50) local loss: 0.6734\n",
      "  Client 51 (User 51) local loss: 0.6703\n",
      "  Client 52 (User 52) local loss: 0.6258\n",
      "  Client 53 (User 53) local loss: 0.5746\n",
      "  Client 54 (User 54) local loss: 0.7208\n",
      "  Client 55 (User 55) local loss: 0.5646\n",
      "  Client 56 (User 56) local loss: 0.6693\n",
      "  Client 57 (User 57) local loss: 0.6903\n",
      "  Client 58 (User 58) local loss: 0.5704\n",
      "  Client 59 (User 59) local loss: 0.6296\n",
      "  Client 60 (User 60) local loss: 0.6114\n",
      "  Client 61 (User 61) local loss: 0.6093\n",
      "  Client 62 (User 62) local loss: 0.6732\n",
      "  Client 63 (User 63) local loss: 0.6554\n",
      "  Client 64 (User 64) local loss: 0.6394\n",
      "  Client 65 (User 65) local loss: 0.6336\n",
      "  Client 66 (User 66) local loss: 0.6215\n",
      "  Client 67 (User 67) local loss: 0.5371\n",
      "  Client 68 (User 68) local loss: 0.7022\n",
      "  Client 69 (User 69) local loss: 0.5905\n",
      "  Client 70 (User 70) local loss: 0.6757\n",
      "  Client 71 (User 71) local loss: 0.6420\n",
      "  Client 72 (User 72) local loss: 0.7017\n",
      "  Client 73 (User 73) local loss: 0.6007\n",
      "  Client 74 (User 74) local loss: 0.5963\n",
      "  Client 75 (User 75) local loss: 0.5817\n",
      "  Client 76 (User 76) local loss: 0.6081\n",
      "  Client 77 (User 77) local loss: 0.7029\n",
      "  Client 78 (User 78) local loss: 0.6535\n",
      "  Client 79 (User 79) local loss: 0.7323\n",
      "  Client 80 (User 80) local loss: 0.5795\n",
      "  Client 81 (User 81) local loss: 0.5541\n",
      "  Client 82 (User 82) local loss: 0.5919\n",
      "  Client 83 (User 83) local loss: 0.5472\n",
      "  Client 84 (User 84) local loss: 0.5980\n",
      "  Client 85 (User 85) local loss: 0.6892\n",
      "  Client 86 (User 86) local loss: 0.6247\n",
      "  Client 87 (User 87) local loss: 0.6694\n",
      "  Client 88 (User 88) local loss: 0.6765\n",
      "  Client 89 (User 89) local loss: 0.5265\n",
      "  Client 90 (User 90) local loss: 0.5490\n",
      "  Client 91 (User 91) local loss: 0.6452\n",
      "  Client 92 (User 92) local loss: 0.4886\n",
      "  Client 93 (User 93) local loss: 0.7017\n",
      "  Client 94 (User 94) local loss: 0.6684\n",
      "  Client 95 (User 95) local loss: 0.6585\n",
      "  Client 96 (User 96) local loss: 0.5987\n",
      "  Client 97 (User 97) local loss: 0.5815\n",
      "  Client 98 (User 98) local loss: 0.6503\n",
      "  Client 99 (User 99) local loss: 0.6223\n",
      "Round 3 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 4/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6886\n",
      "  Client 1 (User 1) local loss: 0.6862\n",
      "  Client 2 (User 2) local loss: 0.6640\n",
      "  Client 3 (User 3) local loss: 0.6795\n",
      "  Client 4 (User 4) local loss: 0.6286\n",
      "  Client 5 (User 5) local loss: 0.5622\n",
      "  Client 6 (User 6) local loss: 0.6309\n",
      "  Client 7 (User 7) local loss: 0.6759\n",
      "  Client 8 (User 8) local loss: 0.5598\n",
      "  Client 9 (User 9) local loss: 0.5653\n",
      "  Client 10 (User 10) local loss: 0.6143\n",
      "  Client 11 (User 11) local loss: 0.6693\n",
      "  Client 12 (User 12) local loss: 0.5075\n",
      "  Client 13 (User 13) local loss: 0.6774\n",
      "  Client 14 (User 14) local loss: 0.6439\n",
      "  Client 15 (User 15) local loss: 0.4048\n",
      "  Client 16 (User 16) local loss: 0.6341\n",
      "  Client 17 (User 17) local loss: 0.5707\n",
      "  Client 18 (User 18) local loss: 0.4892\n",
      "  Client 19 (User 19) local loss: 0.5631\n",
      "  Client 20 (User 20) local loss: 0.6293\n",
      "  Client 21 (User 21) local loss: 0.6505\n",
      "  Client 22 (User 22) local loss: 0.5842\n",
      "  Client 23 (User 23) local loss: 0.6798\n",
      "  Client 24 (User 24) local loss: 0.5751\n",
      "  Client 25 (User 25) local loss: 0.5875\n",
      "  Client 26 (User 26) local loss: 0.6279\n",
      "  Client 27 (User 27) local loss: 0.6025\n",
      "  Client 28 (User 28) local loss: 0.7042\n",
      "  Client 29 (User 29) local loss: 0.6645\n",
      "  Client 30 (User 30) local loss: 0.5776\n",
      "  Client 31 (User 31) local loss: 0.5429\n",
      "  Client 32 (User 32) local loss: 0.5690\n",
      "  Client 33 (User 33) local loss: 0.4901\n",
      "  Client 34 (User 34) local loss: 0.5609\n",
      "  Client 35 (User 35) local loss: 0.5458\n",
      "  Client 36 (User 36) local loss: 0.6482\n",
      "  Client 37 (User 37) local loss: 0.6489\n",
      "  Client 38 (User 38) local loss: 0.5680\n",
      "  Client 39 (User 39) local loss: 0.5959\n",
      "  Client 40 (User 40) local loss: 0.6266\n",
      "  Client 41 (User 41) local loss: 0.6323\n",
      "  Client 42 (User 42) local loss: 0.6492\n",
      "  Client 43 (User 43) local loss: 0.6585\n",
      "  Client 44 (User 44) local loss: 0.6930\n",
      "  Client 45 (User 45) local loss: 0.7114\n",
      "  Client 46 (User 46) local loss: 0.6336\n",
      "  Client 47 (User 47) local loss: 0.5725\n",
      "  Client 48 (User 48) local loss: 0.6612\n",
      "  Client 49 (User 49) local loss: 0.6023\n",
      "  Client 50 (User 50) local loss: 0.6440\n",
      "  Client 51 (User 51) local loss: 0.6146\n",
      "  Client 52 (User 52) local loss: 0.5495\n",
      "  Client 53 (User 53) local loss: 0.5263\n",
      "  Client 54 (User 54) local loss: 0.6938\n",
      "  Client 55 (User 55) local loss: 0.5607\n",
      "  Client 56 (User 56) local loss: 0.6607\n",
      "  Client 57 (User 57) local loss: 0.6854\n",
      "  Client 58 (User 58) local loss: 0.5705\n",
      "  Client 59 (User 59) local loss: 0.6346\n",
      "  Client 60 (User 60) local loss: 0.6042\n",
      "  Client 61 (User 61) local loss: 0.6447\n",
      "  Client 62 (User 62) local loss: 0.6836\n",
      "  Client 63 (User 63) local loss: 0.6149\n",
      "  Client 64 (User 64) local loss: 0.6263\n",
      "  Client 65 (User 65) local loss: 0.6789\n",
      "  Client 66 (User 66) local loss: 0.6070\n",
      "  Client 67 (User 67) local loss: 0.5712\n",
      "  Client 68 (User 68) local loss: 0.7012\n",
      "  Client 69 (User 69) local loss: 0.5776\n",
      "  Client 70 (User 70) local loss: 0.6753\n",
      "  Client 71 (User 71) local loss: 0.6507\n",
      "  Client 72 (User 72) local loss: 0.7137\n",
      "  Client 73 (User 73) local loss: 0.5684\n",
      "  Client 74 (User 74) local loss: 0.5258\n",
      "  Client 75 (User 75) local loss: 0.5880\n",
      "  Client 76 (User 76) local loss: 0.6012\n",
      "  Client 77 (User 77) local loss: 0.6748\n",
      "  Client 78 (User 78) local loss: 0.7088\n",
      "  Client 79 (User 79) local loss: 0.7272\n",
      "  Client 80 (User 80) local loss: 0.5784\n",
      "  Client 81 (User 81) local loss: 0.5397\n",
      "  Client 82 (User 82) local loss: 0.5909\n",
      "  Client 83 (User 83) local loss: 0.5225\n",
      "  Client 84 (User 84) local loss: 0.5968\n",
      "  Client 85 (User 85) local loss: 0.7115\n",
      "  Client 86 (User 86) local loss: 0.6163\n",
      "  Client 87 (User 87) local loss: 0.6626\n",
      "  Client 88 (User 88) local loss: 0.6071\n",
      "  Client 89 (User 89) local loss: 0.4879\n",
      "  Client 90 (User 90) local loss: 0.5407\n",
      "  Client 91 (User 91) local loss: 0.6191\n",
      "  Client 92 (User 92) local loss: 0.5132\n",
      "  Client 93 (User 93) local loss: 0.6890\n",
      "  Client 94 (User 94) local loss: 0.6831\n",
      "  Client 95 (User 95) local loss: 0.6540\n",
      "  Client 96 (User 96) local loss: 0.5835\n",
      "  Client 97 (User 97) local loss: 0.5181\n",
      "  Client 98 (User 98) local loss: 0.6207\n",
      "  Client 99 (User 99) local loss: 0.6346\n",
      "Round 4 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 5/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6559\n",
      "  Client 1 (User 1) local loss: 0.7016\n",
      "  Client 2 (User 2) local loss: 0.6547\n",
      "  Client 3 (User 3) local loss: 0.6679\n",
      "  Client 4 (User 4) local loss: 0.5939\n",
      "  Client 5 (User 5) local loss: 0.5997\n",
      "  Client 6 (User 6) local loss: 0.6296\n",
      "  Client 7 (User 7) local loss: 0.6432\n",
      "  Client 8 (User 8) local loss: 0.5482\n",
      "  Client 9 (User 9) local loss: 0.5619\n",
      "  Client 10 (User 10) local loss: 0.6580\n",
      "  Client 11 (User 11) local loss: 0.7190\n",
      "  Client 12 (User 12) local loss: 0.4522\n",
      "  Client 13 (User 13) local loss: 0.6980\n",
      "  Client 14 (User 14) local loss: 0.6420\n",
      "  Client 15 (User 15) local loss: 0.3561\n",
      "  Client 16 (User 16) local loss: 0.6471\n",
      "  Client 17 (User 17) local loss: 0.5302\n",
      "  Client 18 (User 18) local loss: 0.4686\n",
      "  Client 19 (User 19) local loss: 0.5559\n",
      "  Client 20 (User 20) local loss: 0.6897\n",
      "  Client 21 (User 21) local loss: 0.6351\n",
      "  Client 22 (User 22) local loss: 0.5331\n",
      "  Client 23 (User 23) local loss: 0.6409\n",
      "  Client 24 (User 24) local loss: 0.6143\n",
      "  Client 25 (User 25) local loss: 0.5811\n",
      "  Client 26 (User 26) local loss: 0.5992\n",
      "  Client 27 (User 27) local loss: 0.5824\n",
      "  Client 28 (User 28) local loss: 0.6772\n",
      "  Client 29 (User 29) local loss: 0.6714\n",
      "  Client 30 (User 30) local loss: 0.5244\n",
      "  Client 31 (User 31) local loss: 0.5973\n",
      "  Client 32 (User 32) local loss: 0.5277\n",
      "  Client 33 (User 33) local loss: 0.5169\n",
      "  Client 34 (User 34) local loss: 0.5786\n",
      "  Client 35 (User 35) local loss: 0.5583\n",
      "  Client 36 (User 36) local loss: 0.6673\n",
      "  Client 37 (User 37) local loss: 0.6782\n",
      "  Client 38 (User 38) local loss: 0.5661\n",
      "  Client 39 (User 39) local loss: 0.5747\n",
      "  Client 40 (User 40) local loss: 0.6038\n",
      "  Client 41 (User 41) local loss: 0.6524\n",
      "  Client 42 (User 42) local loss: 0.6756\n",
      "  Client 43 (User 43) local loss: 0.6202\n",
      "  Client 44 (User 44) local loss: 0.6746\n",
      "  Client 45 (User 45) local loss: 0.6730\n",
      "  Client 46 (User 46) local loss: 0.6035\n",
      "  Client 47 (User 47) local loss: 0.6282\n",
      "  Client 48 (User 48) local loss: 0.6666\n",
      "  Client 49 (User 49) local loss: 0.6014\n",
      "  Client 50 (User 50) local loss: 0.6807\n",
      "  Client 51 (User 51) local loss: 0.5783\n",
      "  Client 52 (User 52) local loss: 0.5786\n",
      "  Client 53 (User 53) local loss: 0.5514\n",
      "  Client 54 (User 54) local loss: 0.7007\n",
      "  Client 55 (User 55) local loss: 0.5489\n",
      "  Client 56 (User 56) local loss: 0.7067\n",
      "  Client 57 (User 57) local loss: 0.6783\n",
      "  Client 58 (User 58) local loss: 0.5846\n",
      "  Client 59 (User 59) local loss: 0.6392\n",
      "  Client 60 (User 60) local loss: 0.5940\n",
      "  Client 61 (User 61) local loss: 0.6491\n",
      "  Client 62 (User 62) local loss: 0.6770\n",
      "  Client 63 (User 63) local loss: 0.6613\n",
      "  Client 64 (User 64) local loss: 0.6399\n",
      "  Client 65 (User 65) local loss: 0.6573\n",
      "  Client 66 (User 66) local loss: 0.5706\n",
      "  Client 67 (User 67) local loss: 0.5540\n",
      "  Client 68 (User 68) local loss: 0.6897\n",
      "  Client 69 (User 69) local loss: 0.5788\n",
      "  Client 70 (User 70) local loss: 0.6572\n",
      "  Client 71 (User 71) local loss: 0.6189\n",
      "  Client 72 (User 72) local loss: 0.7009\n",
      "  Client 73 (User 73) local loss: 0.6052\n",
      "  Client 74 (User 74) local loss: 0.5969\n",
      "  Client 75 (User 75) local loss: 0.6535\n",
      "  Client 76 (User 76) local loss: 0.5843\n",
      "  Client 77 (User 77) local loss: 0.6576\n",
      "  Client 78 (User 78) local loss: 0.7233\n",
      "  Client 79 (User 79) local loss: 0.7062\n",
      "  Client 80 (User 80) local loss: 0.5615\n",
      "  Client 81 (User 81) local loss: 0.5746\n",
      "  Client 82 (User 82) local loss: 0.6188\n",
      "  Client 83 (User 83) local loss: 0.5007\n",
      "  Client 84 (User 84) local loss: 0.6042\n",
      "  Client 85 (User 85) local loss: 0.6782\n",
      "  Client 86 (User 86) local loss: 0.5711\n",
      "  Client 87 (User 87) local loss: 0.6454\n",
      "  Client 88 (User 88) local loss: 0.6420\n",
      "  Client 89 (User 89) local loss: 0.4665\n",
      "  Client 90 (User 90) local loss: 0.5225\n",
      "  Client 91 (User 91) local loss: 0.6370\n",
      "  Client 92 (User 92) local loss: 0.5206\n",
      "  Client 93 (User 93) local loss: 0.6852\n",
      "  Client 94 (User 94) local loss: 0.6257\n",
      "  Client 95 (User 95) local loss: 0.6600\n",
      "  Client 96 (User 96) local loss: 0.5604\n",
      "  Client 97 (User 97) local loss: 0.4903\n",
      "  Client 98 (User 98) local loss: 0.6247\n",
      "  Client 99 (User 99) local loss: 0.6283\n",
      "Round 5 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 6/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6618\n",
      "  Client 1 (User 1) local loss: 0.6841\n",
      "  Client 2 (User 2) local loss: 0.5865\n",
      "  Client 3 (User 3) local loss: 0.6766\n",
      "  Client 4 (User 4) local loss: 0.6037\n",
      "  Client 5 (User 5) local loss: 0.5377\n",
      "  Client 6 (User 6) local loss: 0.6414\n",
      "  Client 7 (User 7) local loss: 0.6365\n",
      "  Client 8 (User 8) local loss: 0.5137\n",
      "  Client 9 (User 9) local loss: 0.5646\n",
      "  Client 10 (User 10) local loss: 0.6104\n",
      "  Client 11 (User 11) local loss: 0.6362\n",
      "  Client 12 (User 12) local loss: 0.4831\n",
      "  Client 13 (User 13) local loss: 0.6639\n",
      "  Client 14 (User 14) local loss: 0.6400\n",
      "  Client 15 (User 15) local loss: 0.3208\n",
      "  Client 16 (User 16) local loss: 0.6311\n",
      "  Client 17 (User 17) local loss: 0.5297\n",
      "  Client 18 (User 18) local loss: 0.4356\n",
      "  Client 19 (User 19) local loss: 0.5960\n",
      "  Client 20 (User 20) local loss: 0.6678\n",
      "  Client 21 (User 21) local loss: 0.6208\n",
      "  Client 22 (User 22) local loss: 0.5195\n",
      "  Client 23 (User 23) local loss: 0.6756\n",
      "  Client 24 (User 24) local loss: 0.5803\n",
      "  Client 25 (User 25) local loss: 0.6266\n",
      "  Client 26 (User 26) local loss: 0.5849\n",
      "  Client 27 (User 27) local loss: 0.5629\n",
      "  Client 28 (User 28) local loss: 0.6751\n",
      "  Client 29 (User 29) local loss: 0.6734\n",
      "  Client 30 (User 30) local loss: 0.5473\n",
      "  Client 31 (User 31) local loss: 0.5862\n",
      "  Client 32 (User 32) local loss: 0.5120\n",
      "  Client 33 (User 33) local loss: 0.4662\n",
      "  Client 34 (User 34) local loss: 0.5540\n",
      "  Client 35 (User 35) local loss: 0.5638\n",
      "  Client 36 (User 36) local loss: 0.6782\n",
      "  Client 37 (User 37) local loss: 0.6840\n",
      "  Client 38 (User 38) local loss: 0.5614\n",
      "  Client 39 (User 39) local loss: 0.6221\n",
      "  Client 40 (User 40) local loss: 0.6169\n",
      "  Client 41 (User 41) local loss: 0.6686\n",
      "  Client 42 (User 42) local loss: 0.6672\n",
      "  Client 43 (User 43) local loss: 0.6194\n",
      "  Client 44 (User 44) local loss: 0.6975\n",
      "  Client 45 (User 45) local loss: 0.7184\n",
      "  Client 46 (User 46) local loss: 0.6049\n",
      "  Client 47 (User 47) local loss: 0.5681\n",
      "  Client 48 (User 48) local loss: 0.6501\n",
      "  Client 49 (User 49) local loss: 0.6283\n",
      "  Client 50 (User 50) local loss: 0.6688\n",
      "  Client 51 (User 51) local loss: 0.5853\n",
      "  Client 52 (User 52) local loss: 0.5877\n",
      "  Client 53 (User 53) local loss: 0.4683\n",
      "  Client 54 (User 54) local loss: 0.6888\n",
      "  Client 55 (User 55) local loss: 0.5936\n",
      "  Client 56 (User 56) local loss: 0.6817\n",
      "  Client 57 (User 57) local loss: 0.6652\n",
      "  Client 58 (User 58) local loss: 0.6087\n",
      "  Client 59 (User 59) local loss: 0.6369\n",
      "  Client 60 (User 60) local loss: 0.6107\n",
      "  Client 61 (User 61) local loss: 0.6317\n",
      "  Client 62 (User 62) local loss: 0.6700\n",
      "  Client 63 (User 63) local loss: 0.6015\n",
      "  Client 64 (User 64) local loss: 0.6414\n",
      "  Client 65 (User 65) local loss: 0.6354\n",
      "  Client 66 (User 66) local loss: 0.6217\n",
      "  Client 67 (User 67) local loss: 0.5612\n",
      "  Client 68 (User 68) local loss: 0.6981\n",
      "  Client 69 (User 69) local loss: 0.5987\n",
      "  Client 70 (User 70) local loss: 0.7013\n",
      "  Client 71 (User 71) local loss: 0.6388\n",
      "  Client 72 (User 72) local loss: 0.6863\n",
      "  Client 73 (User 73) local loss: 0.6117\n",
      "  Client 74 (User 74) local loss: 0.5739\n",
      "  Client 75 (User 75) local loss: 0.5636\n",
      "  Client 76 (User 76) local loss: 0.5892\n",
      "  Client 77 (User 77) local loss: 0.6846\n",
      "  Client 78 (User 78) local loss: 0.6713\n",
      "  Client 79 (User 79) local loss: 0.7254\n",
      "  Client 80 (User 80) local loss: 0.5979\n",
      "  Client 81 (User 81) local loss: 0.5663\n",
      "  Client 82 (User 82) local loss: 0.6239\n",
      "  Client 83 (User 83) local loss: 0.4927\n",
      "  Client 84 (User 84) local loss: 0.5824\n",
      "  Client 85 (User 85) local loss: 0.6957\n",
      "  Client 86 (User 86) local loss: 0.5248\n",
      "  Client 87 (User 87) local loss: 0.6580\n",
      "  Client 88 (User 88) local loss: 0.6501\n",
      "  Client 89 (User 89) local loss: 0.4386\n",
      "  Client 90 (User 90) local loss: 0.5457\n",
      "  Client 91 (User 91) local loss: 0.6351\n",
      "  Client 92 (User 92) local loss: 0.4608\n",
      "  Client 93 (User 93) local loss: 0.6640\n",
      "  Client 94 (User 94) local loss: 0.6617\n",
      "  Client 95 (User 95) local loss: 0.6697\n",
      "  Client 96 (User 96) local loss: 0.5987\n",
      "  Client 97 (User 97) local loss: 0.5512\n",
      "  Client 98 (User 98) local loss: 0.6701\n",
      "  Client 99 (User 99) local loss: 0.6224\n",
      "Round 6 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 7/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6474\n",
      "  Client 1 (User 1) local loss: 0.6678\n",
      "  Client 2 (User 2) local loss: 0.7034\n",
      "  Client 3 (User 3) local loss: 0.6697\n",
      "  Client 4 (User 4) local loss: 0.5454\n",
      "  Client 5 (User 5) local loss: 0.5423\n",
      "  Client 6 (User 6) local loss: 0.6578\n",
      "  Client 7 (User 7) local loss: 0.6535\n",
      "  Client 8 (User 8) local loss: 0.4875\n",
      "  Client 9 (User 9) local loss: 0.5645\n",
      "  Client 10 (User 10) local loss: 0.6342\n",
      "  Client 11 (User 11) local loss: 0.6652\n",
      "  Client 12 (User 12) local loss: 0.5178\n",
      "  Client 13 (User 13) local loss: 0.6618\n",
      "  Client 14 (User 14) local loss: 0.6394\n",
      "  Client 15 (User 15) local loss: 0.3685\n",
      "  Client 16 (User 16) local loss: 0.6498\n",
      "  Client 17 (User 17) local loss: 0.5030\n",
      "  Client 18 (User 18) local loss: 0.5010\n",
      "  Client 19 (User 19) local loss: 0.5777\n",
      "  Client 20 (User 20) local loss: 0.6601\n",
      "  Client 21 (User 21) local loss: 0.6311\n",
      "  Client 22 (User 22) local loss: 0.5120\n",
      "  Client 23 (User 23) local loss: 0.6635\n",
      "  Client 24 (User 24) local loss: 0.5576\n",
      "  Client 25 (User 25) local loss: 0.5810\n",
      "  Client 26 (User 26) local loss: 0.5961\n",
      "  Client 27 (User 27) local loss: 0.5823\n",
      "  Client 28 (User 28) local loss: 0.6639\n",
      "  Client 29 (User 29) local loss: 0.6828\n",
      "  Client 30 (User 30) local loss: 0.4989\n",
      "  Client 31 (User 31) local loss: 0.6161\n",
      "  Client 32 (User 32) local loss: 0.5171\n",
      "  Client 33 (User 33) local loss: 0.5314\n",
      "  Client 34 (User 34) local loss: 0.6502\n",
      "  Client 35 (User 35) local loss: 0.5534\n",
      "  Client 36 (User 36) local loss: 0.6275\n",
      "  Client 37 (User 37) local loss: 0.6488\n",
      "  Client 38 (User 38) local loss: 0.6092\n",
      "  Client 39 (User 39) local loss: 0.5994\n",
      "  Client 40 (User 40) local loss: 0.6376\n",
      "  Client 41 (User 41) local loss: 0.6475\n",
      "  Client 42 (User 42) local loss: 0.6696\n",
      "  Client 43 (User 43) local loss: 0.6418\n",
      "  Client 44 (User 44) local loss: 0.6785\n",
      "  Client 45 (User 45) local loss: 0.6919\n",
      "  Client 46 (User 46) local loss: 0.5624\n",
      "  Client 47 (User 47) local loss: 0.5999\n",
      "  Client 48 (User 48) local loss: 0.6630\n",
      "  Client 49 (User 49) local loss: 0.6411\n",
      "  Client 50 (User 50) local loss: 0.6709\n",
      "  Client 51 (User 51) local loss: 0.5769\n",
      "  Client 52 (User 52) local loss: 0.5699\n",
      "  Client 53 (User 53) local loss: 0.5370\n",
      "  Client 54 (User 54) local loss: 0.7236\n",
      "  Client 55 (User 55) local loss: 0.6214\n",
      "  Client 56 (User 56) local loss: 0.6685\n",
      "  Client 57 (User 57) local loss: 0.6884\n",
      "  Client 58 (User 58) local loss: 0.5697\n",
      "  Client 59 (User 59) local loss: 0.6525\n",
      "  Client 60 (User 60) local loss: 0.6388\n",
      "  Client 61 (User 61) local loss: 0.5706\n",
      "  Client 62 (User 62) local loss: 0.6659\n",
      "  Client 63 (User 63) local loss: 0.6425\n",
      "  Client 64 (User 64) local loss: 0.6310\n",
      "  Client 65 (User 65) local loss: 0.6435\n",
      "  Client 66 (User 66) local loss: 0.6111\n",
      "  Client 67 (User 67) local loss: 0.5516\n",
      "  Client 68 (User 68) local loss: 0.6770\n",
      "  Client 69 (User 69) local loss: 0.5539\n",
      "  Client 70 (User 70) local loss: 0.7038\n",
      "  Client 71 (User 71) local loss: 0.6818\n",
      "  Client 72 (User 72) local loss: 0.6921\n",
      "  Client 73 (User 73) local loss: 0.5857\n",
      "  Client 74 (User 74) local loss: 0.5745\n",
      "  Client 75 (User 75) local loss: 0.6455\n",
      "  Client 76 (User 76) local loss: 0.6159\n",
      "  Client 77 (User 77) local loss: 0.7015\n",
      "  Client 78 (User 78) local loss: 0.7163\n",
      "  Client 79 (User 79) local loss: 0.7111\n",
      "  Client 80 (User 80) local loss: 0.5757\n",
      "  Client 81 (User 81) local loss: 0.5629\n",
      "  Client 82 (User 82) local loss: 0.6002\n",
      "  Client 83 (User 83) local loss: 0.4455\n",
      "  Client 84 (User 84) local loss: 0.5651\n",
      "  Client 85 (User 85) local loss: 0.7196\n",
      "  Client 86 (User 86) local loss: 0.6072\n",
      "  Client 87 (User 87) local loss: 0.6645\n",
      "  Client 88 (User 88) local loss: 0.6487\n",
      "  Client 89 (User 89) local loss: 0.4292\n",
      "  Client 90 (User 90) local loss: 0.5095\n",
      "  Client 91 (User 91) local loss: 0.6528\n",
      "  Client 92 (User 92) local loss: 0.5289\n",
      "  Client 93 (User 93) local loss: 0.6987\n",
      "  Client 94 (User 94) local loss: 0.6449\n",
      "  Client 95 (User 95) local loss: 0.6824\n",
      "  Client 96 (User 96) local loss: 0.5995\n",
      "  Client 97 (User 97) local loss: 0.5366\n",
      "  Client 98 (User 98) local loss: 0.6711\n",
      "  Client 99 (User 99) local loss: 0.6456\n",
      "Round 7 completed. Global item embeddings updated.\n",
      "\n",
      "--- Communication Round 8/10 ---\n",
      "  Client 0 (User 0) local loss: 0.6522\n",
      "  Client 1 (User 1) local loss: 0.6733\n",
      "  Client 2 (User 2) local loss: 0.6511\n",
      "  Client 3 (User 3) local loss: 0.6653\n",
      "  Client 4 (User 4) local loss: 0.6611\n",
      "  Client 5 (User 5) local loss: 0.5404\n",
      "  Client 6 (User 6) local loss: 0.6141\n",
      "  Client 7 (User 7) local loss: 0.5925\n",
      "  Client 8 (User 8) local loss: 0.5433\n",
      "  Client 9 (User 9) local loss: 0.5293\n",
      "  Client 10 (User 10) local loss: 0.5873\n",
      "  Client 11 (User 11) local loss: 0.6617\n",
      "  Client 12 (User 12) local loss: 0.5233\n",
      "  Client 13 (User 13) local loss: 0.6631\n",
      "  Client 14 (User 14) local loss: 0.6052\n",
      "  Client 15 (User 15) local loss: 0.3513\n",
      "  Client 16 (User 16) local loss: 0.6356\n",
      "  Client 17 (User 17) local loss: 0.5241\n",
      "  Client 18 (User 18) local loss: 0.5459\n",
      "  Client 19 (User 19) local loss: 0.5162\n",
      "  Client 20 (User 20) local loss: 0.6617\n",
      "  Client 21 (User 21) local loss: 0.6271\n",
      "  Client 22 (User 22) local loss: 0.4921\n",
      "  Client 23 (User 23) local loss: 0.6509\n",
      "  Client 24 (User 24) local loss: 0.5772\n",
      "  Client 25 (User 25) local loss: 0.5942\n",
      "  Client 26 (User 26) local loss: 0.5926\n",
      "  Client 27 (User 27) local loss: 0.5990\n",
      "  Client 28 (User 28) local loss: 0.6684\n",
      "  Client 29 (User 29) local loss: 0.6733\n",
      "  Client 30 (User 30) local loss: 0.5394\n",
      "  Client 31 (User 31) local loss: 0.5714\n",
      "  Client 32 (User 32) local loss: 0.5927\n",
      "  Client 33 (User 33) local loss: 0.4855\n",
      "  Client 34 (User 34) local loss: 0.6181\n",
      "  Client 35 (User 35) local loss: 0.5328\n",
      "  Client 36 (User 36) local loss: 0.6524\n",
      "  Client 37 (User 37) local loss: 0.6483\n",
      "  Client 38 (User 38) local loss: 0.5593\n",
      "  Client 39 (User 39) local loss: 0.6123\n",
      "  Client 40 (User 40) local loss: 0.6493\n",
      "  Client 41 (User 41) local loss: 0.6318\n",
      "  Client 42 (User 42) local loss: 0.6540\n",
      "  Client 43 (User 43) local loss: 0.6410\n",
      "  Client 44 (User 44) local loss: 0.6713\n",
      "  Client 45 (User 45) local loss: 0.6799\n",
      "  Client 46 (User 46) local loss: 0.6089\n",
      "  Client 47 (User 47) local loss: 0.6018\n",
      "  Client 48 (User 48) local loss: 0.6206\n",
      "  Client 49 (User 49) local loss: 0.6327\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 251\u001b[39m\n\u001b[32m    248\u001b[39m optimizer.zero_grad()\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# predictions, user_linear_weight_matrix, item_embs_batch = model(user_ids_batch, item_ids_batch, current_user_texts)\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# ClientModelのforwardの戻り値を修正したため、それに合わせる\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m predictions, user_joint_embedding_linear_weight, local_item_embedding_weight = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ids_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_user_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# 損失計算 (L_1のみ)\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# 論文の式(10) L_1(y,y^) [cite: 91]\u001b[39;00m\n\u001b[32m    255\u001b[39m loss = nn.BCELoss()(predictions.squeeze(), labels_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mClientModel.forward\u001b[39m\u001b[34m(self, user_ids, item_ids, user_texts_batch)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_ids, item_ids, user_texts_batch):\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# ユーザーのテキスト特徴をPLMで埋め込み\u001b[39;00m\n\u001b[32m     40\u001b[39m     encoded_input = plm_tokenizer(user_texts_batch, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     plm_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mplm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m.last_hidden_state[:, \u001b[32m0\u001b[39m, :] \u001b[38;5;66;03m# [CLS]トークンの埋め込みを使用 [cite: 73]\u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Joint Embedding Layer の線形変換\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# 論文の式(3): e_u = h(v_u) = v_u W_d1xd + b [cite: 78]\u001b[39;00m\n\u001b[32m     45\u001b[39m     user_embedding = \u001b[38;5;28mself\u001b[39m.user_joint_embedding_linear(plm_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1016\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m   1012\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m   1013\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m   1014\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1016\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1029\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:662\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    651\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    652\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    653\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    659\u001b[39m         output_attentions,\n\u001b[32m    660\u001b[39m     )\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    672\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:552\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    541\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    542\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    549\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m    550\u001b[39m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[32m    551\u001b[39m     self_attn_past_key_value = past_key_value[:\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:482\u001b[39m, in \u001b[36mBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    473\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    474\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    480\u001b[39m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    481\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    492\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/project-UD7q69fU-py3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:407\u001b[39m, in \u001b[36mBertSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[32m    403\u001b[39m is_causal = (\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    405\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    417\u001b[39m attn_output = attn_output.reshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m.all_head_size)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 軽量 LLM 埋め込みモデルのロード (変更なし)\n",
    "plm_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "plm_tokenizer = AutoTokenizer.from_pretrained(plm_model_name)\n",
    "plm_model = AutoModel.from_pretrained(plm_model_name)\n",
    "\n",
    "# PLMは学習済みモデルのため、勾配計算を無効化\n",
    "for param in plm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "plm_embedding_dim = plm_model.config.hidden_size\n",
    "print(f\"PLM embedding dimension: {plm_embedding_dim}\")\n",
    "\n",
    "\n",
    "class ClientModel(nn.Module):\n",
    "    def __init__(self, num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.plm_model = plm_model\n",
    "        \n",
    "        # Joint Embedding Layer の線形変換部分 (ユーザーのローカルパラメータ)\n",
    "        # 論文の「trainable linear layer」[cite: 75]\n",
    "        self.user_joint_embedding_linear = nn.Linear(plm_embedding_dim, joint_embedding_output_dim)\n",
    "        \n",
    "        # アイテム埋め込み (各クライアントのローカルパラメータとして初期化される)\n",
    "        self.local_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "\n",
    "        # 予測層 (各クライアントのローカルパラメータ)\n",
    "        self.prediction_layer = nn.Linear(joint_embedding_output_dim + item_embedding_dim, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, user_texts_batch):\n",
    "        # ユーザーのテキスト特徴をPLMで埋め込み\n",
    "        encoded_input = plm_tokenizer(user_texts_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        plm_output = self.plm_model(**encoded_input).last_hidden_state[:, 0, :] # [CLS]トークンの埋め込みを使用 [cite: 73]\n",
    "\n",
    "        # Joint Embedding Layer の線形変換\n",
    "        # 論文の式(3): e_u = h(v_u) = v_u W_d1xd + b [cite: 78]\n",
    "        user_embedding = self.user_joint_embedding_linear(plm_output)\n",
    "\n",
    "        # ローカルのアイテム埋め込み\n",
    "        item_embedding = self.local_item_embedding(item_ids)\n",
    "\n",
    "        # ユーザー埋め込みとアイテム埋め込みを結合\n",
    "        combined_features = torch.cat((user_embedding, item_embedding), dim=1)\n",
    "\n",
    "        # 予測\n",
    "        prediction = torch.sigmoid(self.prediction_layer(combined_features))\n",
    "        # 論文では「user joint embedding weights」[cite: 61] と「local item embeddings」[cite: 61] をサーバーに送信するとある。\n",
    "        # ここでは、user_joint_embedding_linear.weight と local_item_embedding.weight を返す\n",
    "        return prediction, self.user_joint_embedding_linear.weight, self.local_item_embedding.weight\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, num_users, num_items, item_embedding_dim, joint_embedding_output_dim):\n",
    "        # グローバルアイテム埋め込みは、全アイテムの埋め込み行列として管理\n",
    "        self.global_item_embedding = nn.Embedding(num_items, item_embedding_dim)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        self.joint_embedding_output_dim = joint_embedding_output_dim\n",
    "    \n",
    "    def build_user_relationship_graph(self, user_linear_weights_map):\n",
    "        \"\"\"\n",
    "        各ユーザーのuser_joint_embedding_linear.weightからユーザー関係グラフを構築します。\n",
    "        論文の式 (15) に基づいています。\n",
    "        \n",
    "        Args:\n",
    "            user_linear_weights_map (dict): {user_id: user_joint_embedding_linear.weight.data (flattened)}\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: ユーザーグラフの隣接行列 (NumPy配列)\n",
    "            list: グラフのノード順に対応するユーザーIDのリスト\n",
    "        \"\"\"\n",
    "        # ユーザーIDをグラフのノードとして扱う\n",
    "        sorted_user_ids = sorted(user_linear_weights_map.keys())\n",
    "        if not sorted_user_ids:\n",
    "            return np.zeros((0, 0)), []\n",
    "\n",
    "        # 各ユーザーの線形層の重みベクトルを収集\n",
    "        # 論文の「w_i = vec(W_i)」に相当 [cite: 105]\n",
    "        user_weight_vectors = np.array([\n",
    "            user_linear_weights_map[u_id].cpu().numpy() for u_id in sorted_user_ids\n",
    "        ])\n",
    "\n",
    "        # コサイン類似度で類似度行列を計算 (S_ij)\n",
    "        # 論文の式(15)に相当 [cite: 106]\n",
    "        similarity_matrix = cosine_similarity(user_weight_vectors)\n",
    "\n",
    "        # ここでは簡単のため、完全な類似度グラフを使用 (S' に相当)\n",
    "        # 論文の「take the top-N in the highest similarity list」 は、後のステップで実装可能 [cite: 108]\n",
    "        user_graph_adj = similarity_matrix \n",
    "        \n",
    "        return user_graph_adj, sorted_user_ids\n",
    "\n",
    "    def aggregate_item_embeddings(self, user_local_item_weights, user_graph_adj, sorted_user_ids):\n",
    "        \"\"\"\n",
    "        ユーザー関係グラフに基づいて、アイテム埋め込みをグローバルに集約します。\n",
    "        論文の式 (16) と (17) に基づいています。\n",
    "        \n",
    "        Args:\n",
    "            user_local_item_weights (dict): {user_id: local_item_embedding.weight.data (Tensor)}\n",
    "            user_graph_adj (np.ndarray): ユーザーグラフの隣接行列\n",
    "            sorted_user_ids (list): user_graph_adj のノード順に対応するユーザーIDのリスト\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: 更新されたグローバルアイテム埋め込みの重み\n",
    "        \"\"\"\n",
    "        if not user_local_item_weights:\n",
    "            return self.global_item_embedding.weight.data\n",
    "\n",
    "        # グラフの順序に合わせて各ユーザーのアイテム埋め込みを行列Aとしてまとめる\n",
    "        # A は (num_users, num_items, item_embedding_dim)\n",
    "        # 論文の「A is the round item embedding matrix, the I-th row represents the item embedding obtained from user i」に相当 \n",
    "        item_embedding_matrix_A = torch.stack([\n",
    "            user_local_item_weights[u_id] for u_id in sorted_user_ids\n",
    "        ]) # (num_users, num_items, item_embedding_dim)\n",
    "\n",
    "        # グラフの正規化 (S'')\n",
    "        row_sums_graph = np.sum(user_graph_adj, axis=1, keepdims=True)\n",
    "        row_sums_graph[row_sums_graph == 0] = 1 # ゼロ除算回避\n",
    "        normalized_user_graph_adj = user_graph_adj / row_sums_graph\n",
    "        \n",
    "        # NumPyをPyTorchテンソルに変換\n",
    "        normalized_user_graph_adj_tensor = torch.tensor(normalized_user_graph_adj, dtype=torch.float32)\n",
    "\n",
    "        # グラフ畳み込み (R = S'' A)\n",
    "        # R は (num_users, num_items, item_embedding_dim) となる\n",
    "        # MatMul: (num_users, num_users) x (num_users, num_items, item_embedding_dim)\n",
    "        # Einstein Summation Convention: 'ij, jkd -> ikd'\n",
    "        R_tensor = torch.einsum('ij, jkd -> ikd', normalized_user_graph_adj_tensor, item_embedding_matrix_A) # \n",
    "\n",
    "        # グローバルアイテム埋め込みの更新 (θ_global = DR)\n",
    "        # 論文の式(17)に相当 [cite: 113]\n",
    "        # ここではDを全ユーザーの単純平均と解釈 (Rの0次元目を平均)\n",
    "        new_global_item_embedding_weight = R_tensor.mean(dim=0) # (num_items, item_embedding_dim)\n",
    "\n",
    "        # サーバーのグローバルアイテム埋め込みを直接更新\n",
    "        self.global_item_embedding.weight.data.copy_(new_global_item_embedding_weight)\n",
    "        \n",
    "        return self.global_item_embedding.weight.data\n",
    "\n",
    "\n",
    "# データセットの準備とクライアントへの分割 (変更)\n",
    "# 1クライアント1ユーザーをシミュレート\n",
    "num_users = 100\n",
    "num_items = 50\n",
    "num_clients = num_users # ここを修正: クライアント数とユーザー数を同じにする\n",
    "\n",
    "user_texts = {i: f\"This user likes movies about {i % 5} and enjoys {i % 3}.\" for i in range(num_users)}\n",
    "\n",
    "interactions_list = []\n",
    "for u_id in range(num_users):\n",
    "    for i_id in range(num_items):\n",
    "        if np.random.rand() > 0.7:\n",
    "            interactions_list.append([u_id, i_id, 1])\n",
    "        else:\n",
    "            interactions_list.append([u_id, i_id, 0])\n",
    "\n",
    "interactions = torch.tensor(interactions_list, dtype=torch.float32)\n",
    "\n",
    "client_user_map = {} # {client_id: user_id}\n",
    "client_datasets = {}\n",
    "for u_id in range(num_users):\n",
    "    client_id = u_id # クライアントIDをユーザーIDと同じにする NOTE: 1クライアント複数ユーザのようなケースにも対応できるようにしているが今回は、1クライアント1ユーザ.\n",
    "    client_user_map[client_id] = u_id\n",
    "\n",
    "    # 各クライアントは自身のユーザーのインタラクションデータのみを持つ\n",
    "    client_interactions_indices = [i for i, (u, _, _) in enumerate(interactions_list) if u == u_id]\n",
    "    if not client_interactions_indices: # インタラクションがないユーザーの場合のハンドリング\n",
    "        print(f\"Warning: User {u_id} has no interactions. Client {client_id} will have an empty dataset.\")\n",
    "        client_subset = TensorDataset(torch.empty(0, dtype=torch.long), torch.empty(0, dtype=torch.long), torch.empty(0, dtype=torch.float32))\n",
    "    else:\n",
    "        client_subset = Subset(TensorDataset(interactions[:, 0].long(), interactions[:, 1].long(), interactions[:, 2]), client_interactions_indices)\n",
    "\n",
    "    # バッチサイズを小さくするか、ユーザーごとのインタラクション数に合わせる\n",
    "    # 各ユーザーのインタラクション数が少ない場合があるので、batch_size=1でもよい\n",
    "    client_datasets[client_id] = DataLoader(client_subset, batch_size=min(32, max(1, len(client_interactions_indices))), shuffle=True)\n",
    "\n",
    "print(f\"Number of users: {num_users}\")\n",
    "print(f\"Number of items: {num_items}\")\n",
    "print(f\"Total interactions: {len(interactions)}\")\n",
    "print(f\"Number of clients (1 client per user): {num_clients}\")\n",
    "\n",
    "\n",
    "# モデルのハイパーパラメータ\n",
    "item_embedding_dim = 32\n",
    "joint_embedding_output_dim = 32 \n",
    "\n",
    "# サーバーのインスタンス化\n",
    "server = Server(num_users, num_items, item_embedding_dim, joint_embedding_output_dim)\n",
    "\n",
    "# 各クライアントのモデルを辞書で保持\n",
    "client_models = {}\n",
    "client_optimizers = {}\n",
    "for client_id in range(num_clients):\n",
    "    client_models[client_id] = ClientModel(num_items, item_embedding_dim, plm_model, plm_embedding_dim, joint_embedding_output_dim)\n",
    "    client_optimizers[client_id] = optim.Adam(client_models[client_id].parameters(), lr=0.001)\n",
    "\n",
    "# 学習ループ (フェデレーテッド学習ラウンド)\n",
    "num_communication_rounds = 10\n",
    "local_epochs = 1 \n",
    "\n",
    "for round_num in range(num_communication_rounds):\n",
    "    print(f\"\\n--- Communication Round {round_num + 1}/{num_communication_rounds} ---\")\n",
    "    \n",
    "    # サーバーからグローバルアイテム埋め込みをクライアントに配布\n",
    "    # 論文のステップ「Global Distribution: Updated global project embeddings are broadcast to all clients for next-round initialization.」[cite: 63]\n",
    "    for client_id in range(num_clients):\n",
    "        client_models[client_id].local_item_embedding.weight.data.copy_(server.global_item_embedding.weight.data)\n",
    "\n",
    "    user_linear_weights_for_graph = {} # {user_id: user_joint_embedding_linear.weight.data (flattened)}\n",
    "    user_local_item_weights_to_server = {} # {user_id: local_item_embedding.weight.data (Tensor)}\n",
    "    \n",
    "    # クライアントのローカル学習\n",
    "    # 論文のステップ「Local Training」[cite: 60]\n",
    "    for client_id in range(num_clients):\n",
    "        model = client_models[client_id]\n",
    "        optimizer = client_optimizers[client_id]\n",
    "        dataloader = client_datasets[client_id]\n",
    "        \n",
    "        model.train()\n",
    "        local_loss = 0\n",
    "        \n",
    "        # このクライアントが担当するユーザーID\n",
    "        current_user_id = client_user_map[client_id] \n",
    "        \n",
    "        if len(dataloader.dataset) == 0: # インタラクションがない場合はスキップ\n",
    "            print(f\"  Client {client_id} (User {current_user_id}) has no interactions, skipping local training.\")\n",
    "            # グラフ構築のために、初期状態の重みを使用するか、ゼロベクトルを使用するか決定する必要がある\n",
    "            # ここでは、訓練されなかったクライアントのために、現在のモデルの重み（グローバル初期化時と同じ）をアップロードする\n",
    "            user_linear_weights_for_graph[current_user_id] = model.user_joint_embedding_linear.weight.data.clone().flatten()\n",
    "            user_local_item_weights_to_server[current_user_id] = model.local_item_embedding.weight.data.clone()\n",
    "            continue\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            for user_ids_batch, item_ids_batch, labels_batch in dataloader:\n",
    "                # 1クライアント1ユーザーなので、user_ids_batchはすべて同じユーザーIDになるはず\n",
    "                assert torch.all(user_ids_batch == current_user_id) \n",
    "                current_user_texts = [user_texts[uid.item()] for uid in user_ids_batch]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                # predictions, user_linear_weight_matrix, item_embs_batch = model(user_ids_batch, item_ids_batch, current_user_texts)\n",
    "                # ClientModelのforwardの戻り値を修正したため、それに合わせる\n",
    "                predictions, user_joint_embedding_linear_weight, local_item_embedding_weight = model(user_ids_batch, item_ids_batch, current_user_texts)\n",
    "                \n",
    "                # 損失計算 (L_1のみ)\n",
    "                # 論文の式(10) L_1(y,y^) [cite: 91]\n",
    "                loss = nn.BCELoss()(predictions.squeeze(), labels_batch)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                local_loss += loss.item()\n",
    "\n",
    "        # クライアントがサーバーにアップロードするパラメータを収集\n",
    "        # 論文のステップ「Parameter Uploading: Clients transmit user joint embedding weights and local item embeddings to the server.」[cite: 61]\n",
    "        # 各ユーザー（クライアント）は自身の user_joint_embedding_linear.weight をベクトル化してアップロード\n",
    "        user_linear_weights_for_graph[current_user_id] = user_joint_embedding_linear_weight.data.clone().flatten()\n",
    "        \n",
    "        # 各ユーザー（クライアント）は自身の local_item_embedding.weight もアップロード\n",
    "        user_local_item_weights_to_server[current_user_id] = local_item_embedding_weight.data.clone()\n",
    "\n",
    "        print(f\"  Client {client_id} (User {current_user_id}) local loss: {local_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    # サーバーでの処理\n",
    "    # 論文のステップ「Graph Aggregation: The server constructs user relation graphs from text embeddings and aggregates parameters through graph convolution.」[cite: 62]\n",
    "    # ユーザー関係グラフの構築\n",
    "    # 論文のステップ「Build User Relaction Graph」[cite: 102, 122]\n",
    "    user_graph_adj, sorted_user_ids_for_graph = server.build_user_relationship_graph(\n",
    "        user_linear_weights_for_graph\n",
    "    )\n",
    "    \n",
    "    # アイテム埋め込みの集約\n",
    "    # 論文のステップ「Learn user common item embeddings with Eq.(16)」[cite: 122] と\n",
    "    # 「Learn globally shared item embedding θ_global with Eq.(17)」[cite: 122]\n",
    "    server.aggregate_item_embeddings(\n",
    "        user_local_item_weights_to_server, \n",
    "        user_graph_adj, \n",
    "        sorted_user_ids_for_graph\n",
    "    )\n",
    "\n",
    "    print(f\"Round {round_num + 1} completed. Global item embeddings updated.\")\n",
    "\n",
    "print(\"Federated training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cc5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-UD7q69fU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
